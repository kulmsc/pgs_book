[["index.html", "Comparison of PGS Generative Methods Preface", " Comparison of PGS Generative Methods Scott Kulm 2021-02-26 Preface The purpose of this book is to describe: 1. What is a PolyGenic Score (PGS) 2. How Different Methods Produce a PGS 3. How Accurate are PGSs 4. What Caveats Need to Be Thought About in PGS Construction Please note the book is still in the early phases. "],["introduction.html", "1 Introduction 1.1 Directory Framework", " 1 Introduction PolyGenic Scores provide a key formulation of genetic findings into disease prediction. There has been a fair amount of concern over the accuracy, confounding and equitability of PGSs. I believe the best way to judge the significance of these worries, and more importantly, ultimately work towards their resolve, is through well-doccumented research. Quick note on set-up. I am writing this book within a sub-directory of my larger project directory. Hopefully everything will work this way. 1.1 Directory Framework If you would like to follow along, I would like to make clear how the directories are constructed. list.files(&quot;..&quot;) ## [1] &quot;adjust_ss&quot; &quot;analyze_score&quot; &quot;book&quot; ## [4] &quot;common&quot; &quot;do_score&quot; &quot;images&quot; ## [7] &quot;local_scripts&quot; &quot;med_scripts&quot; &quot;mod_sets&quot; ## [10] &quot;old_scripts&quot; &quot;qc&quot; &quot;raw_ss&quot; ## [13] &quot;verify_toy_example&quot; I am currently writing in the book directory, one level above will lead to all of the relevant sub-directories. The second and third chapters on summary statistics take place within the directory raw_ss, the fourth chapter on adjusting summary statistics takes place in adjust_ss, . The common, finn_gen, and a few other diretories are indirectly called within scripts outside their own directory. Full paths will be used, so it should be clear where everything is at all times. "],["quality-control.html", "2 Quality Control 2.1 Previously Applied QC 2.2 Initial QC", " 2 Quality Control To begin work on producing a set of PGSs, the input data must first be carefully controlled. Throughout this project the UK Biobank will be the solitary set of data examined. The reason being is that the UK Biobank is the only large and easily accessed data-set that contains both genotypic and phenotypic information. A brief description of the UK Biobank … 2.1 Previously Applied QC In the process of sequencing the data the good people at the UK Biobank have already applied some quality control measures. To understand exactly what they did we first need to know how they even got the data to begin with. Of the nearly 500,000 people that were avaliable to be sequenced, batches of approximitley 4,600 people were created. The first 11 batches were sequenced on the UK BiLEVE Axiom array, the remaining 95 batches were sequenced with the UK Biobank Axiom Array. Both arrays were carefully created for this type of research, although we should be careful going forward as batch effects could change allele frequencies and the ultimate PGS distribution. As the arrays were novel, some of the allele probes were not constructed well enough to clearly determine what allele a person was. A total of 35,014 unique markers were therefore removed from everyone right off the bat. Genotype calling by Affymetrix resulted in a data set of 489,212 individuals typed at 812,428 markers with which to carry out further QC. This QC was population structure aware, with different ancestry groups determined by comparing PCA loadings from UK Biobank individuals to a selection of 1000 Genomes Project individuals (The markers that went into this PCA were carefully QC’d). Afterwards, within population structure homogenous groups to each batch the following tests were applied: Batch Effects Plate Effects Departures from Hardy-Weinberg Equilibrium Sex Effects Array Effects Discordance Across Controls If a marker failed the first 4 tests it was removed from the batch, and if a marker failed the last 2 tests then it was removed from the entire data-set. Each of these tests are hypothesis tests, with the cut-off chosen for removal set at p &lt; 10^-12. Clearly this is pretty extreme so it is important to note there may be more QC that needs to be done. Figure 2.1: Failure rates Following marker QC a pipeline of sample QC was applied. A good description of the pipeline is shown below. What is important to note is that the doccumentation seems to note that only individuals with really extreme missingness or hetrozygosity were removed from the dataset. Otherwise they were simply marked as being an outlier in their respective test. A more stringent threshold of the sample QC and marker QC was set for the dataset that was used within a principal component analysis. The output of this PCA was then used to determine a white, British ancestry subset. This was completed by comparing the samples who declared they were white and British and then removing outliers from the main cluster of this grouping based on PCA. Figure 2.2: British PCA Far more information on all of these steps can be found from the BioRxiv pdf: “Genome-wide genetic data on ~500,000 UK Biobank participants”. The big takeaways that I gleam are that the UK Biobank did think about genotyping seriously, the most abberant markers have been removed although some questionable markers likely remain, and that quite a few abberant samples remain although removing them should be easy since they have been marked. All of this gives a good starting point for this work. 2.2 Initial QC To increase levels of QC, a file that lists all of the outliers was used to create a list of high quality anonymous IDS. The script that ran this entire process is displayed below. In short, the process carried out involved removes outliers in hetrozygosity, putative sex chromosome aneupolidy, and excess relatvies all determined by the UK Biobank processes described above. Lastly, only individuals who were determined to be white with British ancestry were kept. This is a highly unfortunate cut-off, but nescessary in order to create a genetically homogenous individuals to be tested. Now that we have a base level of genetic data QC, we can move onto QC of the summary statistics. "],["summary-statistics.html", "3 Summary Statistics", " 3 Summary Statistics To create the PGSs we need summary statistics, or results from Genome-Wide Association Studies (GWASs). One overall requirement for the summary statistics that we use is that they cannot have utilized the UK Biobank in their production. If they did we would be overfitting the problem, which is not good. Each summary statistic must also have the following features (or columns): Chromosome Position Variant ID (the rsID) Effect Allele Alternate Allele Standard Error of the Effect Effect (Beta, Odds Ratio) P-Value The reasons we need these specific columns is as follows. Chromosome and position give the position of the variant on the genome, which is important in determining variant proximity for LD-aware methods. The variant allele is important for basic recognition purposes of which variants make it into the final score. The effect and alternative allele are nescessary just based on the polygenic risk score definition. While the alternative allele is not strictly nescessary for scoring, it is needed to determine if the variant is ambigous. The standard error and p-value are used by many methods for thresholding purposes. Lastly the effect is the other basic component needed in the polygenic risk score equation. "],["getting-the-summary-statistics.html", "4 Getting the Summary Statistics 4.1 Prepare Variants 4.2 Standardize the Summary Statistics 4.3 Heritability Estimation 4.4 Genetic Correlation Estimation 4.5 Final Changes and Remarks", " 4 Getting the Summary Statistics Now we have to get the actual summary statistics. A key consideration is to pull from summary statistics with the largest possibly underlying sample size, because it will produce the most accurate estimates. The studies can be obtained with: #Files that are already haromized mkdir Bentham wget -O Bentham/raw_bentham.ss.gz ftp://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/BenthamJ_26502338_GCST003156/harmonised/26502338-GCST003156-EFO_0002690-build37.f.tsv.gz mkdir Christophersen wget -O Christophersen/raw_christophersen.ss.gz ftp://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/ChristophersenIE_28416818_GCST004296/harmonised/28416818-GCST004296-EFO_0000275-build37.f.tsv.gz mkdir Demenais wget -O Demenais/raw_demenais.ss.gz ftp://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/DemenaisF_29273806_GCST005212/harmonised/29273806-GCST005212-EFO_0000270-build37.f.tsv.gz mkdir Dubois wget -O Dubois/raw_dubois.ss.gz ftp://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/DuboisPC_20190752_GCST000612/harmonised/20190752-GCST000612-EFO_0001060-Build37.f.tsv.gz mkdir Liu-1 wget -O Liu-1/raw_liu-1.ss.gz ftp://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/LiuJZ_26192919_GCST003044/harmonised/26192919-GCST003044-EFO_0000384-Build37.f.tsv.gz mkdir Liu-2 wget -O Liu-2/raw_liu-2.ss.gz ftp://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/LiuJZ_26192919_GCST003045/harmonised/26192919-GCST003045-EFO_0000729-Build37.f.tsv.gz mkdir Malik wget -O Malik/raw_malik.ss.gz ftp://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/MalikR_29531354_GCST005838/harmonised/29531354-GCST005838-EFO_0000712-build37.f.tsv.gz mkdir Michailidou wget -O Michailidou/raw_michailidou.ss.gz ftp://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/MichailidouK_29059683_GCST004988/harmonised/29059683-GCST004988-EFO_0000305-build37.f.tsv.gz mkdir Nikpay wget -O Nikpay/raw_nikpay.ss.gz ftp://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/NikpayM_26343387_GCST003116/harmonised/26343387-GCST003116-EFO_0000378-build37.f.tsv.gz mkdir Okada wget -O Okada/raw_okada.ss.gz ftp://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/OkadaY_24390342_GCST002318/harmonised/24390342-GCST002318-EFO_0000685-Build37.f.tsv.gz mkdir Onengut wget -O Onengut/raw_onengut.ss.gz ftp://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/Onengut-GumuscuS_25751624_GCST005536/harmonised/25751624-GCST005536-EFO_0001359-Build37.f.tsv.gz mkdir Phelan wget -O Phelan/raw_phelan.ss.gz ftp://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/PhelanCM_28346442_GCST004462/harmonised/28346442-GCST004462-EFO_0001075-Build37.f.tsv.gz mkdir Schumacher wget -O Schumacher/raw_schumacher.ss.gz ftp://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/SchumacherFR_29892016_GCST006085/harmonised/29892016-GCST006085-EFO_0001663-build37.f.tsv.gz mkdir Tsoi wget -O Tsoi/raw_tsoi.ss.gz ftp://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/TsoiLC_23143594_GCST005527/harmonised/23143594-GCST005527-EFO_0000676-Build37.f.tsv.gz mkdir Rheenen wget -O Rheenen/raw_rheenen.ss.gz ftp://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/vanRheenenW_27455348_GCST004692/harmonised/27455348-GCST004692-EFO_0000253-build37.f.tsv.gz #Files that need to be harmonized mkdir Jin wget -O Jin/ ftp://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/JinY_30674883_GCST007111/JinY_PrePMID_GWAS123chr* mkdir Namjou wget -O Namjou/raw_namjou.ss ftp://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/NamjouB_31311600_GCST008468/NamjouB_31311600_NAFLD.txt mkdir Lopez wget -O Lopez/raw_lopez.ss ftp://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/Lopez-IsacE_31672989_GCST009131/Lopez-Isac_prePMID_META_GWAS_SSc.meta.txt mkdir Xie wget -O Xie/raw_xie.ss.gz ftp://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/XieJ_32231244_GCST010004/Trans-ethnic_GWAS_meta-analysis_without_replication.txt.gz mkdir Mahajan wget -O Mahajan/raw_mahajan.ss ftp://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/MahajanA_29632382_GCST007515/T2D_TranEthnic.BMIunadjusted.txt mkdir Shah wget -O Shah/raw_shah.ss.gz ftp://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/ShahS_31919418_GCST009541/ShahS_31919418_HeartFailure.gz mkdir Kottgen wget -O Kottgen/raw_kottgen.ss.gz ftp://ftp.ebi.ac.uk/pub/databases/gwas/ftp://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/KottgenA_23263486_GCST001790/GUGC_MetaAnalysis_Results_Gout.csv.zip #Note there is also data from 23andMe that needs to be processed This is basically just a series of wget’s to the FTP server of the GWAS catalog. I am also using some files from 23andMe, however these cannot be openly downloaded on GWAS Catalog. Lastly, a committee member of mine asked me to look into a few pyschiatric related traits, which has summary statistics available on request or within the pyschiatric genomics consortium (https://www.med.unc.edu/pgc/download-results/). While I likely could have followed a similar request approach to recieve a few more sets, the total number of 25 seems like a good stopping point. Figure 4.1: test If you want to manually download just one summary statistic, or you want a more pictoral description of the summary statistics then you can access https://www.ebi.ac.uk/gwas/downloads/summary-statistics . There are other GWAS results that are not fully summary statistics, as the motivation of this project is to assess different methods we want the full summary statistics for many SNPs, not just the signifiant ones. Plus, from the full summary statistics we can always reduce down to only a significant-only score. 4.1 Prepare Variants As we’ve already QCd the individuals, the other half of the QC is on the variants. That can be easily done by keeping variants that have an imputation INFO score above 0.9, and removing duplicate variants (or variants that are tri-allelic). The INFO score refers to the probability the imputation software has in calling the allele the way it did, we only want high probability variants. We do not want duplicate variants because its tri-allele option slightly increases the probability that it was called or otherwise referred to incorrectly at some point in its analysis. Moreover, the biology is likely more complicating (perhaps not agreeing with the assumptions of the downstream methods), and sorting gets easier. The other variant level of QC nescessary is on the minor allele frequency and hardy weinberg equilibrium, but we can do that after the white, british group has already be determined. Note that in other analyses this step could be done now, but with file formats as I have (bgen now, plink later), I will wait for this step. The script used to pull this off is as follows, where the ukb_mfi_all.txt file originates from the UKBB directly. #Reduce the full list of RSIDs to those with INFO score greater than 0.9 cat ~/athena/ukbiobank/qc/imputed/ukb_mfi_all.txt | awk &#39;$8 &gt; 0.9 {print $0}&#39; &gt; common_files/impute_rsids #Extract all of the duplicated RSIDs cat ~/athena/ukbiobank/qc/imputed/ukb_mfi_all.txt | cut -f2 | sort | uniq -d &gt; common_files/dup_ids #Remove the duplicated RSIDs from the full list of (INFO approved) SNPs cat common_files/impute_rsids | fgrep -w -v -f common_files/dup_ids &gt; common_files/temp mv common_files/temp common_files/impute_rsids 4.2 Standardize the Summary Statistics This is a big step. The underlying motivation is that all of the files need to look the same so downstream coding is far easier. In this process we will convert the base pair positions, or the genome build, so they match the UK Biobank. The can simply be done by matching the rsIDs. We will also remove ambigious SNPs, and then flip the remaining SNPs so they match the UK Biobank strand. The exact procedures, and a few other small changes are described in the script. library(vroom) library(stringr) library(bigsnpr) options(warn=2) #impute &lt;- as.data.frame(vroom(&quot;common_files/impute_rsids&quot;, col_names = F)) impute &lt;- read.table(&quot;common_files/impute_rsids&quot;, header = F, stringsAsFactors = F) colnames(impute) &lt;- c(&quot;LOC&quot;, &quot;SNP&quot;, &quot;POS&quot;, &quot;A1&quot;, &quot;A2&quot;, &quot;MAF&quot;, &quot;AX&quot;, &quot;INFO&quot;) #First remove SNPs where the base is longer than one allele #And make sure the SNP is either A, C, G, T #Remove ambigous SNPs, those where the bases are actually pairs impute &lt;- impute[nchar(impute$A1) == 1 &amp; nchar(impute$A2) == 1,] impute &lt;- impute[impute$A1 %in% c(&quot;A&quot;, &quot;C&quot;, &quot;G&quot;, &quot;T&quot;) &amp; impute$A2 %in% c(&quot;A&quot;, &quot;C&quot;, &quot;G&quot;, &quot;T&quot;),] impute &lt;- impute[!((impute$A1 == &quot;A&quot; &amp; impute$A2 == &quot;T&quot;) | (impute$A1 == &quot;T&quot; &amp; impute$A2 == &quot;A&quot;) | (impute$A1 == &quot;G&quot; &amp; impute$A2 == &quot;C&quot;) | (impute$A1 == &quot;C&quot; &amp; impute$A2 == &quot;G&quot;)),] adjust_ss &lt;- function(author){ #Start by reading in the summary statistics file and a parameters file that states the column #names of the desired columns #ss &lt;- as.data.frame(vroom(paste0(author, &quot;/raw_&quot;, tolower(author), &quot;.ss.gz&quot;))) ss &lt;- read.table(paste0(author, &quot;/raw_&quot;, tolower(author), &quot;.ss.gz&quot;), stringsAsFactors=F, header = T) params &lt;- read.table(paste0(author, &quot;/parameters&quot;), stringsAsFactors=F) system(paste0(&quot;echo clean notes &gt; &quot;, author, &quot;/clean.log&quot;)) system(paste0(&quot;echo after read: &quot;, nrow(ss), &quot; &gt;&gt; &quot;, author, &quot;/clean.log&quot;)) #Check if there are missing columns, and fill them in just so things don&#39;t go haywire below missing_cols &lt;- params[!(params[,1] %in% colnames(ss)),1] if(length(missing_cols) &gt; 0){ if(&quot;NO_CHR&quot; %in% missing_cols){ ss$NO_CHR &lt;- 0 } if(&quot;NO_POS&quot; %in% missing_cols){ ss$NO_POS &lt;- 0 } if(&quot;NO_SE&quot; %in% missing_cols){ ss$NO_SE &lt;- 0 } } #Construct a common ss object, with common column names based on the manually curated params ss &lt;- ss[,c(which(colnames(ss) == params[1,1]), which(colnames(ss) == params[2,1]), which(colnames(ss) == params[3,1]), which(colnames(ss) == params[4,1]), which(colnames(ss) == params[5,1]), which(colnames(ss) == params[6,1]), which(colnames(ss) == params[7,1]), which(colnames(ss) == params[8,1]))] colnames(ss) &lt;- c(&quot;CHR&quot;, &quot;BP&quot;, &quot;RSID&quot;, &quot;A1&quot;, &quot;A2&quot;, &quot;SE&quot;, &quot;BETA&quot;, &quot;P&quot;) ss$A1 &lt;- toupper(ss$A1) ss$A2 &lt;- toupper(ss$A2) ss &lt;- ss[!is.na(ss$RSID),] ss &lt;- ss[!is.na(ss$BETA),] ss &lt;- ss[!is.na(ss$P),] system(paste0(&quot;echo after remove NA: &quot;, nrow(ss), &quot; &gt;&gt; &quot;, author, &quot;/clean.log&quot;)) #Remove duplicate SNP IDs dup_ids &lt;- ss$RSID[duplicated(ss$RSID)] ss &lt;- ss[!(ss$RSID %in% dup_ids),] system(paste0(&quot;echo after remove duplicated IDs: &quot;, nrow(ss), &quot; &gt;&gt; &quot;, author, &quot;/clean.log&quot;)) #First remove SNPs where the base is longer than one allele #And make sure the SNP is either A, C, G, T #Remove ambigous SNPs, those where the bases are actually pairs ss &lt;- ss[nchar(ss$A1) == 1 &amp; nchar(ss$A2) == 1,] ss &lt;- ss[ss$A1 %in% c(&quot;A&quot;, &quot;C&quot;, &quot;G&quot;, &quot;T&quot;) &amp; ss$A2 %in% c(&quot;A&quot;, &quot;C&quot;, &quot;G&quot;, &quot;T&quot;),] system(paste0(&quot;echo after remove non ACGT SNPs: &quot;, nrow(ss), &quot; &gt;&gt; &quot;, author, &quot;/clean.log&quot;)) ss &lt;- ss[!((ss$A1 == &quot;A&quot; &amp; ss$A2 == &quot;T&quot;) | (ss$A1 == &quot;T&quot; &amp; ss$A2 == &quot;A&quot;) | (ss$A1 == &quot;G&quot; &amp; ss$A2 == &quot;C&quot;) | (ss$A1 == &quot;C&quot; &amp; ss$A2 == &quot;G&quot;)),] system(paste0(&quot;echo after remove ambigous SNPs: &quot;, nrow(ss), &quot; &gt;&gt; &quot;, author, &quot;/clean.log&quot;)) #Make sure the imputation reference and the ss objects have the same number of SNP IDs ss$RSID &lt;- tolower(ss$RSID) ss &lt;- ss[ss$RSID %in% impute$SNP,] sub_impute &lt;- impute[impute$SNP %in% ss$RSID,] system(paste0(&quot;echo after remove SNPs not in the UKBB imputation: &quot;, nrow(ss), &quot; &gt;&gt; &quot;, author, &quot;/clean.log&quot;)) if(nrow(ss) != nrow(sub_impute)){ print(&quot;SIZE MISMATCH&quot;) } #Extract the chromosomes from the imputation reference object #Sometimes the chromosome is not listed for an object #But since the rows seem to be ordered we can impute the chromosome based on the surrounding chromosomes chr &lt;- sapply(strsplit(sub_impute[,1], &quot;:&quot;), function(x) x[[1]]) for(i in as.character(1:22)){ if(i %in% chr){ min_ind &lt;- min(which(chr==i)) max_ind &lt;- max(which(chr==i)) chr[min_ind:max_ind] &lt;- i } } #Finish cleaning up the chr, because &quot;X&quot; could be there instead of 23 chr[!(chr %in% as.character(1:22))] &lt;- &quot;23&quot; chr &lt;- as.numeric(chr) #Sort the imputation reference and the ss objects so they are the same order #Then assign the imputation chr and pos to the ss object ss &lt;- ss[order(ss$RSID)[rank(sub_impute$SNP)],] ss &lt;- ss[order(chr, sub_impute$POS),] sub_impute &lt;- sub_impute[order(chr, sub_impute$POS),] chr &lt;- chr[order(chr)] #make the ss object chromosome and position the same as the imputed object ss$CHR &lt;- chr ss$BP &lt;- sub_impute$POS #If there is a name in the parameters that states CHANGE_BOTH assuming that it&#39;s not BETA but OR #This would just be a simple exponentiation if(nrow(params) &gt; 8){ if(params[9,1] == &quot;CHANGE_BOTH&quot;){ #will assume that the effect name is for odds ratio #following the walds ratio tests can just switch things over assuming a normal distribution #This may not be exactly what was completed in the published GWAS, but it should be a good approximation #And few methods seem to use the SE column anyway ss$BETA &lt;- log(ss$BETA) ss$SE &lt;- abs(ss$BETA/qnorm(ss$P)) } } #use the bignspr function to flip and reverse the summmary statistics colnames(ss) &lt;- c(&quot;chr&quot;, &quot;pos&quot;, &quot;rsid&quot;, &quot;a0&quot;, &quot;a1&quot;, &quot;beta_set&quot;, &quot;beta&quot;, &quot;p&quot;) save_impute_cols &lt;- colnames(sub_impute) colnames(sub_impute) &lt;- c(&quot;loc&quot;, &quot;rsid&quot;, &quot;pos&quot;, &quot;a0&quot;, &quot;a1&quot;, &quot;maf&quot;, &quot;ax&quot;, &quot;info&quot;) sub_impute$chr &lt;- ss$chr ss &lt;- snp_match(ss, sub_impute) ss &lt;- ss[,c(1,2,5,3,4,6,7,8)] colnames(ss) &lt;- c(&quot;CHR&quot;, &quot;BP&quot;, &quot;RSID&quot;, &quot;A1&quot;, &quot;A2&quot;, &quot;SE&quot;, &quot;BETA&quot;, &quot;P&quot;) colnames(sub_impute) &lt;- save_impute_cols system(paste0(&quot;echo after removing SNPs that do not flip: &quot;, nrow(ss), &quot; &gt;&gt; &quot;, author, &quot;/clean.log&quot;)) #Finally add in effective sample size, as defined by PLINK notes &lt;- read.table(paste0(author, &quot;/notes&quot;), sep = &#39;\\t&#39;, stringsAsFactors=F) ss$ESS &lt;- round(4/(1/as.numeric(notes[4,1]) + 1/as.numeric(notes[5,1]))) #According to LDPRED-2 it is a good idea to compare to a validation set following: sd_ss &lt;- 2/(ss$SE * sqrt(ss$ESS)) #For the validation set I will use summary statistics from the FinnGen Biobank #First I have to go through several steps to line everything up finn_notes &lt;- read.table(&quot;../finngen_ss/sample_size&quot;, stringsAsFactors=F) if(author %in% finn_notes[,4]){ finn_ess &lt;- 4/((1/finn_notes[finn_notes[,4] == author,2]) + (1/finn_notes[finn_notes[,4] == author,3])) finn_pheno &lt;- finn_notes[finn_notes[,4] == author,1] finn_ss &lt;- read.table(paste0(&quot;../finngen_ss/summary_stats_finngen_r3_&quot;, finn_pheno, &quot;.gz&quot;), header =F, stringsAsFactors=F, sep = &#39;\\t&#39;) finn_ss &lt;- finn_ss[finn_ss[,5] %in% ss$RSID,] dup_rs &lt;- finn_ss[duplicated(finn_ss[,5]), 5] finn_ss &lt;- finn_ss[!finn_ss[,5] %in% dup_rs,] finn_rs &lt;- finn_ss[,5] finn_sd &lt;- finn_ss[,9] finn_sd &lt;- c(finn_sd, rep(0, (nrow(ss) - length(finn_rs)))) finn_rs &lt;- c(finn_rs, ss$RSID[!(ss$RSID %in% finn_rs)]) finn_sd &lt;- finn_sd[order(finn_rs)[rank(ss$RSID)]] finn_sd &lt;- 2/(finn_sd * sqrt(finn_ess)) good_rs &lt;- ss$RSID[sd_ss &lt; 2 * finn_sd &amp; sd_ss &gt; 0.5 * finn_sd] good_rs &lt;- c(good_rs, ss$RSID[finn_sd == Inf]) ss &lt;- ss[ss$RSID %in% good_rs,] } system(paste0(&quot;echo after removing SNPs that do not align with FinnGen: &quot;, nrow(ss), &quot; &gt;&gt; &quot;, author, &quot;/clean.log&quot;)) #Now write the answer write.table(ss, paste0(author, &quot;/clean_&quot;, tolower(author), &quot;.txt&quot;), row.names = F, col.names = T, sep = &#39;\\t&#39;, quote = F) system(paste0(&quot;gzip &quot;, author, &quot;/clean_&quot;, tolower(author), &quot;.txt&quot;)) } all_authors &lt;- read.table(&quot;common_files/list_authors&quot;, stringsAsFactors=F) for(author in all_authors[,1]){ print(author) adjust_ss(author) } As you can see at the bottom of the script I am looping over all of the sets of summary statistics, which are organized so each set belongs to its own directory with the name raw_author.ss.gz. Also within the directory are two files, “notes” and “parameters”. The notes files contains some meta-information and the parameters names the column names referring to a different statistic or type of information. Specifically “notes” contains with each new line: author name, disease name, total sample size, case sample size, control sample size, ancestry of GWAS and title of originating publication. Specifically “parameters” contains the chromosome, base pair location, rs prefixed variant ID, effect allele (or first allele), non-effect allele (or second allele), standard error of the effect, effect, and p value. There is an optional ninth line with the term CHANGE_BOTH which indicates the effect is an odds ratio and needs to be converted to a beta values (spanning from negative to positive). With the script read in for reference, I want to clearly list everything that I am kicking out of the summary statistics. To do this I will call examples from the Phelan summary statistics. The raw download appears as: ss &lt;- read.table(&quot;../raw_ss/Phelan/raw_phelan.ss.gz&quot;, stringsAsFactors=F, header=T, nrows = 10) head(ss) ## rsid Chromosome Position Effect Baseline EAF ## 1 rs145072688 1 10352 TA T 0.42360 ## 2 rs376342519 1 10616 C CCGCCGTTGCAAAGGCGCGCCG 0.99100 ## 3 rs201725126 1 13116 G T 0.17040 ## 4 rs200579949 1 13118 G A 0.17040 ## 5 rs75454623 1 14930 G A 0.52060 ## 6 rs199856693 1 14933 A G 0.04797 ## R2_oncoarray overall_OR overall_SE overall_chi2 overall_pvalue ## 1 0.4713 -0.019590 0.02150 0.83020 0.3622 ## 2 0.8243 0.013190 0.09657 0.01867 0.8913 ## 3 0.3866 0.006643 0.02865 0.05375 0.8167 ## 4 0.3866 0.006643 0.02865 0.05375 0.8167 ## 5 0.4054 0.022960 0.02127 1.16500 0.2804 ## 6 0.3547 0.070590 0.06168 1.31000 0.2524 INFO Score &lt; 0.9 - only want alleles whose identity are certain Non-duplicate - want simple base subsititions that are easier to call and process ss &lt;- read.table(&quot;../raw_ss/Phelan/raw_phelan.ss.gz&quot;, stringsAsFactors=F, header=F, skip = 629730, nrows = 2) print(ss) ## V1 V2 V3 V4 V5 V6 V7 V8 V9 V10 V11 ## 1 rs7517916 1 109370390 A C 0.2888 0.7717 -0.046220 0.01603 8.3130 0.003937 ## 2 rs7517916 1 109370390 G C 0.3199 0.8600 0.009952 0.01498 0.4416 0.506400 We can see the SNP rs7517916 is tri-allelic, with alleles A, C, G. As this tri-system makes calling more difficult, and strand determination near impossible we discard this SNP altogether. ACGT - similar to above, limiting to the most simple cases of base pair subtitition or single nucleotide polymorphism ss &lt;- read.table(&quot;../raw_ss/Phelan/raw_phelan.ss.gz&quot;, stringsAsFactors=F, header=F, skip = 1, nrows = 2) print(ss) ## V1 V2 V3 V4 V5 V6 V7 V8 V9 ## 1 rs145072688 1 10352 TA T 0.4236 0.4713 -0.01959 0.02150 ## 2 rs376342519 1 10616 C CCGCCGTTGCAAAGGCGCGCCG 0.9910 0.8243 0.01319 0.09657 ## V10 V11 ## 1 0.83020 0.3622 ## 2 0.01867 0.8913 Here we have two clear examples of SNPs whose alleles are not just A, C, G, T. This paradigm does not work with our strand flipping capabilities (and is harder to call by most sequencing technologies) so we again discard these types of SNPs. Non-ambigous - If the alleles are A and T or C and G, these are called ambigous and will present a problem later on when we try to determine if the standedness of the summary statistics match the strand of our data. This is likely possibly to figure out through allele frequencies, but again, it’s not worth the risk ss &lt;- read.table(&quot;../raw_ss/Phelan/raw_phelan.ss.gz&quot;, stringsAsFactors=F, header=F, skip = 9, nrows = 1) print(ss) ## V1 V2 V3 V4 V5 V6 V7 V8 V9 V10 V11 ## 1 rs201931625 1 15274 TRUE A 0.6996 0.432 0.00715 0.02451 0.08508 0.7705 The two alleles described are T and A. As stated, since flipping these alleles leaves us where we started we must again discard this SNP since flipping is impossible. Non-X chromosome - As chromosome 23 is very different between men and women (and it’s relatively short), we would likely have to do some special case regressions to set up an accurate model, which makes it easiest just to forget it. Note, no example in Phelan but if it did exist the chromosome column would be X, Y or 23. Non-reversable SNPs - We need to flip (or reverse) SNPs such that the allele identities of the summary statistics match the allele identities of the genotypes. We do this by assuming that if they do not line up then we can swap A with T, or C with G (and the converse), and things will work. However, if just one of the SNPs matches after reversing then we have a weird problem that is easiest to resolve by removing the troublesome SNP. sst &lt;- read.table(&quot;../raw_ss/Phelan/raw_phelan.ss.gz&quot;, stringsAsFactors=F, header=F, skip = 280, nrows = 1) ref &lt;- read.table(&quot;../raw_ss/common_files/impute_rsids&quot;, stringsAsFactors=F, header=F, skip = 5995727, nrow = 1) print(sst) ## V1 V2 V3 V4 V5 V6 V7 V8 V9 V10 V11 ## 1 rs12184267 1 715265 TRUE C 0.04354 0.371 0.01388 0.05711 0.05906 0.808 print(ref) ## V1 V2 V3 V4 V5 V6 V7 V8 ## 1 1:715265_C_T rs12184267 715265 C TRUE 0.0366377 TRUE 0.926915 This is an example of reversed SNPs, the A1 of the summary statistic does not match the A1 of the reference data. Therefore we swap the position of the alleles in the summary statistics and similarly reverse the beta or effect value. sst &lt;- read.table(&quot;../raw_ss/Phelan/raw_phelan.ss.gz&quot;, stringsAsFactors=F, header=F, skip = 375350, nrows = 1) ref &lt;- read.table(&quot;../raw_ss/common_files/impute_rsids&quot;, stringsAsFactors=F, header=F, skip = 6358575, nrow = 1) print(sst) ## V1 V2 V3 V4 V5 V6 V7 V8 V9 V10 V11 ## 1 rs1390473 1 64804379 TRUE C 0.001289 -99 0.4462 1.128 0.1566 0.6923 print(ref) ## V1 V2 V3 V4 V5 V6 V7 V8 ## 1 1:64804379_A_G rs1390473 64804379 A G 0.00451314 A 0.934127 This is an example of a SNP that needs to be flipped since the summary statistic is on one strand while the complementary base pairs are described in the reference data. In this case the beta or effect value stays the same because the same information is being described in both the summary statistic and reference data, just not using the same language or strand. sst &lt;- read.table(&quot;../raw_ss/Phelan/raw_phelan.ss.gz&quot;, stringsAsFactors=F, header=F, skip = 15414049, nrows = 1) ref &lt;- read.table(&quot;../raw_ss/common_files/impute_rsids&quot;, stringsAsFactors=F, header=F, skip = 7679970, nrow = 1) print(sst) ## V1 V2 V3 V4 V5 V6 V7 V8 V9 V10 V11 ## 1 rs8120968 20 61831053 TRUE G 4.62e-05 0.5318 0.8177 1.37 0.3563 0.5506 print(ref) ## V1 V2 V3 V4 V5 V6 V7 V8 ## 1 20:61831053_G_A rs8120968 61831053 G A 0.00120068 A 0.926685 This is an example of a SNP that is not resolved after either flipping or reversing. In short, the G allele appears to be on the reference stand but the T allele does not. With this confusion we decide to play it safe and discard the SNP altogether. Standard error outliers - Following the supplementary of the method LDPRED2, we can compare standard errors between studies to determine if SNPs are outliers in their effects. For this task I have pulled results from FinnGen Biobank, which while not matching ancestry well with British, does a decent enough job of falling within the European category to work. The remaining steps mostly involve re-aligning, changing column names and the like. Note that we take such a liberal stance on removing SNPs because we assume there is a density of summary statistics such that the removal of any SNP will still leave behind another SNP within a given causal locus that is ultimately important for prediction. 4.3 Heritability Estimation Many downstream methods require heritability estimates of the trait using the corresponding summary statistics. While many, many heritability estimate methods exist I am limited to those that only require summary statistics, of which I know of 2: Linkage Disequilibirum Score Regression and High-Definition Likelihood (HDL). The first step required is to munge the summary statistics, or further QC them following a munge_sumstats script provided by LDSC. The script for which is simple: cat common_files/list_authors | while read author;do low_author=`echo &quot;$author&quot; | tr &#39;[:upper:]&#39; &#39;[:lower:]&#39;` munge_sumstats --sumstats ${author}/clean_${low_author}.txt.gz --N-col ESS --out ${author}/${low_author}.munged done The next step is the actual heritability estimation, which luckily only requires a simple command line call for each method. We do have to be careful however in making sure all of the columns match up in the arguments. The script therefore looks like: cat common_files/list_authors | while read author;do #author=Tsoi low_author=`echo &quot;$author&quot; | tr &#39;[:upper:]&#39; &#39;[:lower:]&#39;` ldsc --h2 ${author}/${low_author}.munged.sumstats.gz --ref-ld-chr ~/athena/refs/eur_w_ld_chr/ --w-ld-chr ~/athena/refs/eur_w_ld_chr/ --out ${author}/${low_author}.h2 Rscript ~/Programs/HDL/HDL.run.R \\ gwas.df=${author}/${low_author}.munged.sumstats.gz \\ LD.path=~/athena/refs/UKB_imputed_SVD_eigen99_extraction \\ output.file=${author}/${low_author}.HDL.h2.Rout done We can compile all of the heritability estimates, which are currently sitting in log files, into a single file using a simple bash script. Additionaly, we can include other useful information that may be needed downstream, such as sample size and number of SNPs. The script looks like: echo author,trait,sampe_size,cases,controls,ancestry,snps,ldsc_h2,ldsc_h2_se,hdl_h2,hdl_h2se &gt; meta_stats cat common_files/list_authors | while read author;do low_author=`echo &quot;$author&quot; | tr &#39;[:upper:]&#39; &#39;[:lower:]&#39;` trait=`cat ${author}/notes | head -2 | tail -1` samp_size=`cat ${author}/notes | head -3 | tail -1` cases=`cat ${author}/notes | head -4 | tail -1` controls=`cat ${author}/notes | head -5 | tail -1` ancestry=`cat ${author}/notes | head -6 | tail -1` snps=`zcat ${author}/clean_${low_author}.txt.gz | wc -l` ldsc_h2=`cat ${author}/${low_author}.h2.log | fgrep &quot;scale h2&quot; | cut -f2 -d&#39;:&#39; | cut -f2 -d&#39; &#39;` ldsc_h2se=`cat ${author}/${low_author}.h2.log | fgrep &quot;scale h2&quot; | cut -f2 -d&#39;:&#39; | cut -f3 -d&#39; &#39; | cut -f2 -d&#39;(&#39; | cut -f1 -d&#39;)&#39;` hdl_h2=`cat ${author}/${low_author}.HDL.h2.Rout | fgrep Heritability | cut -f6 -d&#39; &#39;` hdl_h2se=`cat ${author}/${low_author}.HDL.h2.Rout | fgrep Heritability | cut -f7 -d&#39; &#39; | cut -f2 -d&#39;(&#39; | cut -f1 -d&#39;)&#39;` echo $author,$trait,$samp_size,$cases,$controls,$ancestry,$snps,$ldsc_h2,$ldsc_h2se,$hdl_h2,$hdl_h2se &gt;&gt; meta_stats done The only problem is that we still do not have a single heritability value to use downstream. We can fix this problem by conducting a very simple meta-analysis. We average the estimates inversely weighted by their standard errors. If one of the algorithms did not converge on a set of summary statistics then the other algorithms value stands without any averaging. If both alogortihms failed the value of 0.01, is assumed. This last part is somewhat arbritrary but I figured a low estimate would be best. The script used to perform this basic meta-analysis looks like: info &lt;- read.csv(&quot;meta_stats&quot;, stringsAsFactors=F, header=T) info$hdl_h2[grepl(&quot;was&quot;, info$hdl_h2)] &lt;- 0 info$hdl_h2se[grepl(&quot;estimated&quot;, info$hdl_h2se)] &lt;- 0 info$hdl_h2 &lt;- as.numeric(info$hdl_h2) info$hdl_h2se &lt;- as.numeric(info$hdl_h2se) weights &lt;- cbind(1/info$ldsc_h2_se, 1/info$hdl_h2se)/rowSums(cbind(1/info$ldsc_h2_se, 1/info$hdl_h2se)) new_h2 &lt;- rowSums(cbind(info$ldsc_h2, info$hdl_h2) * weights) final_h2 &lt;- rep(0, nrow(info)) final_h2[info$hdl_h2 == 0] &lt;- info$ldsc_h2[info$hdl_h2 == 0] final_h2[info$ldsc_h2 &lt; 0 | info$ldsc_h2 &gt; 1] &lt;- info$hdl_h2[info$ldsc_h2 &lt; 0 | info$ldsc_h2 &gt; 1] final_h2[final_h2 == 0] &lt;- new_h2[final_h2 == 0] final_h2[is.nan(final_h2)] &lt;- 0.01 info$h2 &lt;- final_h2 write.table(info, &quot;meta_stats&quot;, row.names = F, col.names = T, quote = F, sep = &#39;,&#39;) 4.4 Genetic Correlation Estimation One method, smtpred, requires estimation of genetic correlation. Along with the motivation this is just good information to know and plot later on, I will now go through the process of calculating pairwide genetic correlations. Luckily for us this process is quite similar to the heritability estimation above, although I should note the process is quite slower. Because I have two methods that run in two different environments I wrote two scripts this time to execute each. #double for loop to get pairwise correlations #always remember to load the right python environment cat common_files/temp_authors | while read author;do cat common_files/list_authors | while read sec_author;do low_author=`echo &quot;$author&quot; | tr &#39;[:upper:]&#39; &#39;[:lower:]&#39;` o_author=`echo &quot;$sec_author&quot; | tr &#39;[:upper:]&#39; &#39;[:lower:]&#39;` ldsc --rg ${author}/${low_author}.munged.sumstats.gz,${sec_author}/${o_author}.munged.sumstats.gz --ref-ld-chr ~/athena/refs/eur_w_ld_chr/ --w-ld-chr ~/athena/refs/eur_w_ld_chr/ --out gen_corr/ldsc/${low_author}.${o_author}.corr done done and the other is: library(HDL) all_authors &lt;- read.table(&quot;common_files/list_authors&quot;, stringsAsFactors = F) gwas_files &lt;- list() LD.path &lt;- &quot;~/athena/refs/UKB_imputed_SVD_eigen99_extraction/&quot; # read in all of the authors once up top i &lt;- 1 for(author in all_authors[,1]){ low_author &lt;- tolower(author) gwas_files[[i]] &lt;- read.table(paste0(author, &quot;/&quot;, low_author, &quot;.munged.sumstats.gz&quot;), stringsAsFactors=F, header=T) i &lt;- i + 1 } # create a doule for loop to get pairwise correlations for(i in 12:length(gwas_files)){ for(j in 1:length(gwas_files)){ if(i != j &amp; (!(i == 12 &amp; j %in% 1:24))){ #I was having some trouble completing some calculations so I would manually set this change res.HDL &lt;- HDL.rg(gwas_files[[i]], gwas_files[[j]], LD.path) write.table(res.HDL$estimates.df, paste0(&quot;gen_corr/hdl/&quot;, tolower(all_authors[i,1]), &quot;.&quot;, tolower(all_authors[j,1]), &quot;.corr.log&quot;), row.names = T, col.names = T, quote = F) } } } Once complete, try to find all of the possible log files that would be made and pull out the key line with the genetic correlation value and its stanadard error, writing to a new long file. rm genetic_correlations cat common_files/list_authors | while read fauth1;do cat common_files/list_authors | while read fauth2;do auth1=`echo &quot;$fauth1&quot; | tr &#39;[:upper:]&#39; &#39;[:lower:]&#39;` auth2=`echo &quot;$fauth2&quot; | tr &#39;[:upper:]&#39; &#39;[:lower:]&#39;` if [ -e gen_corr/ldsc/${auth1}.${auth2}.corr.log ];then rg_ldsc=`cat gen_corr/ldsc/${auth1}.${auth2}.corr.log | fgrep &quot;Genetic Correlation:&quot; | cut -f3 -d&#39; &#39;` se_ldsc=`cat gen_corr/ldsc/${auth1}.${auth2}.corr.log | fgrep &quot;Genetic Correlation:&quot; | cut -f4 -d&#39; &#39; | cut -f2 -d&#39;(&#39; | cut -f1 -d&#39;)&#39;` else rg_ldsc=NA se_ldsc=NA fi if [ -e gen_corr/hdl/${auth1}.${auth2}.corr.log ];then rg_hdl=`cat gen_corr/hdl/${auth1}.${auth2}.corr.log | fgrep Correlation | cut -f2 -d&#39; &#39;` se_hdl=`cat gen_corr/hdl/${auth1}.${auth2}.corr.log | fgrep Correlation | cut -f3 -d&#39; &#39;` else rg_hdl=NA se_hdl=NA fi echo $auth1 $auth2 $rg_ldsc $se_ldsc $rg_hdl $se_hdl &gt;&gt; genetic_correlations done done Lastly, we need to go through like before and create just one genetic correlation value from our two estimates. As before, we will average two estimates (if they exist), based on their inverse standard error. Whereas before we were not fine with having an NA value, here that is totally fine. Other non-finite values such as Inf or NaN might also be passed on, that’s fine for now and we will deal with it later on as needed. gencorr &lt;- read.table(&quot;genetic_correlations&quot;, stringsAsFactors=F, fill = T) gencorr$avg &lt;- NA gencorr$se &lt;- NA for(i in 1:nrow(gencorr)){ if(is.finite(gencorr[i,3]) &amp; is.finite(gencorr[i,5])){ weights &lt;- c(1/gencorr[i,4], 1/gencorr[i,6]) / sum(c(1/gencorr[i,4], 1/gencorr[i,6])) gencorr$avg[i] &lt;- sum(c(gencorr[i,3], gencorr[i,5]) * weights) gencorr$se[i] &lt;- sum(c(gencorr[i,4], gencorr[i,6]) * weights) } else if(is.finite(gencorr[i,3])){ gencorr$avg[i] &lt;- gencorr[i,3] gencorr$se[i] &lt;- gencorr[i,4] } else if(is.finite(gencorr[i,5])){ gencorr$avg[i] &lt;- gencorr[i,5] gencorr$se[i] &lt;- gencorr[i,6] } } write.table(gencorr, &quot;genetic_correlations&quot;, row.names = F, col.names = F, sep = &#39;\\t&#39;, quote = F) 4.5 Final Changes and Remarks The last thing to do is to split the polished and cleaned summary statistics into chromosome chunks. This way we can process each chromosome seperately and everything will run much more easily. The script to do this looks like: cat common_files/list_authors | while read author;do low_author=`echo &quot;$author&quot; | tr &#39;[:upper:]&#39; &#39;[:lower:]&#39;` mkdir ${author}/chr_ss for chr in {1..23};do zcat ${author}/clean_${low_author}.txt.gz | head -1 &gt; ${author}/chr_ss/${low_author}_${chr}.ss zcat ${author}/clean_${low_author}.txt.gz | awk -v var=&quot;$chr&quot; &#39;$1 == var {print $0}&#39; &gt;&gt; ${author}/chr_ss/${low_author}_${chr}.ss gzip ${author}/chr_ss/${low_author}_${chr}.ss done done We could also do this as we process the summary statistics files, but I personally like having the files around like this and don’t mind the memory needed to store them. We are almost officialy done with QC (remember we still need to look at MAF and HWE). This QC aimed to be on the stringent side to ensure we have good information going into the downstream methods. "],["adjusting-summary-statistics.html", "5 Adjusting Summary Statistics 5.1 Simple 5.2 Clumping 5.3 Double Weight 5.4 LDpred 5.5 LDpred2 5.6 SBLUP 5.7 SMTpred 5.8 prsCS 5.9 lassosum 5.10 Tweedie 5.11 SBayesR 5.12 JAMPred 5.13 Winner’s Curse Lasso 5.14 Winner’s Curse Likelihood 5.15 Winner’s Curse 2D", " 5 Adjusting Summary Statistics The main thrust of this project, and a key step in any polygenic risk scoring process, is adjusting summary statistics. In short, adjusting summary statistics are nescessary because as they stand linkage disequilibrium and a possible high prevelance of false positives will severly limit the predictive ability contained within the underlying GWAS. There are many ways to actually carry out this adjustment. In fact, there are quite a few people who have spent considerable time working on methods to adjust summary statistics with the highest possible accuracy. The problem is that these people do not always leave the greatest doccumentation or instructions. In the following text I will attempt to translate the doccumentation, while pulling from the original publication and possible other sources, to produce a clear and intended scripts for summary statistic adjustment. 5.0.1 Computational Framework A key consideration in setting up a summary statistic adjustment workflow is time. Many of the adjustment scripts are slow. Therefore, parallelization is a near nescessity to get things done. While I am sure there are fancy systems or clever linux commands, I went with a low-tech bash script. The key idea of the bash script is that it continously runs, beginning a summary statistic adjustment on one chromosome with one method when there is space available. The space determination is made by constantly checking a poss_dirs file. If there is a directory number within a script is begun in the background for adjustment. On its completion it will return the name of its directory to the poss_dirs file. In the mean time a while loop with a wait function keeps everything active until this time comes. The other important consideration is independence. At the top of this script directories that contain intermediate files are emptied, leaving room for a clean starting place. maxDirs=8 rm temp_files/* rm logs/* rm done_check/* rm -r comp_zone/* for (( i=1; i&lt;=$maxDirs; i++ )); do mkdir comp_zone/dir$i echo $i &gt;&gt; temp_files/poss_dirs done cat all_specs/chr_specs | while read chr; do cat all_specs/author_specs | while read author; do ./setup_data.sh $author $chr cat all_specs/method_specs | while read method; do echo about to hermes ./hermes.sh $chr $method $author &amp;&gt; logs/${author}.${chr}.${method}.log &amp; sleep $(( ( RANDOM % 30 ) + 1 )) goOn=False while [ $goOn == &quot;False&quot; ]; do openSlots=`cat temp_files/poss_dirs | wc -l` if [ $openSlots -gt 0 ]; then echo NOW WE CAN GO goOn=True else echo MUST WAIT FOR ROOM TO GO sleep $(( ( RANDOM % 30 ) + 1 )) openSlots=`cat temp_files/poss_dirs | wc -l` fi done done ./check_to_delete.sh done done Note that if instead of having a multi-score laptop or other large computer you have a cluster submission system you can likely change this script slightly so that hermes.sh is not submitted to the background but instead is just submitted to your cluster management system. Perhaps I will write this option in soon. #Should have some sort of graphic indicating what is going on As can be seen, the actual adjustment is launched through the script hermes.sh (an ode to swift completion). At the top of hermes.sh some quick file re-writing claims the directory, and therefore slot to run an adjustment. Then the method specific script is called. An important consideration is the taskset command, which will limit the descrending computation to a select number of clusters. Finally, once the method is complete the directory name is returned to poss_dirs and the directory that contained all of the computation is emptied. Just as before everything was a wrapper for hermes.sh, here everything is a wrapper for the details within the method specific script. 5.1 Simple The simple methods are not really methods at all, but rather the most primitive subsetting that has been considered in the past and therefore for the sake of completeness will be considered here as well. Specifically, these methods simply threshold the summary statistics based on a p-value cut off. The first uses the genome-wide signficance threshold of 5e-8, the second uses the sometimes cited genome-wide interesting or suggested level of 1e-6, the third keeps every SNP possible, and the fourth keeps SNPs with p-values above 0.5. The idea is that the final method can act as a false negative, i.e. if it returns any predictive value we know something is likely going wrong. chr=$1 author=$2 dir=$3 low_author=`echo &quot;$author&quot; | tr &#39;[:upper:]&#39; &#39;[:lower:]&#39;` d=comp_zone/dir${dir} if [ ! -e ~/athena/doc_score/mod_sets/${author}/${low_author}.simple.1.ss ]; then cat temp_files/ss.${low_author}.${chr} | awk &#39;$8 &lt; 5e-8 {print $0}&#39; &gt; ~/athena/doc_score/mod_sets/${author}/${low_author}.${chr}.simple.1.ss fi if [ ! -e ~/athena/doc_score/mod_sets/${author}/${low_author}.simple.2.ss ]; then cat temp_files/ss.${low_author}.${chr} | awk &#39;$8 &lt; 1e-6 {print $0}&#39; &gt; ~/athena/doc_score/mod_sets/${author}/${low_author}.${chr}.simple.2.ss fi if [ ! -e ~/athena/doc_score/mod_sets/${author}/${low_author}.simple.3.ss ]; then cat temp_files/ss.${low_author}.${chr} &gt; ~/athena/doc_score/mod_sets/${author}/${low_author}.${chr}.simple.3.ss fi if [ ! -e ~/athena/doc_score/mod_sets/${author}/${low_author}.simple.4.ss ]; then cat temp_files/ss.${low_author}.${chr} | awk &#39;$8 &gt; 0.5 {print $0}&#39; &gt; ~/athena/doc_score/mod_sets/${author}/${low_author}.${chr}.simple.4.ss fi Note there is not any single publication or doccumentation linked to these “methods”, they are just a natural starting place for making scores. 5.2 Clumping The next, most common method involves clumping, which is an intelligent method to threshold SNPs based on their p-value while limiting false positives caused by linkage disequilibrium. Specifically, this is done by limiting a significant locus to maintaining only one SNP in the adjusted summary statistics. The size of this locus is determined by a r-squared parameter. While it is likely possible to write your own clumping algorithm, I and I assume most other people use PLINK, a tool with amazing doccumentation. The two obvious clumping parameters are the p-value and r2. An array of 3 values for each are chosen, leading to 9 total clumped summary statistics. The final parameter is the genotype file that generated the LD information. Many methods that I will be using require LD information. Frustratingly, the exact choice of LD information often varies based on the originating publication. As there is actually not any publication to specifically go along with clump the choice here is not well-informed. I have assumed using the UKBB is a good choice, and because it is computationally easy to do so I will employ the full possible sample size. A final consideration that is not always apparent is that sometimes the clumping algorithm leaves zero SNPs. In this case we need an if statement to reveal that nothing should be done. If there are SNPs remaining then we simply subset the input to these SNPs and pass them on. chr=$1 author=$2 dir=$3 low_author=`echo &quot;$author&quot; | tr &#39;[:upper:]&#39; &#39;[:lower:]&#39;` d=comp_zone/dir${dir} i=1 cat all_specs/clump_param_specs | tail -n +2 | while read spec;do plim=`echo $spec | cut -f1 -d&#39; &#39;` r2lim=`echo $spec | cut -f2 -d&#39; &#39;` if [ ! -e ~/athena/doc_score/mod_sets/${author}/${low_author}.clump.${i}.ss ]; then plink --memory 4000 --threads 1 --bfile geno_files/${low_author}.${chr} --clump temp_files/ss.${low_author}.${chr} --clump-snp-field RSID --clump-p1 $plim --clump-r2 $r2lim --out ${d}/out if [ -f ${d}/out.clumped ]; then sed -e &#39;s/ [ ]*/\\t/g&#39; ${d}/out.clumped | sed &#39;/^\\s*$/d&#39; | cut -f4 | tail -n +2 &gt; ${d}/done_rsids fgrep -w -f ${d}/done_rsids temp_files/ss.${low_author}.${chr} &gt; ~/athena/doc_score/mod_sets/${author}/${low_author}.${chr}.clump.${i}.ss fi fi let i=i+1 done More specifics on the doccumentation are described: https://www.cog-genomics.org/plink/1.9/postproc#clump 5.3 Double Weight Increasing from complexity is double weight scores. The motivation is that whenever a hard threshold is chosen the SNPs that are included within the score are hit by a winner’s curse. The corresponding publication explains “by selecting only SNPs with estimated p-values below a certain threshold, one systematically selects SNPs with effect overestimated by chance. Thus, for a large proportion of selected SNPs, betas will be a biased estimate for the true weight”. Mathematically we can think about this comparing the current polygenic risk score format: \\[PGS=\\sum_{i=1}^{k}I(p_i&lt;p^*)\\hat{\\beta}X_i\\] to a winner’s curse aware format: \\[PGS=\\sum_{i=1}^{k}\\hat{\\pi}(X_i)\\hat{\\beta}X_i\\] Here we replace an indicator function that is either 0 or 1 with a probability of inclusion within a set of top Z number SNPs, where Z can be any positive integer less than your total number of available SNPs. The next decision is determining how to calculate the \\(\\hat{\\pi}\\) term. The originating paper, within the supplementary states we should generate a sample of values for each SNP from a normal distribution specificed by \\(N(\\hat{\\beta}, \\hat{SE}^2)\\) (or at least that’s how I interpreted the variable definitions). We then estimate how many times our sample for the SNP is within the top Z number of SNPs. The paper goes onto to mention a wald type statistic, but I could not fully determine how one would best calculate this statistic. The approach I took is likely best described within the following R script. args &lt;- commandArgs(trailingOnly=TRUE) d &lt;- args[1] top_choice &lt;- args[2] #must make sure the number of requested top ranks SNPs is less than the total number of available SNPs ss &lt;- read.table(paste0(d, &quot;/specific_ss&quot;), stringsAsFactors=F) if(top_choice &lt; nrow(ss)){ #construct a matrix with ncols = number of SNPs, nrows = 100 (sample size for each SNP) norm_samples &lt;- apply(ss, 1, function(x) rnorm(100, mean = as.numeric(x[7]), sd = as.numeric(x[6]))) #for each snp generate a rank of the SNP, note that the dimensions are now swapped from above rank_samples &lt;- apply(norm_samples, 1, function(x) rank(x * -1)) #calculate the number of time for each SNP the rank is less than the desired top number of SNPs prob_ranks &lt;- apply(rank_samples, 1, function(x) sum(x &lt; top_choice)/nrow(rank_samples)) #multiple the normal beta values by the winner&#39;s curse probability to get an updated beta value ss[,7] &lt;- ss[,7] * prob_ranks write.table(ss, paste0(d, &quot;/adjust_ss&quot;), col.names = F, row.names = F, sep = &#39;\\t&#39;, quote = F) } Note that this R script is just launched by a short shell script. While short one key component is the PLINK line that subsets the summary statistics to a short subset whose SNPs are ideally not impacted by linkage disequillibrium. The exact parameters utilized are 0.5 for the p-value and 0.05 for R2. In both of the publications I could find that have implemeted this algorithm these are the paramters that were utilized. I therefore did not find the need to change them, especially since their values are not as intrinsic to the idea of double weighting as the parameter of Z important SNPs. There may be a variation that more fully agrees with the intended algorithm, but I believe that this is a faithful enough reproduction to accurately evaluate the method’s performance. For more information on the algorithm please see: https://pubmed.ncbi.nlm.nih.gov/27513194/, specifically the supplemental for implementation details. 5.4 LDpred One of the premier polygenic risk score adjustment algorithms. Rather than using a heuristic, LDpred attempts to provide a rigerous attempt to recreate effect estimates that would be produced if the full genetic information was used in the original estimation process. Further considerations are made to determine the proportion of SNPs that are true causal, and how linkage disequilibrium would change the estimates. The mathematical details are intense, with MCMC algorithms involved, but for the point of application we actually only need to know instillation, application and the troubleshooting processes required (this will be a theme throughout). LDpred runs in two steps, coordination and the MCMC algorithm. A key consideration in the initial coordination step is choosing a genotypic file to be the LD reference. The GitHub page reports that a file with over 1,000 unrelated individuals should be used. Within the publication they utilize their validation data set, which varies from about 100,000 to over a million SNPs. For a few of my summary statistics this will present a possible problem, but I think it is fair to test the limits of their algorithm in this way. To speed execution I limited my validation data set to 5,000 individuals for the LD reference. This 5,000 value is five times more than the recommended value so I hope it is a fair step (I am also encouraged to think so due to similar sample sizes used for the reference within the original publication, in fact they regularly had data sets with less than 5,000 individuals). Within another well-cited publication (“Genome-wide polygenic scores for common diseases identify individuals with risk equivalent to monogenic mutations”) the validation data set was not used, and instead the European individuals of the 1000 Genomes Group were. While this group falls below the 1,000 person recommendation, their performance and the accoldates the paper motivates this reference group as a strong alternative. The few remaining considerations concerning the coordination are the sample size given, which was the effective sample size recommended by PLINK, and the type of effect size specified, which is LOGOR, or beta values that were standardized in the previous chapter. The next step is entitled gibbs, which is the subtype of the MCMC algorithm. The first two arguments of this step are the outputs of the previous, easy enough. The next is the estimated heritability, which was taken from the consensus value determined in the previous chapter. Next is the f values, or the proportion of SNPs that are believed to be causal. As it is rather difficult to know this a priori, a range of parameters are attempted. The last value is the ld-radius. The value recommended to use is the total number of SNPs (across all chromosomes) divided by 3000. This value, and this value alone was utilized. Over the f value and reference genotype options a series of LDpred estimates were generated. The adjusted effect sizes were then subtituted into the original summary statistics to complete the process. Also an important note is that the software does not overwrite the coordination file by default, so if you are trying multiple coordinate set-ups you must manually delete it upon changing. The full code for the process is: chr=$1 author=$2 dir=$3 low_author=`echo &quot;$author&quot; | tr &#39;[:upper:]&#39; &#39;[:lower:]&#39;` d=comp_zone/dir${dir} prev_reftype=&quot;none&quot; i=1 cat all_specs/ldpred_param_specs | tail -n +2 | while read spec;do fval=`echo $spec | cut -f1 -d&#39; &#39;` reftype=`echo $spec | cut -f2 -d&#39; &#39;` echo fval $fval echo reftype $reftype num_snps=`cat ../raw_ss/meta_stats | fgrep $author | cut -f7 -d&#39;,&#39;` h2=`cat ../raw_ss/meta_stats | fgrep $author | cut -f12 -d&#39;,&#39;` rad=`echo $num_snps/3000 | bc` if [ $reftype != $prev_reftype ];then echo removeing ldradius and coordoutput rm ${d}/*ldradius* rm ${d}/coord_output fi if [ ! -e ~/athena/doc_score/mod_sets/${author}/${low_author}.ldpred.${i}.ss ]; then echo no ldpred score already exists present_cord=`ls ${d}/*ldradius* | wc -l` if [ $present_cord -eq 0 ];then echo there is not already a ldradius file present if [ $reftype == &quot;TGP&quot; ];then #1000 genomes echo went with TGP ldpred coord --gf ~/athena/refs/1000genomes/eur.${chr} --ssf temp_files/ss.${low_author}.${chr} --ssf-format CUSTOM --rs RSID --A1 A1 --A2 A2 --eff BETA --pos BP --chr CHR --pval P --se SE --ncol ESS --eff_type LOGOR --out ${d}/coord_output else #UKBB echo went with UKB head -5000 geno_files/${low_author}.${chr}.fam | cut -f1 &gt; ${d}/subset_inds plink --bfile geno_files/${low_author}.${chr} --keep-fam ${d}/subset_inds --make-bed --out ${d}/for_ldpred ldpred coord --gf ${d}/for_ldpred --ssf temp_files/ss.${low_author}.${chr} --ssf-format CUSTOM --rs RSID --A1 A1 --A2 A2 --eff BETA --pos BP --chr CHR --pval P --se SE --ncol ESS --eff_type LOGOR --out ${d}/coord_output fi fi ldpred gibbs --cf ${d}/coord_output --ldf ${d}/ld_file --h2 $h2 --ldr $rad --f $fval --out ${d}/ldpred.${i}.res new_file=`ls ${d}/ldpred.${i}.res_LDpred_p* | wc -l` if [ $new_file -gt 0 ];then echo found new file new_file_name=`ls ${d}/ldpred.${i}.res_LDpred_p*` echo it is $new_file_name Rscript helper_scripts/ldpred_beta_switch.R dir$dir $new_file_name $author $chr $i fi prev_reftpye=$reftype fi let i=i+1 done For more information I would (and have) read the originial publication, https://www.cell.com/ajhg/fulltext/S0002-9297(15)00365-1, follow the GitHub instructions, https://github.com/bvilhjal/ldpred, or use the bitbucket instructions, https://bitbucket.org/bjarni_vilhjalmsson/ldpred/src/master/. I think the best instructions are from the direct doccumentation accessed with -h. 5.5 LDpred2 While LDpred is a premier method, there are few additional options and computational limitations that the authors believed should be resolved in an entirely new method implementation. Specifically, LDpred2 is implemented within the bigsnpr package, and therefore required all files to be read into a R environment (compared to previously where things were managed as calls to a python script). I will briefly describe some of the important components of my implementation of the online vignette, which I used to base my own implementation. The first step is loading in the the genotype file that will be used as the linkage disequillibrium. While there was some difficulty in picking a single reference in LDpred, in this implementation the associated publication clearly states that 10,000 UK Biobank individuals were utilized. Specifically, those of white, British ancestry and with imputed SNPs. However, I should note that on initial applications I recieved errors on the genotypic correlation matrix exceeding the maximum vector size. To fix this problem I followed the publication and restricted the possible SNPs to those from HapMap (specifically within a file of the vignette). As I easily have all of those pieces I can easily and quickly load them in. The next big step is calculating the genotypic correlation matrix. This is by far the longest step in the process. The size of the correlation was chosen as 3cM as recommended in the vignette. Following I read in the consensus heritability, then set up a grid of paramters to analyze upon. The vignette contained over 100 sets of parameters, to prevent overfitting on my larger validation set I did not want to create this number of scores for each method, therefore I reduced the paramters investigated. With the parameters, genotypic correlation and read-in summary statistics the snp_ldpred2_grid command can actually be called to adjust the effect sizes. The output from this command can then be substituted into the original summary statistics and then written to produce the final adjusted summary statistics. As in the double weight set up, this method is carried with an initial shell script that prepares the genotypic files. chr=$1 author=$2 dir=$3 d=comp_zone/dir${dir} low_author=`echo &quot;$author&quot; | tr &#39;[:upper:]&#39; &#39;[:lower:]&#39;` head -10000 geno_files/${low_author}.${chr}.fam | cut -f1 &gt; ${d}/subset_inds plink --bfile geno_files/${low_author}.${chr} --keep-fam ${d}/subset_inds --extract ~/athena/refs/hapmap_from_ldpred2 --make-bed --out ${d}/for_ldpred2 Rscript helper_scripts/ldpred2.R $chr $author $d The main point of this shell script is calling a R script, which looks like: library(bigsnpr) #source(&quot;helper_scripts/snp_as_genetic.R&quot;) args &lt;- commandArgs(trailingOnly=TRUE) chr &lt;- args[1] author &lt;- args[2] d &lt;- args[3] lowauthor &lt;- tolower(author) #read in the genotypic data if(!file.exists(paste0(d, &quot;/for_ldpred2.rds&quot;))){ snp_readBed(paste0(d, &quot;/for_ldpred2.bed&quot;)) } obj.bigSNP &lt;- snp_attach(paste0(d, &quot;/for_ldpred2.rds&quot;)) #split up genotypic data as described G &lt;- obj.bigSNP$genotypes CHR &lt;- obj.bigSNP$map$chromosome POS &lt;- obj.bigSNP$map$physical.pos y &lt;- obj.bigSNP$fam$affection - 1 NCORES &lt;- nb_cores() #read in the summary stats sumstats &lt;- bigreadr::fread2(paste0(&quot;temp_files/ss.&quot;, lowauthor, &quot;.&quot;, chr)) colnames(sumstats) &lt;- c(&quot;chr&quot;, &quot;pos&quot;, &quot;rsid&quot;, &quot;a0&quot;, &quot;a1&quot;, &quot;beta_se&quot;, &quot;beta&quot;, &quot;p&quot;, &quot;n_eff&quot;) sumatsts &lt;- sumstats[sumstats$beta_se &gt; 0,] #run snp_match (likely can skip since I do this earlier) map &lt;- obj.bigSNP$map[-(2:3)] names(map) &lt;- c(&quot;chr&quot;, &quot;pos&quot;, &quot;a0&quot;, &quot;a1&quot;) info_snp &lt;- snp_match(sumstats, map, join_by_pos = T) #Calculate the LD correlation matrix print(&quot;calc the corr matrix&quot;) POS2 &lt;- snp_asGeneticPos(CHR, POS, dir = &quot;temp_files&quot;, ncores = 3) df_beta &lt;- info_snp[, c(&quot;beta&quot;, &quot;beta_se&quot;, &quot;n_eff&quot;)] corr0 &lt;- snp_cor(G, ncores = NCORES, infos.pos = POS2, size = 3 / 1000) corr &lt;- bigsparser::as_SFBM(as(corr0, &quot;dgCMatrix&quot;)) #Get the heritability print(&quot;getting h2&quot;) h2 &lt;- read.table(&quot;../raw_ss/meta_stats&quot;, stringsAsFactors=F, sep = &quot;,&quot;, header=T) h2 &lt;- h2$h2[h2$author == author] #Actually run ldpred2 print(&quot;run ldpred2 inf&quot;) beta_inf &lt;- snp_ldpred2_inf(corr, df_beta, h2 = h2) #set up parameters for the non-inf version h2_seq &lt;- round(h2 * c(0.7, 1, 1.4), 3) p_seq &lt;- signif(seq_log(1e-4, 1, length.out = 4), 2) params &lt;- expand.grid(p = p_seq, h2 = h2_seq, sparse = c(FALSE, TRUE)) #run ldpred2 over all the parameters print(&quot;run ldpred2 over grid&quot;) beta_grid &lt;- snp_ldpred2_grid(corr, df_beta, params, ncores = NCORES) #write the results to mod_sets print(&quot;writing the results&quot;) ss &lt;- info_snp[,1:9] ss$beta &lt;- beta_inf write.table(ss, paste0(&quot;../mod_sets/&quot;, author, &quot;/&quot;, lowauthor, &quot;.&quot;, chr, &quot;.ldpred2.1.ss&quot;), row.names = F, col.names = T, quote = F, sep = &#39;\\t&#39;) for(i in 1:ncol(beta_grid)){ ss$beta &lt;- beta_grid[,i] write.table(ss, paste0(&quot;../mod_sets/&quot;, author, &quot;/&quot;, lowauthor, &quot;.&quot;, chr, &quot;.ldpred2.&quot;, i+1, &quot;.ss&quot;), row.names = F, col.names = T, quote = F, sep = &#39;\\t&#39;) } The original vignette is https://privefl.github.io/bigsnpr/articles/LDpred2.html, and the original publication is https://www.biorxiv.org/content/10.1101/2020.04.28.066720v1. 5.6 SBLUP SBLUP, which stands for summary best linear unbiased predictions, attempts to use summary statistics alone to generate BLUP estimates of SNP effect sizes (a similar goal of LDpred). The application of SBLUP is easily completed within the genome-wide complex trait analysis application, a piece of software that is only rivaled by PLINK for its doccumentation and dependability. The first argument of sblup is a genotypic file used for determining a LD correlation matrix. On initial applications I attempeted to use all people within my training set (80,000). While the application did sometimes complete, it was very memory intensive, and slow. Investigating the originating publication I found that in the supplamentary (specifically figure 2) 10,000 individuals were used. In the main text over 7,000 couples were mentioned within an analysis. While more people could have been used in SBLUP, I figured an analysis of 20,000 individuals could be a safe margin on the couples analysis and will give a good picture on whether it performs significantly better than 10,000. The second argument of SBLUP is termed cojo-sblup, which is specified to be \\(m(1/h^2 - 1)\\). This term seem rather important, and turns out to be one of the few parameters worth tuning, therefore I parametrized over three variations in which the heritability term is multipled by 0.7, 1, and 1.3. This way if the heritability was slightly off and the cojo-sblup term is very sensitive I still have the change of obtaining a good set of adjusted summary statistics. The next argument is the cojo-wind term, or the LD radius term. The website recommends 1 Mb even though the default value is 10 Mb. For ease of computation I went with 1 Mb. The final term is the summary statistics, which have to be modified to fit a “ma” format. A key addition in this format is the allele frequency, which was empirically calculated with the UK Biobank full training sample. As before, all of the steps were controlled in the following bash script: chr=$1 author=$2 dir=$3 low_author=`echo &quot;$author&quot; | tr &#39;[:upper:]&#39; &#39;[:lower:]&#39;` d=comp_zone/dir${dir} num_snps=`cat ../raw_ss/meta_stats | fgrep $author | cut -f7 -d&#39;,&#39;` h2=`cat ../raw_ss/meta_stats | fgrep $author | cut -f12 -d&#39;,&#39;` i=1 cat all_specs/sblup_param_specs | while read spec;do coef=`echo $spec | cut -f1 -d&#39; &#39;` fam_num=`echo $spec | cut -f2 -d&#39; &#39;` use_h2=`echo &quot;$h2 * $coef&quot; | bc -l` lambda=`echo &quot;$num_snps * (1/$use_h2 - 1)&quot; | bc` if [ ! -e ~/athena/doc_score/mod_sets/${author}/${low_author}.sblup.${i}.ss ]; then plink --bfile geno_files/${low_author}.${chr} --freq --out temp_files/${low_author}.${chr} Rscript helper_scripts/add_ma.R $author $chr head -$fam_num geno_files/${low_author}.${chr}.fam | cut -f1 &gt; ${d}/subset_inds plink --bfile geno_files/${low_author}.${chr} --keep-fam ${d}/subset_inds --make-bed --out ${d}/for_sblup gcta64 --bfile ${d}/for_sblup --cojo-file temp_files/ss.${low_author}.${chr}.ma --cojo-sblup $lambda --cojo-wind 100 --thread-num 20 --out ${d}/out Rscript helper_scripts/reformat_sblup.R $chr $author $d $i rm ${d}/for_sblup* fi let i=i+1 done The first needed R script for calculating the “ma” summary statistics is: args &lt;- commandArgs(trailingOnly=TRUE) lowauthor &lt;- tolower(args[1]) bim &lt;- read.table(paste0(&quot;geno_files/&quot;, lowauthor, &quot;.&quot;, args[2], &quot;.bim&quot;), stringsAsFactors=F) ss &lt;- read.table(paste0(&quot;temp_files/ss.&quot;, lowauthor, &quot;.&quot;, args[2]), stringsAsFactors=F, header=T) ss &lt;- ss[ss$RSID %in% bim[,2],] frq &lt;- read.table(paste0(&quot;temp_files/&quot;, lowauthor, &quot;.&quot;, args[2], &quot;.frq&quot;), stringsAsFactors=F, header=T) ss$frq &lt;- rep(0, nrow(frq)) ss$frq[ss$A1 == frq$A1] &lt;- frq$MAF[ss$A1 == frq$A1] ss$frq[ss$A2 == frq$A1] &lt;- frq$MAF[ss$A2 == frq$A1] ss &lt;- ss[,c(3,4,5,10,7,6,8,9)] colnames(ss) &lt;- c(&quot;SNP&quot;, &quot;A1&quot;, &quot;A2&quot;, &quot;freq&quot;, &quot;b&quot;, &quot;se&quot;, &quot;p&quot;, &quot;N&quot;) write.table(ss, paste0(&quot;temp_files/ss.&quot;, lowauthor, &quot;.&quot;, args[2],&quot;.ma&quot;), row.names = F, col.names = T, sep = &#39;\\t&#39;, quote = F) The output file looks a little funky, so a final R script substitutes the adjusted effect into the original summary statistics. args &lt;- commandArgs(trailingOnly=TRUE) chr &lt;- args[1] author &lt;- args[2] d &lt;- args[3] i &lt;- args[4] lowauthor &lt;- tolower(author) sblup &lt;- read.table(paste0(d,&quot;/out.sblup.cojo&quot;), stringsAsFactors=F) ss &lt;- read.table(paste0(&quot;temp_files/ss.&quot;, lowauthor, &quot;.&quot;, chr), stringsAsFactors=F, header=T) ss &lt;- ss[ss$RSID %in% sblup[,1],] sblup &lt;- sblup[order(sblup[,1])[rank(ss$RSID)],] ss$BETA &lt;- sblup[,4] write.table(ss, paste0(&quot;../mod_sets/&quot;, author, &quot;/&quot;, lowauthor, &quot;.&quot;, chr, &quot;.sblup.&quot;, i, &quot;.ss&quot;), row.names = F, col.names = T, sep = &#39;\\t&#39;, quote = F) The original publication is https://www.nature.com/articles/s41562-016-0016#MOESM11, and the doccumentation comes from https://cnsgenomics.com/software/gcta/#SBLUP. 5.7 SMTpred SMTPred, which I believe stands for summary multi-trait prediction, is a very interesting method that leverages correlated traits to effectively increase the sample size of the original effect estimates. While the weighting system is actually relatively simple, I will leave that information to the interested reader and instead focus on the actual implementation. The SMTpred python script requires quite a few types of inputs, including heritabilities, genetic correlations, sample sizes and summary statistics. Luckily for us most of these inputs are really easily accesible fixed information. The two items that we can change are the summary statistics and the genetic correlations. Specifically, the SMTpred algorithm accepts either normal least-squares effect estimates and SBLUP outputs. As we are already producing SBLUP adjusted summary statistics we might as well try both. The genetic correlations is a little trickier. Many genetic correlation estimates have very high standard errors, and in my opinion this means they should not be used. Similarly, I can include, in theory 24 genetic correlations in an implementation, however this seems problematic as comparisons across applications likely become more difficult and some of the weaker correlations may be more likely to harm my final output than help. Therefore, I will limit the number of correlations to the top 3, 5 and 10 to see if a more conservative or liberal approach is best. With all of the theory of implementation I may now actually write the code, which is really just a bit of data-pulling and re-arranging. The overall shell script is: chr=$1 author=$2 dir=$3 low_author=`echo &quot;$author&quot; | tr &#39;[:upper:]&#39; &#39;[:lower:]&#39;` d=comp_zone/dir${dir} #NOTE!!!!!!!!!!!! Need to implement sblup option i=1 cat all_specs/smtpred_param_specs | tail -n +2 | while read spec;do max_corr=`echo $spec | cut -f1 -d&#39; &#39;` est_type=`echo $spec | cut -f2 -d&#39; &#39;` if [ ! -e ~/athena/doc_score/mod_sets/${author}/${low_author}.smtpred.${i}.ss ]; then Rscript helper_scripts/set_up_smtpred.R $low_author $d $max_corr cat ${d}/ss_files | cut -f1 -d&#39;.&#39; | while read new_author;do if [ $new_author == &quot;imsgc&quot; ];then upper_author=`echo $new_author | tr [a-z] [A-Z]` else upper_author=${new_author^} fi speclow_author=`echo $new_author | tr &#39;[:upper:]&#39; &#39;[:lower:]&#39;` if [ $est_type == &quot;normal&quot; ];then zcat ~/athena/doc_score/raw_ss/${upper_author}/chr_ss/${new_author}_${chr}.ss.gz &gt; ${d}/${new_author}.ss else zcat ~/athena/doc_score/mod_sets/${upper_author}/${speclow_author}.${chr}.sblup.5.ss &gt; ${d}/${new_author}.ss fi done ss_line=`cat ${d}/ss_files | while read line;do echo ${d}/${line}; done | tr &#39;\\n&#39; &#39; &#39;` python ~/Programs/smtpred/smtpred.py --betafiles $ss_line --nfile ${d}/samp_size --h2file ${d}/herit --rgfile ${d}/rg Rscript helper_scripts/finish_smtpred.R $d $i $low_author $chr fi let i=i+1 done The first R script within this shell script does much of the heavy lifting, reading all the genetic correlations and additional meta-stats, ultimately writing all of the stats files that are reuired in the actual python call of smtpred. args &lt;- commandArgs(trailingOnly=TRUE) author &lt;- args[1] d &lt;- args[2] toprank &lt;- as.numeric(args[3]) gencorr &lt;- read.table(&quot;~/athena/doc_score/raw_ss/genetic_correlations&quot;, stringsAsFactors=F) metastats &lt;- read.table(&quot;~/athena/doc_score/raw_ss/meta_stats&quot;, stringsAsFactors=F, sep = &quot;,&quot;, header = T) gencorr &lt;- gencorr[gencorr[,1] == author,] gencorr &lt;- gencorr[abs(gencorr[,8]) &lt; gencorr[,7] &amp; !is.na(gencorr[,7]) &amp; gencorr[,2] != author,] gencorr &lt;- gencorr[order(gencorr[,7], decreasing=T),] if(nrow(gencorr) &gt; toprank){ gencorr &lt;- gencorr[1:toprank,] } metastats &lt;- metastats[tolower(metastats[,1]) %in% c(author, gencorr[,2]),] sampsize &lt;- cbind(tolower(metastats$author), 4/(1/metastats$cases + 1/metastats$controls)) herit &lt;- cbind(tolower(metastats$author), metastats$h2) ss_names &lt;- paste0(tolower(metastats$author), &quot;.ss&quot;) write.table(sampsize, paste0(d, &quot;/samp_size&quot;), row.names = F, col.names = F, quote = F, sep = &#39;\\t&#39;) write.table(herit, paste0(d, &quot;/herit&quot;), row.names = F, col.names = F, quote = F, sep = &#39;\\t&#39;) write.table(gencorr[,c(1,2,7)], paste0(d, &quot;/rg&quot;), row.names = F, col.names = F, quote = F, sep = &#39;\\t&#39;) write.table(ss_names, paste0(d, &quot;/ss_files&quot;), row.names = F, col.names = F, quote = F, sep = &#39;\\t&#39;) The final R script completes a role similar to many other methods, combining the effects adjusted by the method to the original summary statistics. #arguments are: d variable, i number, low author, chr args &lt;- commandArgs(trailingOnly=TRUE) low_author &lt;- tolower(args[3]) smtpred_ss &lt;- read.table(paste0(args[1], &quot;/multi_trait.beta&quot;), stringsAsFactors=F, header = T) raw_ss &lt;- read.table(paste0(args[1], &quot;/&quot;, args[3], &quot;.ss&quot;), stringsAsFactors=F, header=T) raw_ss &lt;- raw_ss[raw_ss$RSID %in% smtpred_ss$snpid,] smtpred_ss &lt;- smtpred_ss[order(smtpred_ss$snpid)[rank(raw_ss$RSID)],] raw_ss$BETA &lt;- smtpred_ss[,3] write.table(raw_ss, paste0(&quot;~/athena/doc_score/mod_sets/&quot;, tools::toTitleCase(args[3]), &quot;/&quot;, args[3], &quot;.&quot;, args[4], &quot;.smtpred.&quot;, args[2] ,&quot;.ss&quot;), row.names = F, col.names = T, sep = &#39;\\t&#39;, quote = F) The original publication is https://www.nature.com/articles/s41467-017-02769-6, and the doccumentation comes from https://github.com/uqrmaie1/smtpred. 5.8 prsCS the prsCS algorithm is actually very similar to LDpred, in that it aims to shrink some of the least squares effect estimates, thereby generating adjusted estimates that are better poised for polygenic risk scoring. The main difference (I believe) is that LDpred uses a point-block prior on its probability a SNP being causal whereas prsCS goes with a continous prior (naturally). Luckily for us many of the parameters that have confused us in past methods are easily and simply provided to us within this method. Specifically, I am referring to genotypic files for a linkage disequilibrium reference, they are provided on the GitHub page based on the ancestry of the desired polygenic risk score. In fact, the only parameter that we are specifying is phi, which I believe is related to the propotion of underlying casual SNPs for the trait, also know as the polygenicity. While the algorithm states that it can learn this parameter itself, there are some caveats that lead me to believe it would be best to just try a scale of phi values. There are other parameters relating to the MCMC algorithm, but I will not touch those. The actual mechanics of the algorithm include changing the formatting of the summary statistics, running a single python script, and finally substituting the output adjusted effect sizes for the original effect sizes. This process was controlled by the shell script: chr=$1 author=$2 dir=$3 low_author=`echo &quot;$author&quot; | tr &#39;[:upper:]&#39; &#39;[:lower:]&#39;` d=comp_zone/dir${dir} ess=`cat temp_files/ss.${low_author}.${chr} | head -2 | tail -n +2 | cut -f9` cp helper_scripts/prscs_header ${d}/ss cat temp_files/ss.${low_author}.${chr} | tail -n+2 | cut -f3,4,5,7,8 &gt;&gt; ${d}/ss i=1 cat all_specs/prscs_param_specs | while read phi;do if [ ! -e ~/athena/doc_score/mod_sets/${author}/${low_author}.prs.${i}.ss ]; then python ~/Programs/PRScs/PRScs.py --ref_dir=/home/kulmsc/athena/refs/ldblk_1kg_eur --bim_prefix=geno_files/${low_author}.${chr} --sst_file=${d}/ss --phi=${phi} --n_gwas=${ess} --chrom=$chr --out_dir=${d}/output.$i Rscript helper_scripts/prscs_beta_switch.R $d $i $author $chr fi let i=i+1 done The R script needed for effect substitution is: #arguments are: d, i, author, chr args &lt;- commandArgs(trailingOnly=TRUE) d &lt;- args[1] i &lt;- args[2] author &lt;- args[3] chr &lt;- args[4] low_author &lt;- tolower(author) file_name &lt;- list.files(d, paste0(&quot;output.&quot;, i, &quot;_pst&quot;)) beta &lt;- read.table(paste0(d, &quot;/&quot;, file_name), stringsAsFactors = F) ss &lt;- read.table(paste0(&quot;temp_files/ss.&quot;, low_author, &quot;.&quot;, chr), stringsAsFactors=F, header=T) ss &lt;- ss[ss$RSID %in% beta[,2],] beta &lt;- beta[order(beta[,2])[rank(ss$RSID)],] ss$BETA &lt;- beta[,6] write.table(ss, paste0(&quot;~/athena/doc_score/mod_sets/&quot;, author, &quot;/&quot;, low_author, &quot;.&quot;, chr, &quot;.prscs.&quot;, i ,&quot;.ss&quot;), row.names = F, col.names = T, sep = &#39;\\t&#39;, quote = F) The original publication can be found at https://www.nature.com/articles/s41467-019-09718-5, and the doccumentation comes from https://github.com/getian107/PRScs. 5.9 lassosum While lassosum may appear to be a classic method like LDpred, SBLUP, or prsCS, its underlying methedology is actuall far different. Rather than following a theoretical basic that recreates effect estimates that would be produced with full genetic information lassosum tries to recreate the process of lasso regression, a far more heuristic or goal-oriented process. The process of actually implementing lassosum is relatively easy as everything can be carried out within a R script, leaving the controlling shell script to do very little. chr=$1 author=$2 dir=$3 low_author=`echo &quot;$author&quot; | tr &#39;[:upper:]&#39; &#39;[:lower:]&#39;` d=comp_zone/dir${dir} Rscript helper_scripts/lassosum.R $d $chr $low_author The R script it launches does three sets of things. First, it sets up a few important objects: reading in the summary statistics and sets the name of the reference genotypes. Second, it converts the summary statistic P-values into a correlation type statistic then runs the lassosum pipeline. A few of the important parameters that are set in the pipeline include: the name of the LDblock, which is already mostly specified by the software and just needs an ancestry matching name; the sample number or number of people to keep in the LD reference, I chose 5000 as its value exceeds that of the sample size used within the originating publication (from my reading either than 1000 genomes or cases from the WTCCC were used, both of which I think are close to 5000, or at least not an order of magnitude higher); the s parameter (which I am unclear what it represents) is given the values randing from 0.1 to 1 in the paper, and with better performance at lower values I will test 0.1, 0.4 and 0.8; finally the lambda value, which I believe represents the strength of the penalty in the lasso is given the default values ranging from 0.001 to 0.1, therefore I test a similar range but with fewever numbers in my own sample vector. The third thing the script does is subsitute the results into the original summary statistics and writes the results. Altogether it looks like: library(lassosum) #args are: d, chr, low_author args &lt;- commandArgs(trailingOnly=TRUE) ss &lt;- read.table(paste0(&quot;temp_files/ss.&quot;, args[3], &quot;.&quot;, args[2]), stringsAsFactors=F, header=T) ref.bfile &lt;- paste0(&quot;geno_files/&quot;, args[3], &quot;.&quot;, args[2]) cor &lt;- p2cor(p = ss$P, n = ss$ESS[1], sign=ss$BETA) out &lt;- lassosum.pipeline(cor=cor, chr=ss$CHR, pos=ss$BP, A1=ss$A1, A2=ss$A2, # A2 is not required but advised ref.bfile=ref.bfile, LDblocks = &quot;EUR.hg19&quot;, sample = 5000, s = c(0.1, 0.4, 0.8), lambda = c(0.002, 0.004, 0.007, 0.1)) new_ss &lt;- ss[ss$BP %in% out$sumstats[,2],] k &lt;- 1 for(i in 1:3){ for(j in 1:4){ new_ss$BETA &lt;- out$beta[[i]][,j] write.table(new_ss, paste0(&quot;~/athena/doc_score/mod_sets/&quot;, tools::toTitleCase(args[3]), &quot;/&quot;, args[3], &quot;.&quot;, args[2], &quot;.lassosum.&quot;, k ,&quot;.ss&quot;), row.names = F, col.names = T, sep = &#39;\\t&#39;, quote = F) k &lt;- k + 1 } } The original(accessible) publication can be found at https://www.biorxiv.org/content/10.1101/058214v2.full.pdf, and the doccumentation comes from https://github.com/tshmak/lassosum. 5.10 Tweedie The Tweedie Method is fundamentally concerned with the Winner’s Curse idea that has been similarly in several other methods. Tweedie specifically handles the curse by thinking of a true distribution of Z-statistics, and then attempting to create an approximation for this distribution by inserting a kernel over the estimated statistics. However, before we can begin this Winners Curse correction process the corresponding publication recommends we try to limit the amount of linkage disequilbrium within the underlying summary statistics. They have a consistent R2 cut-off of 0.25 and leave the P-value parameter take a range of values. The limited summary statistics are then converted into Z-statistics, incorporated with empirically estimated allele frequencies, and sent into a supplied R script. The output adjusted effect values can the be subset back into the original summary statistics and saved. The controlling script for this process looks like: chr=$1 author=$2 dir=$3 low_author=`echo &quot;$author&quot; | tr &#39;[:upper:]&#39; &#39;[:lower:]&#39;` d=comp_zone/dir${dir} i=1 cat all_specs/tweedie_param_specs | tail -n +2 | while read spec;do plim=`echo $spec | cut -f1 -d&#39; &#39;` if [ ! -e ~/athena/doc_score/mod_sets/${author}/${low_author}.tweedie.${i}.ss ]; then plink --memory 4000 --threads 1 --bfile geno_files/${low_author}.${chr} --clump temp_files/ss.${low_author}.${chr} --clump-snp-field RSID --clump-p1 $plim --clump-r2 0.25 --out ${d}/out if [ -f ${d}/out.clumped ]; then plink --bfile geno_files/${low_author}.${chr} --freq --out ${d}/freq Rscript helper_scripts/add_tweedie.R $author $chr $d Rscript helper_scripts/tweedie.R $author $chr $d $i fi fi let i=i+3 done I won’t show the R script because it is rather long and almost completely what was originally downloaded. The only changes are to read in the summary statistics at the top and convert P-values to Z-statistics, then seperate out the nescessary objects. The original publication comes from https://www.nature.com/articles/srep41262.pdf, and the code comes from https://sites.google.com/site/honcheongso/software/empirical-bayes-risk-prediction. 5.11 SBayesR The SBayesR method is somewhat similar to the SBLUP method in that it uses a LD reference matrix to attempt to recover effect estimates that would be produced from a full genotype aware regression. Any more description would get pretty complicated, so I will leave it to the interested reader. The largest in terms of computation and memory component of a SBayesR run is the construction of the LD reference matrix. There are solid descriptions within the tutorial, the ultimate message is that a sparse and shrunk matrix is best. Although what’s even better is downloading these matricies directly without computation. You can find the links to these matricies on the FAQ page. There is a 1 million HapMap version and a 2.8 million common SNPs version. The corresponding publication saw slightly better results with 2.8 million SNPs, however this larger version looks like it is well over 100 GB compared to the ~50GB of the HapMap. While losing some accuracy, in the effort to make this an attainable guide for all I went with the HapMap version. So please know if you are looking for super accuracy, having a lot of storage and want to use SBayesR then go for the 2.8 million. The remaining parameters can likely be left at their defaults, as that seems like all was done in the publication. However, an important step is to set a P-value and rsq cut-off as recommended in their FAQ. Finally, I ran two models, one for the R model and another for C. The controlling script for this entire process is actually quite simple and looks like: chr=$1 author=$2 dir=$3 low_author=`echo &quot;$author&quot; | tr &#39;[:upper:]&#39; &#39;[:lower:]&#39;` d=comp_zone/dir${dir} plink --bfile geno_files/${low_author}.${chr} --freq --out temp_files/${low_author}.${chr} Rscript helper_scripts/add_ma.R $author $chr gctb2 --sbayes R --ldm ~/athena/refs/ukbEURu_hm3_shrunk_sparse/ukbEURu_hm3_chr${chr}_v3_50k.ldm.sparse --gwas-summary temp_files/ss.${low_author}.${chr}.ma --p-value 0.05 --rsq 0.99 --out-freq 100 --out ${d}/sbay_out Rscript helper_scripts/reformat_sbayesr.R $chr $author $d 1 rm ${d}/sbay_out* gctb2 --sbayes C --ldm ~/athena/refs/ukbEURu_hm3_shrunk_sparse/ukbEURu_hm3_chr${chr}_v3_50k.ldm.sparse --gwas-summary temp_files/ss.${low_author}.${chr}.ma --p-value 0.05 --rsq 0.99 --out-freq 100 --out ${d}/sbay_out Rscript helper_scripts/reformat_sbayesr.R $chr $author $d 2 rm ${d}/sbay_out* At the top of the script is the execution of a R script, which is the exact same as in the SBLUP description. And at the bottom, as I often have to do, I exchange the adjusted effects for those in the original summary statistics. This script looks like: args &lt;- commandArgs(trailingOnly=TRUE) chr &lt;- args[1] author &lt;- args[2] d &lt;- args[3] i &lt;- args[4] lowauthor &lt;- tolower(author) sbay &lt;- read.table(paste0(d,&quot;/sbay_out.snpRes&quot;), stringsAsFactors=F, header = T) ss &lt;- read.table(paste0(&quot;temp_files/ss.&quot;, lowauthor, &quot;.&quot;, chr), stringsAsFactors=F, header=T) ss &lt;- ss[ss$RSID %in% sbay[,2],] sbay &lt;- sbay[order(sbay[,2])[rank(ss$RSID)],] ss$BETA &lt;- sbay$A1Effect write.table(ss, paste0(&quot;../mod_sets/&quot;, author, &quot;/&quot;, lowauthor, &quot;.&quot;, chr, &quot;.sbayesr.&quot;, i, &quot;.ss&quot;), row.names = F, col.names = T, sep = &#39;\\t&#39;, quote = F) chr=$1 author=$2 dir=$3 low_author=`echo &quot;$author&quot; | tr &#39;[:upper:]&#39; &#39;[:lower:]&#39;` d=comp_zone/dir${dir} #spack load /g7nwnaf #spack load gcc@8.2.0 num_snps=`cat ../raw_ss/meta_stats | fgrep $author | cut -f7 -d&#39;,&#39;` h2=`cat ../raw_ss/meta_stats | fgrep $author | cut -f12 -d&#39;,&#39;` samp_size=`cat temp_files/ss.${low_author}.${chr} | head -2 | tail -n +2 | cut -f9` i=1 cat all_specs/dbslmm_param_specs | tail -n+2 | while read spec;do pval=`echo $spec | cut -f1 -d&#39; &#39;` r2=`echo $spec | cut -f1 -d&#39; &#39;` if [ ! -e ~/athena/doc_score/mod_sets/${author}/${low_author}.dbslmm.${i}.ss ]; then plink --bfile geno_files/${low_author}.${chr} --freq --out temp_files/${low_author}.${chr} Rscript helper_scripts/add_gemma.R $author $chr head -5000 geno_files/${low_author}.${chr}.fam &gt; ${d}/keep_people plink --bfile geno_files/${low_author}.${chr} --keep-fam ${d}/keep_people --make-bed --out ${d}/short dbslmm_bash=~/Programs/DBSLMM/dbslmm dbslmm_r=~/Programs/DBSLMM/software/DBSLMM.R ss=temp_files/ss.${low_author}.${chr}.gemma ref=${d}/short blockf=~/athena/refs/ldsplits/chr${chr}.bed Rscript ${dbslmm_r} --summary $ss --outPath ./${d}/ --plink ~/bin/plink --dbslmm ${dbslmm_bash} --ref ${ref} --n ${samp_size} --nsnp ${num_snps} --block ${blockf} --h2 ${h2} --pv=${pval} --r2=${r2} if [ -e ${d}/ss.${low_author}.dbslmm.txt ];then Rscript helper_scripts/reformat_dbslmm.R $chr $author $d $i rm ${d}/ss.${low_author}.dbslmm.txt fi fi let i=i+1 done The main steps involve converting my summary statistics format into the desired GEMMA format, then extracting a large amount of meta-statistics (including heritability, sample size, and number of SNPs), then actually launching the main R script. I have had some troubles getting this program to work, as some specific GCC compilers and additional libraries are needed. The final step in this process substitutes the adjusted beta values into the original summary statistics. The only parameters needed in this process are p-value and R2 values, which are used in a preliminary clumping process in the DBSLMM algorithm. The only other, unclear but common parameter is the number of individuals to include in the LD reference panel. While the original paper only specifies 500 individuals in their reference panel, I thought that value was very low and increasing it would not decrease accuracy. Therefore I have 5,000 individuals in the reference panel, bringing the same size closer in line to other methods. The original publication comes from https://www.sciencedirect.com/science/article/pii/S0002929720301099, and great doccumentation comes from https://biostat0903.github.io/DBSLMM/index.html. 5.12 JAMPred JAMPred, which stands for Joint Analysis of Marginal Summary Statistics Prediction, is a polygenic risk score generating model that is based upon the JAM algorithm. The original algorithm was made to smartly perform meta-analyses for the purpose of fine-mapping. The prediction aspect has been added on, adjusting for both normal and uniquely long-range linkage disequilibrium through the induction of sparsity in the effects. A block approach allows for the long-range correction while also allowing for easy parallelization. Further details on the algorithm are intersting, but we only need to implement the algorithm. chr=$1 author=$2 dir=$3 d=comp_zone/dir${dir} low_author=`echo &quot;$author&quot; | tr &#39;[:upper:]&#39; &#39;[:lower:]&#39;` #can limit to 5,000 samples and R2 &lt; 0.95 head -5000 geno_files/${low_author}.${chr}.fam | cut -f1 &gt; ${d}/subset_inds plink --bfile geno_files/${low_author}.${chr} --keep-fam ${d}/subset_inds --indep-pairwise 500 100 0.95 --out ${d}/snps plink --bfile geno_files/${low_author}.${chr} --keep-fam ${d}/subset_inds --extract ${d}/snps.prune.in --make-bed --out ${d}/for_jampred Rscript helper_scripts/jampred.R $chr $author $d The primary implementation of JAMPred takes place within an R script. The only prior steps needed are setting up the LD reference data. Following the original publication, the sample size in LD reference is set to 5,000 individuals, slightly more than what is used in the primary paper. An interesting step specific to this method is that the markers in the LD reference were specified to have R2 less than 95%, meaning that I had to randomly sample down my markers using PLINK. .libPaths( c( &quot;/home/kulmsc/R/x86_64-pc-linux-gnu-library/3.6&quot;, .libPaths() ) ) library(bigsnpr) library(R2BGLiMS) args &lt;- commandArgs(trailingOnly=TRUE) chr &lt;- args[1] author &lt;- args[2] d &lt;- args[3] if(!file.exists(paste0(d, &quot;/for_jampred.rds&quot;))){ snp_readBed(paste0(d, &quot;/for_jampred.bed&quot;)) } obj.bigSNP &lt;- snp_attach(paste0(d, &quot;/for_jampred.rds&quot;)) ped &lt;- big_copy(snp_fastImputeSimple(obj.bigSNP$genotypes, &quot;mean0&quot;), type = &quot;integer&quot;) ped &lt;- ped$bm() options(bigmemory.allow.dimnames=TRUE) colnames(ped) &lt;- obj.bigSNP$map$marker.ID rm(obj.bigSNP) ss &lt;- read.table(paste0(&quot;temp_files/ss.&quot;, tolower(author), &quot;.&quot;, chr), stringsAsFactors=F, header=T) ss &lt;- ss[ss$RSID %in% colnames(ped),] marg_beta &lt;- ss$BETA names(marg_beta) &lt;- ss$RSID marg_se &lt;- ss$SE names(marg_se) &lt;- ss$RSID meta_stats &lt;- read.table(&quot;~/athena/doc_score/raw_ss/meta_stats&quot;, sep = &quot;,&quot;, stringsAsFactors=F, header = T) meta_line &lt;- meta_stats[meta_stats[,1] == tools::toTitleCase(author),] lambdas &lt;- read.table(&quot;all_specs/jampred_param_specs&quot;, header = T) try_ind &lt;- unname(which(marg_beta != 0)) for(i in 1:nrow(lambdas)){ jampred.res.bin &lt;- JAMPred( marginal.betas = marg_beta[try_ind], n.training = as.numeric(meta_line$sampe_size), marginal.logor.ses = marg_se[try_ind], # Only necessary for a binary trait p.cases.training = meta_line$cases/meta_line$sampe_size, # Only necessary for a binary trait ref.geno = ped[1:nrow(ped),try_ind], total.snps.genome.wide = meta_line$snps, # Total SNPs across all chromosomes n.mil = 0.2, n.cores = 1, beta.binom.b.lambda = lambdas[i,1] debug = TRUE, save.path = paste0(&quot;/home/kulmsc/athena/doc_score/adjust_ss/&quot;, d), seed = 1 # For re-producibility. If not set a random seed is used ) newss &lt;- ss[ss$RSID %in% jampred.res.bin$snps,] newss$BETA &lt;- jampred.res.bin$step2.posterior.mean.snp.weights write.table(newss, paste0(&quot;../mod_sets/&quot;, author, &quot;/&quot;, lowauthor, &quot;.&quot;, chr, &quot;.jampred.&quot;, i, &quot;.ss&quot;), row.names = F, col.names = T, quote = F, sep = &#39;\\t&#39;) } After the genotypic data is prepared, the actual R script can be carried out. While the demands of JAMPred may seem simple, it requires that the genotypic data in 0, 1, and 2s be read into R. This can be a very large file, easily crashing the RAM of even a nice cluster. Therefore I took the approach of using the bigsnpr package to read the data in a memory-smart way. Some funky code then is used to change the column names to the rsids in the summary statistics, and impute the missing data. The memory-smart genotypic file can then be directly inserted into the main JAMPred function call, along with other meta statistics and the summary statistics. The only parameter needing adjusting is lambda. The four lambda values chosen in this trial are the four used within the example on the associated GitHub page. The output of this function are adjusted betas, which can then be substiuted into the main summary statistics. The original publication comes from https://onlinelibrary.wiley.com/doi/full/10.1002/gepi.22245, and the doccumentation is at https://github.com/pjnewcombe/R2BGLiMS. 5.13 Winner’s Curse Lasso The next series of methods come from the same publication that attempts to improve GWAS summary statistics for scoring by correcting the winner’s curse. As a short review, winner’s curse is inflicted upon the SNPs that barely surpass any hard (often p-value) threshold that is made for inclusion in scoring. The economic definition, which is a little easier to follow, is described as the curse of the person who places the winning bid at an auction. While the person wins the item they are often irrational and the bid does not reflect the true price or average bid. To fix this curse the general idea is to make a smooth threshold for SNP inclusion. The first way the corresponding publication does this is with the LASSO algorithm. As we do not have the raw genotypic data we obviously cannot do a true LASSO. However, we can treat the summary statistic effect size as the quantity that becomes penalized we can construct an ad-hoc LASSO approach that limits SNPs to those that are the most powerful. To implement the associated equation the publication first requires limiting SNPs so they are not within LD. They use clumping with R2 less than 0.1, so we do the same in all possible LASSO executions (we also set the p-value limit to 0.5 to remove the SNPs that clearly will not make any following cut-off). While there is no need to match any LD reference panel, because it does not exist, we do need to specify lambda values. While I cannot find any mention of values in the publication I have found that 0.001, 0.01, and 0.1 give a good array of adjusted effect sizes. With all of this in mind we can now launch the actual scoring script. chr=$1 author=$2 dir=$3 low_author=`echo &quot;$author&quot; | tr &#39;[:upper:]&#39; &#39;[:lower:]&#39;` d=comp_zone/dir${dir} plink --memory 4000 --threads 1 --bfile geno_files/${low_author}.${chr} --clump temp_files/ss.${low_author}.${chr} --clump-snp-field RSID --clump-p1 0.5 --clump-r2 0.05 --out ${d}/out sed -e &#39;s/ [ ]*/\\t/g&#39; ${d}/out.clumped | sed &#39;/^\\s*$/d&#39; | cut -f4 | tail -n +2 &gt; ${d}/done_rsids cat temp_files/ss.${low_author}.${chr} | fgrep -w -f ${d}/done_rsids &gt; ${d}/specific_ss i=1 cat all_specs/wc_lasso_param_specs | while read lambda;do if [ ! -e ~/athena/doc_score/mod_sets/${author}/${low_author}.wc_lasso.${i}.ss ]; then python helper_scripts/winners_curse.py lasso $lambda $d $i mv ${d}/summStat ~/athena/doc_score/mod_sets/${author}/${low_author}.${chr}.wc_lasso.${i}.ss fi let i=i+1 done The key line within this script is launching the python winners_curse python script. While not being the shortest script, it is actually quite simple. The summary statistics are read in, each SNP is then iterated through with the nescessary values being sent to the lasso function, and the output adjusted effect size is then substituted into the new summary statistics. I should note that this script was not provided by the publication but written by myself, leaving plenty of room for error. After the script runs I simply save the adjusted summary statistics to finish the process. import numpy as np import gzip import os import sys import pdb from scipy.stats import norm from scipy.optimize import minimize method=sys.argv[1] inputLambda=float(sys.argv[2]) dd=sys.argv[3] ssName=dd+&quot;/specific_ss&quot; pLim=0.05 def normRead(fileName,delimiter): totalData=[] with open(fileName,&quot;r&quot;) as f: for line in f.read().splitlines(): totalData.append(line.split()) totalData=np.array(totalData) return(totalData) def justRead(fileName,delimiter): rList=[] with open(fileName,&quot;r&quot;) as f: for line in f.read().splitlines(): rList.append(line.split(delimiter)) return(np.array(rList)) def likelihood(beta,betaHat,se,alpha): density=norm.pdf((betaHat-beta)/se) lambdaVal=norm.ppf(1-alpha/2)*se cumu1=norm.cdf(beta/se - lambdaVal/se) cumu2=norm.cdf(-beta/se - lambdaVal/se) if abs(beta)&gt;lambdaVal: indi=1 else: indi=0 like=((density/se)/(cumu1+cumu2))*indi return(like) def lasso(beta,lambdaVal): newBeta=np.sign(beta)*abs(abs(beta)-lambdaVal)*(1 if abs(beta)&gt;lambdaVal else 0) return(newBeta) ss=normRead(ssName,&#39;\\t&#39;) ss=ss[ss[:,5] != &quot;Inf&quot;, :] ss=ss[ss[:,5] != &quot;0&quot;, :] #pdb.set_trace() ssText=ss[:,2:5] ssNums=ss[:,(0,1,5,6,7,8)] ssNums=ssNums.astype(float) goodBetaHolder=np.zeros(ss.shape[0]) for i in range(ss.shape[0]): ssTextRow=ssText[i,:] ssNumsRow=ssNums[i,:] zVal=abs(norm.ppf(ssNumsRow[4])) betaSE=ssNumsRow[3]/zVal if method==&quot;like&quot;: y=minimize(likelihood,1,args=(ssNumsRow[3],betaSE,pLim),method=&#39;nelder-mead&#39;) betaAns=y.x elif method==&quot;lasso&quot;: betaAns=lasso(ssNumsRow[3],inputLambda) goodBetaHolder[i]=betaAns goodBetaHolder.astype(&quot;str&quot;) ss[:,6]=goodBetaHolder np.savetxt(dd+&#39;/summStat&#39;, ss, fmt=&#39;%s&#39;, delimiter=&#39;\\t&#39;) The original publication comes from https://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1006493, there is not any supporting doccumentation. 5.14 Winner’s Curse Likelihood Following directly from the previous method, the corresponding publication came up with a second way to correct for winner’s curse, specifically through maximum likelihood. Prior theorizing in determining true effect sizes in regression have created an equation that gives a point estimate for the likelihood of an effect size. This new likelihood can be thresholded the same way the original P-value was. Once again the publication does not give any recommended values for setting a new series of thresholds, however I have found that the values of 0.05, 0.01, and 0.001 work relatively well. The script that controls the process looks very similar to the previous lasso method. chr=$1 author=$2 dir=$3 low_author=`echo &quot;$author&quot; | tr &#39;[:upper:]&#39; &#39;[:lower:]&#39;` d=comp_zone/dir${dir} plink --memory 4000 --threads 1 --bfile geno_files/${low_author}.${chr} --clump temp_files/ss.${low_author}.${chr} --clump-snp-field RSID --clump-p1 0.5 --clump-r2 0.05 --out ${d}/out sed -e &#39;s/ [ ]*/\\t/g&#39; ${d}/out.clumped | sed &#39;/^\\s*$/d&#39; | cut -f4 | tail -n +2 &gt; ${d}/done_rsids cat temp_files/ss.${low_author}.${chr} | fgrep -w -f ${d}/done_rsids &gt; ${d}/specific_ss i=1 if [ ! -e ~/athena/doc_score/mod_sets/${author}/${low_author}.wc_like.${i}.ss ]; then python helper_scripts/winners_curse.py like 0 $d mv ${d}/summStat ~/athena/doc_score/mod_sets/${author}/${low_author}.${chr}.wc_like.${i}.ss fi let i=i+1 Again, the key step is the python script, which is exactly the same as the one above. For simplicity I will not print it again. 5.15 Winner’s Curse 2D Following mostly in a direct line from the previous publication, the 2D method attempts to remove the winner’s curse from summary statistics. But instead of creating an equation that makes a new thresholding statistic the 2D method carries out clumping just as we did in the original clumping method, except with the additional subsetting of which SNPs are clumped by which cut-off. Specifically, SNPs that are within special regions that have been deemed to be more important will get a more lenient p-value cut-off. The original publication attempts multiple regions, I will use those that seemed to have work best: conserved SNPs, blood eQTL SNPs and pleiotropic SNPs. The other important specification are the respective p-value cut-offs. Lucily for us the original publication does give some advice to this question by providing a nice moutain plot. Three values around the peak for both the important and unimportant SNPs regions were taken from this plot. To carry out the 2D approach we iterate through each of the different p-value and region parameters. Upon each set of parameters we split the summary statistics into the important and unimportant set, clump each set based on their respective p-value, subset the respective summary statistics, then join those two sets back together for the final adjusted summary statistics. The script to do this looks like: chr=$1 author=$2 dir=$3 low_author=`echo &quot;$author&quot; | tr &#39;[:upper:]&#39; &#39;[:lower:]&#39;` d=comp_zone/dir${dir} i=1 cat all_specs/wc_2d_param_specs | tail -n +2 | while read spec;do anno_type=`echo $spec | cut -f1 -d&#39; &#39;` pelse=`echo $spec | cut -f2 -d&#39; &#39;` panno=`echo $spec | cut -f3 -d&#39; &#39;` if [ ! -e ~/athena/doc_score/mod_sets/${author}/${low_author}.wc_2d.${i}.ss ]; then head -1 temp_files/ss.${low_author}.${chr} &gt; ${d}/anno_ss head -1 temp_files/ss.${low_author}.${chr} &gt; ${d}/else_ss cat temp_files/ss.${low_author}.${chr} | fgrep -w -f ~/athena/refs/genome_annotations/${anno_type}_snps &gt;&gt; ${d}/anno_ss cat temp_files/ss.${low_author}.${chr} | fgrep -v -w -f ~/athena/refs/genome_annotations/${anno_type}_snps &gt;&gt; ${d}/else_ss plink --memory 4000 --threads 1 --bfile geno_files/${low_author}.${chr} --clump ${d}/anno_ss --clump-snp-field RSID --clump-p1 $panno --clump-r2 0.1 --out ${d}/out.anno plink --memory 4000 --threads 1 --bfile geno_files/${low_author}.${chr} --clump ${d}/else_ss --clump-snp-field RSID --clump-p1 $pelse --clump-r2 0.1 --out ${d}/out.else if [ -e ${d}/out.anno.clumped ];then sed -e &#39;s/ [ ]*/\\t/g&#39; ${d}/out.anno.clumped | sed &#39;/^\\s*$/d&#39; | cut -f4 | tail -n +2 &gt; ${d}/done_rsids fgrep -w -f ${d}/done_rsids temp_files/ss.${low_author}.${chr} &gt; ${d}/ss.out fi if [ -e ${d}/out.else.clumped ];then sed -e &#39;s/ [ ]*/\\t/g&#39; ${d}/out.else.clumped | sed &#39;/^\\s*$/d&#39; | cut -f4 | tail -n +2 &gt; ${d}/done_rsids fgrep -w -f ${d}/done_rsids temp_files/ss.${low_author}.${chr} &gt;&gt; ${d}/ss.out fi if [ -e ${d}/ss.out ];then mv ${d}/ss.out ~/athena/doc_score/mod_sets/${author}/${low_author}.${chr}.wc_2d.${i}.ss fi rm ${d}/done_rsids rm ${d}/ss.out rm ${d}/out.anno* rm ${d}/out.else* rm ${d}/anno_ss rm ${d}/else_ss fi let i=i+1 done Once again this is the same publication as the likelihood and lasso methods. 5.15.1 Additional Methods Thses are all of the methods that I could find that adjust summary statistics for the purpose of producing a polygenic risk score. I am aware that there are a few other methods, including GraBLD, LDPred-herit, stackCT and others that look similar to what have been presented. However, to the best of my knowledge these methods require phenotypic information. I have decided that if I allow the inclusion of phenotypic information into score generation than I should also test regression methods such as BLUP or alphabet bayesian techniques. Since those are fundamentally not what I am trying to do I am excluding any method that requires phenotypic information. If you know another method that I should evaluate please let me know at sdk2004@med.cornell.edu. "],["compiling-the-scores.html", "6 Compiling the Scores 6.1 Simple Score Approach", " 6 Compiling the Scores Converting the adjusted summary statistics to actual polygenic risk scores should be a trivial task. However, there are a few important computational aspects of this step which can either significantly slow down or altogether ruin the scoring process. Specific to the UK Biobank, the key time and therefore computational problem is converting the given bgenix files into something faller that can be easily read into PLINK. Doing this for all several million SNPs and ~500,000 individuals at once will almost certainly wreck your RAM and is slow as it is not parallelizable. Therefore, I have split up scoring over each of the chromosomes (as it is already natural), and overal each adjusted summary statistic file (as it is simplest). 6.1 Simple Score Approach As already alluded to, the approach I took is simple in nature. The code that processes the scoring of each adjusted summary statistic set is: ss_name=$1 author=$2 method=$3 chr=$4 i=$5 echo $ss_name $author $method $chr $i #Just logistics around controlling parallelism go_num=`head -1 temp_files/poss_go` grep -v -w $go_num temp_files/poss_go &gt; temp_files/temp_poss mv temp_files/temp_poss temp_files/poss_go low_author=`echo &quot;$author&quot; | tr &#39;[:upper:]&#39; &#39;[:lower:]&#39;` ver=`echo $ss_name | cut -f4 -d&#39;.&#39;` if [ ! -e small_score_files/score.${low_author}.${chr}.${ver}.${method}.profile.zst ];then cat ../mod_sets/${author}/${ss_name} | cut -f3 &gt; temp_files/rsids.${i} bgenix -g ~/athena/ukbiobank/imputed/ukbb.${chr}.bgen -incl-rsids temp_files/rsids.${i} &gt; temp_files/temp.${i}.bgen plink2_new --memory 12000 --threads 12 --bgen temp_files/temp.${i}.bgen ref-first --sample ~/athena/ukbiobank/imputed/ukbb.${chr}.sample --keep-fam temp_files/brit_eid --make-bed --out temp_files/geno.${i} plink --memory 12000 --threads 12 --bfile temp_files/geno.${i} --keep-allele-order --score ../mod_sets/${author}/${ss_name} 3 4 7 sum --out small_score_files/score.${low_author}.${chr}.${ver}.${method} zstd --rm small_score_files/score.${low_author}.${chr}.${ver}.${method}.profile rm temp_files/rsids.${i} rm temp_files/temp.${i}.bgen rm temp_files/geno.${i}.* else echo already exists fi #Just logistics around controlling parallelism echo $go_num &gt;&gt; temp_files/poss_go The key and simple steps are: one, we get the rsids that are included in the adjusted summary statistic set; two, we use bgenix to subset the original UKBB imputation file to a (hopefully) much smaller subset; three, we produce a bed/bim/fam fileset through plink2; four, we produce the actual scores with PLINK. There are a few other important statements, namely to check to see if the score exists (either in the small_score_files or final_scores directory) before trying to make it anew. 6.1.1 What to Worry About There are a few things that I did not think of originally that should be considered in order to make accurate and even remotely realistic scores. 1 - Matching Alleles - As we already carefully went over when creating clean summary statistics from those orginally downloaded, the alleles in the summary statistics must match the genotype file you are working with. When dealing with the original bgen files this is true. But, when we subset (to say only British individuals) the allele may be flipped if the major allele flips (important, this is true for PLINK but not for PLINK2). To prevent this behavoir in PLINK we use the –keep-allele-order flag. 2 - Sum - The default PLINK behavoir is to average the score in its output. Therefore, the ultimate score is based on the number of SNPs. This becomes a problem if we are creating a larger score by running several PLINK routines on each chromosome and adding up the results. Specifically, because the score will be weighted based on the number of SNPs on each chromosome, not the beta values. To fix this we use the “sum” option, which no longer does any of this averaging. 3 - Allele Frequency - The default behavoir of the PLINK scoring routine is when an allele is unknown an amount proportional to the allele frequency is added. This can be pretty confusing so please check out https://zzz.bwh.harvard.edu/plink/profile.shtml, which has a simple example. The problem here is the exact allele frequency being used. If we used –keep-fam and –score in the same plink call, then the allele frequency is derived from the non-family subset. So instead we must subset into the bed/bim/fam files, and then in a seperate PLINK call we do the scoring. 4 - Round-Off Error - This is a much smaller issue, but in nearly all computational tasks with thousands of multiplications between small values, there is bound to be round off error. While I admit I have not done anything to correct for it, it could be a good idea in the future to multiply the beta values by a fixed value to bring everything futher awayfrom small values. Although, I should clarify, while scores change I have not noticed any changes in the order of individuals. 6.1.2 Controlling and Assembling All of this scoring, for each chromosome, author, etc. are controlled by the following script. This is a very similar process to the one that controls the adjusting summary statistic process, so I won’t go into too much detail explaining. maxGo=18 rm temp_files/poss_go cat ../qc/cv_files/train_eid.0.2.txt | cut -f1 &gt; temp_files/brit_eid cat ../qc/cv_files/test_eid.0.8.txt | cut -f1 &gt;&gt; temp_files/brit_eid for (( i=1; i&lt;=$maxGo; i++ )); do echo $i &gt;&gt; temp_files/poss_go done echo 1 &gt; temp_files/counter cat all_specs/author_specs | while read cauthor;do cat all_specs/method_specs | while read cmethod;do for cchr in {1..22};do ls ../mod_sets/${cauthor}/ | fgrep -w ${cmethod} | awk -v var=&quot;$cchr&quot; -F. &#39;$2 == var {print $0}&#39; | while read cname;do counter_var=`cat temp_files/counter` echo $counter_var ./simple_score.sh $cname $cauthor $cmethod $cchr $counter_var &amp;&gt; logs/log.${counter_var}.log &amp; echo $counter_var + 1 | bc &gt; temp_files/counter sleep $(( ( RANDOM % 10 ) + 1 )) goOn=False while [ $goOn == &quot;False&quot; ]; do openSlots=`cat temp_files/poss_go | wc -l` sizedir=`du temp_files/ | cut -f1` if [ $openSlots -gt 0 ]; then if [ $sizedir -lt 50164096 ];then echo NOW WE CAN GO goOn=True fi else echo MUST WAIT FOR ROOM TO GO sleep $(( ( RANDOM % 5 ) + 1 )) fi done done done done done The final script needed in this process is assembling. The process begins by getting the names of all the small score files, then the method, version, and author are extracted. Then we simply line up the files that have the same qualities except for the chromosomes, read them in then add them together. Note that the system() command must be used to zstd decompress and then remove the uncompressed file. There may be a faster way to do this directly in R in the future. There very well may be a better way to do this since this is alot of IO work. but it gets the job done. Although again I want to note that PLINK rounds off all of the scores in the chromosomes leading to possibly problematic round-off error. library(data.table) all_files &lt;- list.files(&quot;small_score_files/&quot;, pattern = &quot;profile&quot;) split_files &lt;- strsplit(all_files, &quot;.&quot;, fixed = T) all_author &lt;- unlist(lapply(split_files, function(x) x[2])) all_chr &lt;- unlist(lapply(split_files, function(x) x[3])) all_ind &lt;- unlist(lapply(split_files, function(x) x[4])) all_method &lt;- unlist(lapply(split_files, function(x) x[5])) brit_eid &lt;- read.table(&quot;temp_files/brit_eid&quot;, stringsAsFactors=F) new_name &lt;- unique(paste0(all_author, &quot;.&quot;, all_ind, &quot;.&quot;, all_method)) all_score &lt;- matrix(0, nrow = nrow(brit_eid), ncol = length(new_name)) almost_new_name &lt;- paste0(all_author, &quot;.&quot;, all_ind, &quot;.&quot;, all_method) colnames(all_score) &lt;- new_name firstup &lt;- function(x) { substr(x, 1, 1) &lt;- toupper(substr(x, 1, 1)) return(x) } all_upauthor &lt;- firstup(all_author) all_upauthor[all_upauthor == &quot;Imsgc&quot;] &lt;- &quot;IMSGC&quot; i &lt;- 1 j &lt;- 1 for(i in 1:length(all_files)){ real_mod_set &lt;- c(grep(paste0(tolower(all_author[i]), &quot;.[[:digit:]][[:digit:]].&quot;, all_method[i], &quot;.&quot;, all_ind[i], &quot;.ss&quot;), list.files(paste0(&quot;../mod_sets/&quot;, all_upauthor[i],&quot;/&quot;)), value = T), grep(paste0(tolower(all_author[i]), &quot;.[[:digit:]].&quot;, all_method[i], &quot;.&quot;, all_ind[i], &quot;.ss&quot;), list.files(paste0(&quot;../mod_sets/&quot;, all_upauthor[i], &quot;/&quot;)), value = T)) real_scored &lt;- c(grep(paste0(&quot;score.&quot;, tolower(all_author[i]), &quot;.[[:digit:]].&quot;, all_ind[i], &quot;.&quot;, all_method[i], &quot;.profile.zst&quot;), all_files, value = T), grep(paste0(&quot;score.&quot;, tolower(all_author[i]), &quot;.[[:digit:]][[:digit:]].&quot;, all_ind[i], &quot;.&quot;, all_method[i], &quot;.profile.zst&quot;), all_files, value = T)) if(length(real_mod_set) == length(real_scored)){ system(paste0(&quot;zstd -d small_score_files/&quot;, all_files[i])) sub_score &lt;- as.data.frame(fread(paste0(&quot;small_score_files/&quot;, substr(all_files[i], 1, nchar(all_files[i])-4)))) system(paste0(&quot;rm small_score_files/&quot;, substr(all_files[i], 1, nchar(all_files[i])-4))) all_score[,new_name == almost_new_name[i]] &lt;- all_score[,new_name == almost_new_name[i]] + sub_score$SCORESUM } } all_score &lt;- all_score[,colSums(all_score) != 0] next_file &lt;- length(grep(&quot;RDS&quot;, list.files(&quot;final_scores&quot;, &quot;all_score&quot;))) + 1 write.table(all_score, paste0(&quot;final_scores/all_score.&quot;, next_file), row.names = F, col.names = T, quote = F, sep = &#39; &#39;) saveRDS(all_score, paste0(&quot;final_scores/all_score.&quot;, next_file, &quot;.RDS&quot;)) write.table(colnames(all_score), paste0(&quot;final_scores/done_names.&quot;, next_file), row.names = F, col.names = F, quote = F) system(paste0(&quot;gzip final_scores/all_score.&quot;, next_file)) 6.1.3 Verifying Everything Worked As perhaps I have alluded to, scoring is actually not as straightforward as it seems. By taking steps that make it computationally easier there may be inaccuracies that infiltrate your final scores. Therefore, one should check whether the scores made with whatever nice and fancy approach are the same as scores made with the simplest, most fool-proof approach. Specifically, I am thinking about creating one large PLINK file with all of the SNPs needed for the desired score creation, then in one PLINK command creating the score. This process will require iterating through all of the 22 chromosomes and creating a small PLINK file, then in the end merging them all together, and finally creating the actual score desired. The code looks like: rm try_single_score/ss rm try_single_score/rsids rm try_single_score/geno_list Author=IMSGC author=imsgc for chr in {1..22};do cat ../mod_sets/${Author}/${author}.${chr}.clump.1.ss &gt;&gt; try_single_score/ss cat ../mod_sets/${Author}/${author}.${chr}.clump.1.ss | cut -f3 &gt; try_single_score/rsids bgenix -g ~/athena/ukbiobank/imputed/ukbb.${chr}.bgen -incl-rsids try_single_score/rsids &gt; try_single_score/temp.bgen plink2_new --memory 12000 --threads 12 --bgen try_single_score/temp.bgen ref-first --sample ~/athena/ukbiobank/imputed/ukbb.1.sample --keep-fam temp_files/brit_eid --make-bed --out try_single_score/geno.${chr} echo try_single_score/geno.${chr} &gt;&gt; try_single_score/geno_list done plink --merge-list try_single_score/geno_list --make-bed --out try_single_score/all plink --bfile try_single_score/all --keep-allele-order --score try_single_score/ss 3 4 7 no-sum --out try_single_score/score.${author}.clump.1 After the score is created we can compare it to what we have already done. This simply requires reading both scores in and taking the correlation between the two. However, the correlation is not the only thing that matters. Many analyses rely on ranks, therefore I also checked to see if the ranks of both scores are the same. Alas they are not exactly the same, but they are very similar. Seeing as this difference is possibly (likely?) due to round-off error, which I cannot eliminate, and the difference is very likely negligible, I will call my scoring system a success. See the code below for the actual score checking. author &lt;- &quot;imsgc&quot; Author &lt;- &quot;IMSGC&quot; all_score &lt;- readRDS(&quot;final_scores/all_score.1.RDS&quot;) template_score &lt;- read.table(&quot;template.profile&quot;, stringsAsFactors=F, header=T) fileind &lt;- which(colnames(all_score) == paste0(author, &quot;.1.clump&quot;)) new_score &lt;- read.table(paste0(&quot;try_single_score/score.&quot;, author, &quot;.clump.1.profile&quot;), stringsAsFactors=F, header=T) new_score &lt;- new_score[order(new_score[,1])[rank(template_score[,1])],] cor(all_score[,fileind], new_score$SCORE) cor(rank(new_score$SCORE, ties.method=&quot;average&quot;), rank(all_score[,fileind], ties.method=&quot;average&quot;)) mean_dif &lt;- mean(abs(rank(new_score$SCORE, ties.method=&quot;average&quot;) - rank(all_score[,fileind], ties.method=&quot;average&quot;))) max_dif &lt;- max(abs(rank(new_score$SCORE, ties.method=&quot;average&quot;) - rank(all_score[,fileind], ties.method=&quot;average&quot;))) 6.1.4 Other Options I also want to quickly note that this scoring implementation was not my first, or even third try to score the files. The first attempt eventually used PLINK2, which allows you to score multiple columns of beta values simultaneously. While faster, I noticed there to be some scoring errors because of the many zero values that would line up between the scoring files. Perhaps I was reading it wrong, but I assume it is not worth risking bad scores. Quickly, a second attempt used the bigsnpr package, which turned out to be too slow within R. "],["score-analysis-set-up.html", "7 Score Analysis Set-Up 7.1 Defining the Phenotypes 7.2 Making the Phenotype 7.3 Other Scores 7.4 Other Covariates", " 7 Score Analysis Set-Up Now that we have the scores we are nearly ready for analysis. However, there are actually several more things that need to be done, namely setting up all of the phenotypes and covariates. Similar to creating the scores, this is an often underrated process that needs to be done carefully or everything else fails. 7.1 Defining the Phenotypes By phenotype I mean status of whether an individual has the disease corresponding to the polygenic risk score. This is a tricky problem, since first of all each underlying GWAS of the polygenic risk scores may construct phenotypes differently. Adjusting our phenotypes to each GWAS does not seem easy however, or even possible given the limited information within the UK Biobank. However the UK Biobank does have a great deal of information. The sources that we will use to construct phenotypes are as follows: Self-Reported - Each individual was interviewed by a trained nurse and asked about any illnesses they may have. The nurse then placed any description by the individual into a pre-specified tree of diseases. This data can be suspect as the individual may report self-diagnoses not confirmed by a doctor and not really existing, but overall they are likely to line up with actual conditions for most of the individuals. Further description on the self-reported data-type can be found here, http://biobank.ndph.ox.ac.uk/showcase/field.cgi?id=20002, and all possible self-reported codings can be found here, http://biobank.ndph.ox.ac.uk/showcase/coding.cgi?id=3, and here http://biobank.ndph.ox.ac.uk/showcase/coding.cgi?id=6 (for cancer and non-cancer). ICD - The UK Biobank has pulled in the electronic health record of every individual. Specifically, when a doctor makes a diagnosis they will record the ICD code in the computer. These should be highly accurate, however there is always the change of a typo or a doctor recording a similar diagnosis that does not quite match what we want, making ICD codes rather fickle. These records have been parsed into hesin files (hospital episode statistics). In short there this one file, hesin_diag, with ICD codes on every line, and another file, hesin, with dates of hospital episodes. One can look up the dates for a given ICD code by using the EID and instance index. We will go over this more later. More information on the hesin data can be found here, https://biobank.ndph.ox.ac.uk/showcase/showcase/docs/HospitalEpisodeStatistics.pdf. The coding for ICD9 codes can be found here, http://biobank.ndph.ox.ac.uk/showcase/coding.cgi?id=87. The coding for ICD10 codes can be found here, http://biobank.ndph.ox.ac.uk/showcase/coding.cgi?id=19. Note that ICD9 codes are older than ICD10. OPCS - Similar to ICD, OPCS codes are generally part of the electronic health record and are accessed from the hesin set of files. However, instead of recording diagnoses they record operations. While generally not helpful for our purposes, some publications have used specific OPCS codes to assume that an underlying phenotype was the cause. Following precendent I will do the same. More information on OPCS coding can be found here, http://biobank.ndph.ox.ac.uk/showcase/coding.cgi?id=240. There are also OPCS3 codes, but they are very, very sparse. Medications - This is the least orthodox way of determining phenotype. But I figure if someone is taking a medication that is only used for one illness, then there is a very good chance the person has that illness. Unfortunately the UK Biobank does not have to the day records of medications, but only inventories when individuals come in for assessments. By looking over CDC, respective professional society, and Mayo Clinic websites I determine the associated medications and convert them into the UK Biobank codes. More information on Medication coding can be found here, http://biobank.ndph.ox.ac.uk/showcase/coding.cgi?id=4. More information on how medication data was recorded can be found here, http://biobank.ndph.ox.ac.uk/showcase/field.cgi?id=20003. The table that actually holds the conversion from the many possible codes of each category into a 1/0 phenotype is as follows. pheno_defs &lt;- read.table(&quot;../analyze_score/descript_defs/author_defs&quot;, stringsAsFactors=F, header=T) print(pheno_defs) ## author name sex cancer noncancer ## 1 Bentham sle A NA 1381 ## 2 Christophersen atrial_fibrilation A NA 1471 ## 3 Demenais asthma A NA 1111 ## 4 Demontis adhd A NA &lt;NA&gt; ## 5 Dubois celiac_disease A NA 1456 ## 6 Gormley migraine A NA 1265 ## 7 IMSGC ms A NA 1261 ## 8 Jin vitiligo A NA 1661 ## 9 Kottgen gout A NA 1466 ## 10 Liu-1 ulcerative_colitis A NA 1463 ## 11 Liu-2 crohns_disease A NA 1462 ## 12 Mahajan type_2_diabetes A NA 1223 ## 13 Malik stroke A NA 1081 ## 14 Michailidou breast_cancer F 1002 &lt;NA&gt; ## 15 Namjou nonalcoholic_fatty_liver_disease A NA &lt;NA&gt; ## 16 Nikpay coronary_artery_disease A NA 1075|1076 ## 17 Okada rheumatoid_arthritis A NA 1464 ## 18 Onengut type_1_diabetes A NA 1222 ## 19 Phelan ovarian_cancer F 1039 &lt;NA&gt; ## 20 Rheenen als A NA &lt;NA&gt; ## 21 Schumacher prostate_cancer M 1044 &lt;NA&gt; ## 22 Shah heart_failure A NA 1076 ## 23 Sklar bipolar_disease A NA 1291 ## 24 Tsoi psoriaris A NA 1453 ## 25 Wray major_depressive_disorder A NA 1286 ## 26 Xie membranous_glomerulonephritis A NA &lt;NA&gt; ## icd9 icd10 ## 1 710 M321|M328|M329 ## 2 4273 I48 ## 3 493 J45|J46 ## 4 314 F90 ## 5 579 &lt;NA&gt; ## 6 346 G43 ## 7 340 G35 ## 8 7091 L80 ## 9 274 M10 ## 10 556 K51 ## 11 555 K50 ## 12 &lt;NA&gt; E11 ## 13 431|432|433|434|435|436|437|438 I60|I61|I62|I633|I64|I65|I66|I67|I68|I69 ## 14 174 C50 ## 15 5718 K760 ## 16 410|411|412 I21|I22|I23|I241|I252 ## 17 714 M05|M06 ## 18 &lt;NA&gt; E10 ## 19 183 C56 ## 20 3352 G122 ## 21 185 C61 ## 22 428 I50 ## 23 296 F31 ## 24 6960|6961 L40 ## 25 &lt;NA&gt; F33 ## 26 5831 N002 ## opcs ## 1 &lt;NA&gt; ## 2 K622|K623 ## 3 &lt;NA&gt; ## 4 &lt;NA&gt; ## 5 &lt;NA&gt; ## 6 &lt;NA&gt; ## 7 &lt;NA&gt; ## 8 &lt;NA&gt; ## 9 &lt;NA&gt; ## 10 &lt;NA&gt; ## 11 &lt;NA&gt; ## 12 &lt;NA&gt; ## 13 U543|Z35 ## 14 B27|B28|B29 ## 15 &lt;NA&gt; ## 16 K40|K41|K45|K49|K50|K75 ## 17 U504 ## 18 &lt;NA&gt; ## 19 &lt;NA&gt; ## 20 X852 ## 21 &lt;NA&gt; ## 22 &lt;NA&gt; ## 23 &lt;NA&gt; ## 24 &lt;NA&gt; ## 25 &lt;NA&gt; ## 26 &lt;NA&gt; ## meds ## 1 &lt;NA&gt; ## 2 1140888482 ## 3 1141168340 ## 4 &lt;NA&gt; ## 5 &lt;NA&gt; ## 6 1141163670|1141167932|1141172728|1141185436|1141192666|1141150620|1141151284 ## 7 1141188640|1141188642|1141150596|1141172620|1141165546|1141167618|1141189254|1141189256 ## 8 &lt;NA&gt; ## 9 1140875408 ## 10 1141153242 ## 11 &lt;NA&gt; ## 12 &lt;NA&gt; ## 13 &lt;NA&gt; ## 14 1140923018|1141190734 ## 15 &lt;NA&gt; ## 16 &lt;NA&gt; ## 17 1141145896|1140909702|1141188588|1141180070|1140871188 ## 18 &lt;NA&gt; ## 19 &lt;NA&gt; ## 20 1141195974 ## 21 1141150594|1140870274|1140921100 ## 22 &lt;NA&gt; ## 23 &lt;NA&gt; ## 24 &lt;NA&gt; ## 25 &lt;NA&gt; ## 26 &lt;NA&gt; The pipe symbol is used to indicate that if any of the codes can be found in the respective data type the phenotype will be called positive. 7.2 Making the Phenotype Now that we know what codes go to which phenotype, we simply need to go through the respective data files and check off when we find one for each EID. Easier said than done, so I’ve broken down things into parts. The first part is preparing the data, specifically breaking down the large phenotype file downloaded from the UK Biobank into parts that are easy to inspect and read in. Along with these files, the hesin files are also nescessary, although they do not need any breaking down. I would display these files but I do not think I am allowed to. Anyway, the breaking down scripts looks like the following (note that if following along your indices are likely different). #self diag from 472 to 573 #date attend assessment center from 41 to 43 #medication from 574 to 717 zcat ~/athena/ukbiobank/phenotypes/ukb26867.csv.gz | cut -d&#39;,&#39; -f1 &gt; eid.csv zcat ~/athena/ukbiobank/phenotypes/ukb26867.csv.gz | cut -d&#39;,&#39; -f472-573 &gt; self_report_diag.csv zcat ~/athena/ukbiobank/phenotypes/ukb26867.csv.gz | cut -d&#39;,&#39; -f454-471 &gt; self_report_cancer.csv zcat ~/athena/ukbiobank/phenotypes/ukb26867.csv.gz | cut -d&#39;,&#39; -f41-43 &gt; date_assessed.csv zcat ~/athena/ukbiobank/phenotypes/ukb26867.csv.gz | cut -d&#39;,&#39; -f574-717 &gt; medications.csv Now that everything is prepared data-wise we can get on with inspecting and calling phenotypes. I have tried this in many different ways, and the fastest option seems to be breaking down the total 500,000 people into groups and calling phenotypes for each group in parallel. This parallel component is controlled by the following script, which is straightforward. cat parallel_splits | while read line;do star=`echo $line | cut -d&#39; &#39; -f1` end=`echo $line | cut -d&#39; &#39; -f2` echo $star python better_pheno.py $star $end &amp; sleep 80 done As you may be able to see the key script here is called better_pheno.py. This script has a few different parts. First it reads in all of the prepared data. Next it subsets down to the group of individuals specified by the control_make_pheno, and sorts each file so the EIDs line up. This sorting is important as it allows for quick indexing of EIDs (just iterate to the next unique EID rather than searching for the index). Lastly I check each type of phenotype (self-report, ICD, etc.) for the coding that was specified. For the ICD and OPCS this process required me to check not just the exact code, but also a more general code due to the hierarchical natur of their coding. For example if I am looking for G35 and an individual has G351 then I will still count that as a match. Further details on how this script works can be found in the well recorded comments of the script itself, which starts below. import numpy as np import datetime import time import pickle import pdb import gzip import os import sys import sys import re #Declare the author that corresponds to the phenotype you want #Also the indices of the group we want phenotypes for author = &quot;Christophersen&quot; start_ind = int(sys.argv[1]) end_ind = int(sys.argv[2]) #Function to read in the data def normRead(fileName, withHeader = True, delim = &#39;\\t&#39;, removeQuote = False): with open(fileName,&quot;r&quot;,encoding = &quot;latin-1&quot;) as f: totalData=[] for line in f.read().splitlines(): if removeQuote: totalData.append(line.replace(&#39;&quot;&#39;, &#39;&#39;).strip().split(delim)) else: totalData.append(line.split(delim)) if withHeader: header=totalData[0] del totalData[0] else: header = None totalData=np.array(totalData) return(totalData,header) #Read in the files that were split from the main UKBB phenotype file date_ass,ass_header = normRead(&quot;date_assessed.csv&quot;, True, &quot;,&quot;, True) meds, meds_header = normRead(&quot;medications.csv&quot;, True, &quot;,&quot;, True) self_rep, self_rep_header = normRead(&quot;self_report_diag.csv&quot;, True, &quot;,&quot;, True) cancer_rep, cancer_rep_header = normRead(&quot;self_report_cancer.csv&quot;, True, &quot;,&quot;, True) big_eid, eid_head = normRead(&quot;eid.csv&quot;, True, &quot;,&quot;, True) #sort the files just read in so they are in EID order date_ass = date_ass[big_eid[:,0].argsort(),:] meds = meds[big_eid[:,0].argsort(),:] self_rep = self_rep[big_eid[:,0].argsort(),:] cancer_rep = cancer_rep[big_eid[:,0].argsort(),:] big_eid = big_eid[big_eid[:,0].argsort(),:] #Get the phase, or the assessment type for cancer, self-report and medication report #Phase meaning what index, or what time the person came in to be assessed (first, second or third assessment) cancer_phase = [x.split(&quot;-&quot;)[1].split(&quot;.&quot;)[0] for x in cancer_rep_header] self_phase = [x.split(&quot;-&quot;)[1].split(&quot;.&quot;)[0] for x in self_rep_header] meds_phase = [x.split(&quot;-&quot;)[1].split(&quot;.&quot;)[0] for x in meds_header] #Read in the hesin type of data and again sort by EID diag, head_diag = normRead(&quot;/home/kulmsc/athena/ukbiobank/hesin/hesin_diag.txt&quot;) oper, head_oper = normRead(&quot;/home/kulmsc/athena/ukbiobank/hesin/hesin_oper.txt&quot;) hesin, head_hesin = normRead(&quot;/home/kulmsc/athena/ukbiobank/hesin/hesin.txt&quot;) diag = diag[diag[:,0].argsort(),:] oper = oper[oper[:,0].argsort(),:] hesin = hesin[hesin[:,0].argsort(),:] diag_eid = np.unique(diag[:,0]) oper_eid = np.unique(diag[:,0]) diag_max = diag.shape[0] - 1 oper_max = oper.shape[0] - 1 diag_eid_list = diag[:,0].tolist() oper_eid_list = oper[:,0].tolist() #Read in the disease defintion and split the types with multiple condictions, then make into a dict defs, head_defs = normRead(&quot;../descript_defs/author_defs&quot;) def_ind = defs[:,0].tolist().index(author) split_defs = list() for type_def in defs[def_ind, 3:9]: split_defs.append(type_def.split(&quot;|&quot;)) #Produce a dictionary so we can easily pull out the codes for each data type use_defs = dict(zip(head_defs[3:9], split_defs)) #This if for timing, which I do not do anymore #cancer_sr_time = 0 #noncancer_sr_time = 0 #hesin_setup_time = 0 #icd9_time = 0 #icd10_time = 0 #hesin_oper_time = 0 #med_time = 0 #Find the splits of the input data, so RAM will be less #Simply find the eid corresponding to the start and stop index #Continuing to skip them if they do not appear in the given data type def subset_big_data(eid_list, big_data): for ind in range(start_ind, end_ind): if big_eid[ind][0] in eid_list: start_eid = eid_list.index(big_eid[ind][0]) break for ind in range(end_ind, start_ind,-1): if big_eid[ind][0] in eid_list: end_eid = np.where(big_data[:,0] == big_eid[ind][0])[0][-1] break return(big_data[start_eid:end_eid,:]) #I&#39;m still bad at python indexing so I have to include this line to fix a single case example if end_ind &gt; big_eid.shape[0]: end_ind = big_eid.shape[0] - 1 #Apply the subset_big_data, and convert some things to lists for easier indexing diag = subset_big_data(diag_eid_list, diag) oper = subset_big_data(oper_eid_list, oper) hesin = subset_big_data(hesin[:,0].tolist(), hesin) diag_eid_list = diag[:,0].tolist() oper_eid_list = oper[:,0].tolist() #Establish indicdes of diag and oper for easy indexing (do not need to look and make index every time #only need to add the extent of the current eid to this index) start_eid_diag = 0 start_eid_oper = 0 #Subset the things that do not require the subset_big_data function meds = meds[start_ind:end_ind,:] self_rep = self_rep[start_ind:end_ind,:] date_ass = date_ass[start_ind:end_ind,:] cancer_rep = cancer_rep[start_ind:end_ind,:] big_eid = big_eid[start_ind:end_ind,:] #Prepare the data objects that will hold diagnosis results df_occur = np.zeros((big_eid.shape[0], 6)) df_date = np.tile(&quot;__________&quot;, (big_eid.shape[0], 6)) #Iterate through the indices of each unique EID #Note for lessons learned in speed-up: # - do not subset objects (I think copies are made in RAM which really slow things down) # - always try to just iterate to the next index rather than searching for some keyword for ind in range(0, (end_ind - start_ind)): if ind % 10000 == 0: print(ind) #So I know how fast things are running #Set the value of the actual eid curr_eid = big_eid[ind][0] #Now we go through and fill in each column of df_occur and df_date, one data type at a time #CANCER SELF REPORT (this is the name of the column in df_occur and df_date I am filling in) if use_defs[&quot;cancer&quot;][0] != &quot;NA&quot;: #check to see if there is a noncancer definition #t1 = time.time() if any(np.isin(use_defs[&quot;cancer&quot;], cancer_rep[ind,:])): #if the cancer definition is in the cancer data locs = np.where(np.isin(cancer_rep[ind,:], use_defs[&quot;cancer&quot;]))[0] #get assessment index of the cancer occurence try_date = date_ass[ind, int(cancer_phase[locs[0]])] #record the date based on index of ind. assessment if try_date == &quot;&quot;: #somtimes the data is empty so we go back to the last date we know try_date = date_ass[ind,0] df_date[ind,0] = try_date df_occur[ind,0] = 1 #t2 = time.time() #cancer_sr_time += t2-t1 #NON-CANCER SELF REPORT #this is the same process as with the cancer data, but now with non-cancer data if use_defs[&quot;noncancer&quot;][0] != &quot;NA&quot;: #t22 = time.time() if any(np.isin(use_defs[&quot;noncancer&quot;], self_rep[ind,:])): locs = np.where(np.isin(self_rep[ind,:], use_defs[&quot;noncancer&quot;]))[0] try_date = date_ass[ind, int(self_phase[locs[0]])] if try_date == &quot;&quot;: try_date = date_ass[ind, 0] df_date[ind,1] = try_date df_occur[ind,1] = 1 #t3 = time.time() #noncancer_sr_time += t3-t22 #HESIN DIAG if curr_eid in diag_eid_list: #check if the eid has ever had any ICD codes #t4 = time.time() #set up the hesin indexing, since multiple rows can have the same eid we use this #use this technique to get the index of the next unique EID if curr_eid != diag_eid_list[-1]: next_eid = np.unique(diag[start_eid_diag:(start_eid_diag+7000),0])[1] ext_eid = diag_eid_list.index(next_eid) else: ext_eid = diag_max #t5 = time.time() #hesin_setup_time += t5-t4 #ICD - 9 #as was explained either the full or slightly shorter ICD code may match what we want, so we create both use_short_icd9_diag = [x[0:3] for x in diag[start_eid_diag:ext_eid,4]] #Then we check to see if either the short short or long ICD codes (from the hesin) match any of the definitions if any(np.isin(use_defs[&quot;icd9&quot;], use_short_icd9_diag)): #If there is a match we get all of the locations in the hesin of the match short_icd9_locs = np.where(np.isin(use_short_icd9_diag, use_defs[&quot;icd9&quot;]))[0][0] else: short_icd9_locs = 10000 if any(np.isin(use_defs[&quot;icd9&quot;], diag[start_eid_diag:ext_eid,4])): long_icd9_locs = np.where(np.isin(diag[start_eid_diag:ext_eid,4], use_defs[&quot;icd9&quot;]))[0][0] else: long_icd9_locs = 10000 #There cannot possibly be a match greater than 10000, so I set it to the impossible value if long_icd9_locs != 10000 or short_icd9_locs != 10000: #Find the minimum matching location as it is the earliest time icd9_locs = min((long_icd9_locs, short_icd9_locs)) #Then we get the instance or the numbered time the EID went to the hospital icd9_ins_index = diag[start_eid_diag+icd9_locs,1] #We carry the ins_index and EID to the larger hesin array to get the date #Somtimes the most accurate form of the date is empty so we go to the next best raw_date = hesin[np.logical_and(hesin[:,0] == curr_eid, hesin[:,1] == icd9_ins_index),5][0] if raw_date == &quot;&quot;: raw_date = hesin[np.logical_and(hesin[:,0] == curr_eid, hesin[:,1] == icd9_ins_index),21][0] if raw_date == &quot;&quot;: raw_date = hesin[np.logical_and(hesin[:,0] == curr_eid, hesin[:,1] == icd9_ins_index),4][0] df_occur[ind,2] = 1 df_date[ind,2] = raw_date #t6 = time.time() #icd9_time += t6-t5 #The process for ICD10 is nearly exactly the same as for ICD9 #ICD - 10 use_short_icd10_diag = [x[0:3] for x in diag[start_eid_diag:ext_eid,6]] if any(np.isin(use_defs[&quot;icd10&quot;], use_short_icd10_diag)): short_icd10_locs = np.where(np.isin(use_short_icd10_diag, use_defs[&quot;icd10&quot;]))[0][0] else: short_icd10_locs = 10000 if any(np.isin(use_defs[&quot;icd10&quot;], diag[start_eid_diag:ext_eid,6])): long_icd10_locs = np.where(np.isin(diag[start_eid_diag:ext_eid,6], use_defs[&quot;icd10&quot;]))[0][0] else: long_icd10_locs = 10000 if long_icd10_locs != 10000 or short_icd10_locs != 10000: icd10_locs = min((long_icd10_locs, short_icd10_locs)) icd10_ins_index = diag[start_eid_diag+icd10_locs,1] raw_date = hesin[np.logical_and(hesin[:,0] == curr_eid, hesin[:,1] == icd10_ins_index),5][0] if raw_date == &quot;&quot;: raw_date = hesin[np.logical_and(hesin[:,0] == curr_eid, hesin[:,1] == icd10_ins_index),21][0] if raw_date == &quot;&quot;: raw_date = hesin[np.logical_and(hesin[:,0] == curr_eid, hesin[:,1] == icd10_ins_index),4][0] df_occur[ind,3] = 1 df_date[ind,3] = raw_date start_eid_diag = ext_eid #t7 = time.time() #icd10_time += t7-t6 #The process for HESIN OPER is nearly exactly the same as for HESIN DIAG (which includes ICD10 and ICD)) #HESIN OPER if curr_eid in oper_eid_list and use_defs[&quot;opcs&quot;][0] != &quot;NA&quot;: #t8 = time.time() if curr_eid != oper_eid_list[-1]: #if it is not the last in the list next_eid = np.unique(oper[start_eid_oper:(start_eid_oper+7000),0])[1] ext_eid = oper_eid_list.index(next_eid) else: ext_eid = oper_max use_short_oper = [x[0:3] for x in oper[start_eid_oper:ext_eid,7]] if any(np.isin(use_defs[&quot;opcs&quot;], use_short_oper)): short_oper_locs = np.where(np.isin(use_short_oper, use_defs[&quot;opcs&quot;]))[0][0] else: short_oper_locs = 10000 if any(np.isin(use_defs[&quot;opcs&quot;], oper[start_eid_oper:ext_eid,7])): long_oper_locs = np.where(np.isin(oper[start_eid_oper:ext_eid,7], use_defs[&quot;opcs&quot;]))[0][0] else: long_oper_locs = 10000 if long_oper_locs != 10000 or short_oper_locs != 10000: oper_locs = min((long_oper_locs, short_oper_locs)) oper_ins_index = oper[start_eid_oper+oper_locs,1] raw_date = hesin[np.logical_and(hesin[:,0] == curr_eid, hesin[:,1] == oper_ins_index),5][0] if raw_date == &quot;&quot;: raw_date = hesin[np.logical_and(hesin[:,0] == curr_eid, hesin[:,1] == oper_ins_index),21][0] if raw_date == &quot;&quot;: raw_date = hesin[np.logical_and(hesin[:,0] == curr_eid, hesin[:,1] == oper_ins_index),4][0] df_occur[ind,4] = 1 df_date[ind,4] = raw_date start_eid_oper = ext_eid #t9 = time.time() #hesin_oper_time += t9-t8 #The medication process is nearly the same as for cancer and non-cancer #MEDICATION if use_defs[&quot;meds&quot;][0] != &quot;NA&quot;: #t10 = time.time() if any(np.isin(use_defs[&quot;meds&quot;], meds[ind,:])): locs = np.where(np.isin(meds[ind,:], use_defs[&quot;meds&quot;]))[0] df_date[ind,5] = date_ass[ind, int(meds_phase[locs[0]])] df_occur[ind,5] = 1 #t11 = time.time() #med_time += t11 - t10 #save the output phenos np.savetxt(&quot;raw_output/diag.coding.&quot; + author.lower() + &quot;.&quot; + str(start_ind) + &quot;.txt.gz&quot;, df_occur, fmt=&#39;%i&#39;) np.savetxt(&quot;raw_output/diag.time.&quot; + author.lower() + &quot;.&quot; + str(start_ind) + &quot;.txt.gz&quot;, df_date, fmt=&#39;%s&#39;) print(&quot;end&quot;) The final step in the process is combining all of the small subset phenotype file into one large phenotype file. The mechanics of this script are very simple, as all that needs to be done is iterating over the subsets and concatenating them together. ls raw_output/ | cut -f3 -d&#39;.&#39; | sort | uniq | while read author;do rm pheno_defs/diag.${author}.txt.gz rm pheno_defs/time.${author}.txt.gz ls raw_output/diag.coding.${author}* | cut -f2 -d&#39;/&#39; | cut -f4 -d&#39;.&#39; | sort -n | while read num;do zcat raw_output/diag.coding.${author}.${num}.txt.gz &gt;&gt; pheno_defs/diag.${author}.txt zcat raw_output/diag.time.${author}.${num}.txt.gz &gt;&gt; pheno_defs/time.${author}.txt done gzip pheno_defs/diag.${author}.txt gzip pheno_defs/time.${author}.txt done The final output are two files for each phenotype. Both files contain six columns for each different defintion type, and 502,535 rows for each individual. One file will either contain 0’s and 1’s for no phenotype present or yes phenotype present. The other file will have a series of dahes where there is a 0 in the corresponding file, and the date the phenotype started where there are 1’s in the corresponding file. 7.3 Other Scores To evaluate the prior methods against more curated scores I will downloaded scoring summary statistics and creating scores here. The problem, with this aim is that scoring summary statistics are often hard to find and come in various formats that are difficult to standardize. For example scoring summary statistics are often not located within figures, may not contain rsIDs or genome reference, may not label the type of effect or be saved in a difficult format. Luckily a great resource has come into existence recently called PGS Catalog, https://www.pgscatalog.org/browse/all/. My idea to ensure that the other scores I create are all reasonable is that I will only use scores within PGS Catalog. While there are other scores that I probably could access, I think this is a good compromise to keep things accurate while still carrying out the mission of checking on other scores (and just maybe this will motivate people to upload their scoring summary statistics to PGS catalog with all of the important information nescessary to recreate). To get the scoring summary statistics I simply searched for all of the phenotypes that I am researching within the PGS Catalog. I checked all available scores to ensure they were not derived from the UK Biobank. I then saved the name of the all the scores that met both of these requirements. Then iterating through the list each score was downloaded with a call to wget and the address http://ftp.ebi.ac.uk/pub/databases/spot/pgs/scores/{SCORING_NAME}/ScoringFiles/{SCORING_NAME}.txt.gz. Each of the summary statistics then had to be checked just as the summary statistics from GWAS Catalog were. The process is rather similar to before, making sure that the rsIDs in the score exist within the UK Biobank, removing ambigous SNPs and flipping SNPs where nescessary. The full script looks like: library(vroom) library(stringr) library(bigsnpr) options(warn=2) #Read in the UKBB summary statistics impute &lt;- read.table(&quot;../../raw_ss/common_files/impute_rsids&quot;, header = F, stringsAsFactors = F) colnames(impute) &lt;- c(&quot;LOC&quot;, &quot;SNP&quot;, &quot;POS&quot;, &quot;A1&quot;, &quot;A2&quot;, &quot;MAF&quot;, &quot;AX&quot;, &quot;INFO&quot;) #Make sure the UKBB summary statistics have alleles that match ACGT and are not ambigous impute &lt;- impute[nchar(impute$A1) == 1 &amp; nchar(impute$A2) == 1,] impute &lt;- impute[impute$A1 %in% c(&quot;A&quot;, &quot;C&quot;, &quot;G&quot;, &quot;T&quot;) &amp; impute$A2 %in% c(&quot;A&quot;, &quot;C&quot;, &quot;G&quot;, &quot;T&quot;),] impute &lt;- impute[!((impute$A1 == &quot;A&quot; &amp; impute$A2 == &quot;T&quot;) | (impute$A1 == &quot;T&quot; &amp; impute$A2 == &quot;A&quot;) | (impute$A1 == &quot;G&quot; &amp; impute$A2 == &quot;C&quot;) | (impute$A1 == &quot;C&quot; &amp; impute$A2 == &quot;G&quot;)),] #Read in other UKBB data that comes with chromosomes so I can give a chromosome to each SNP impute$CHR &lt;- &quot;X&quot; for(i in 1:22){ temp &lt;- readRDS(paste0(&quot;~/athena/ukbiobank/qc/imputed/chr&quot;, i, &quot;.RDS&quot;)) impute$CHR[impute$SNP %in% temp[,2]] &lt;- i } impute &lt;- impute[impute$CHR %in% 1:22,] impute$SUPERPOS &lt;- paste0(impute$CHR, &quot;_&quot;, impute$POS) #Now iterating through each of the score summary statistics ### for(filename in list.files(&quot;raw_other_ss/&quot;)){ #read the summary statistic in ss &lt;- read.table(paste0(&quot;raw_other_ss/&quot;, filename), stringsAsFactors=F, header=T, sep=&#39;\\t&#39;) #require both a column for major and minor allele, if only one exists refining is not possible if(&quot;effect_allele&quot; %in% colnames(ss) &amp; &quot;reference_allele&quot; %in% colnames(ss)){ #limit SNPs to those with ACGT ss$effect_allele &lt;- toupper(ss$effect_allele) ss$reference_allele &lt;- toupper(ss$reference_allele) ss &lt;- ss[nchar(ss$effect_allele) == 1 &amp; nchar(ss$reference_allele) == 1,] ss &lt;- ss[ss$effect_allele %in% c(&quot;A&quot;, &quot;C&quot;, &quot;G&quot;, &quot;T&quot;) &amp; ss$reference_allele %in% c(&quot;A&quot;, &quot;C&quot;, &quot;G&quot;, &quot;T&quot;),] #remove ambigous SNPs ss &lt;- ss[!((ss$effect_allele == &quot;A&quot; &amp; ss$reference_allele == &quot;T&quot;) | (ss$effect_allele == &quot;T&quot; &amp; ss$reference_allele == &quot;A&quot;) | (ss$effect_allele == &quot;G&quot; &amp; ss$reference_allele == &quot;C&quot;) | (ss$effect_allele == &quot;C&quot; &amp; ss$reference_allele == &quot;G&quot;)),] #if rsID in the ss use it to match and sort to the UKBB #if not then use the chromosome and position (I already checked that all scores&#39; ref genomes match UKBB) if(&quot;rsID&quot; %in% colnames(ss)){ ss &lt;- ss[!is.na(ss$rsID),] ss$rsID &lt;- tolower(ss$rsID) ss &lt;- ss[ss$rsID %in% impute$SNP,] sub_impute &lt;- impute[impute$SNP %in% ss$rsID,] ss &lt;- ss[order(ss$rsID)[rank(sub_impute$SNP)],] } else { ss$SUPERPOS &lt;- paste0(ss$chr_name, &quot;_&quot;, ss$chr_position) ss &lt;- ss[ss$SUPERPOS %in% impute$SUPERPOS,] sub_impute &lt;- impute[impute$SUPERPOS %in% ss$SUPERPOS,] ss &lt;- ss[order(ss$SUPERPOS)[rank(sub_impute$SUPERPOS)],] ss$rsID &lt;- sub_impute$SNP } #Change the column names and then use the snp_match function from bigsnpr to flip alleles colnames(sub_impute) &lt;- c(&quot;loc&quot;, &quot;rsid&quot;, &quot;pos&quot;, &quot;a0&quot;, &quot;a1&quot;, &quot;maf&quot;, &quot;ax&quot;, &quot;info&quot;, &quot;chr&quot;, &quot;superpos&quot;) colnames(ss)[colnames(ss) == &quot;effect_allele&quot;] &lt;- &quot;a0&quot; colnames(ss)[colnames(ss) == &quot;reference_allele&quot;] &lt;- &quot;a1&quot; colnames(ss)[colnames(ss) == &quot;rsID&quot;] &lt;- &quot;rsid&quot; colnames(ss)[colnames(ss) == &quot;effect_weight&quot;] &lt;- &quot;beta&quot; ss$pos &lt;- sub_impute$pos ss$chr &lt;- sub_impute$chr ss &lt;- snp_match(ss, sub_impute) #write out the refined summary statistic out_ss &lt;- data.frame(chr = ss$chr, rsid = ss$rsid.ss, A1 = ss$a0, beta = ss$beta) new_name &lt;- strsplit(filename, &quot;.&quot;, fixed = T)[[1]][1] write.table(out_ss, paste0(&quot;refine_other_ss/&quot;, new_name, &quot;.new.ss&quot;), col.names = T, row.names = F, sep = &#39;\\t&#39;, quote=F) } } Within this process a key limitation was that both major and minor allele are present. Approximitley 30% of scores did not have both and therefore could not be used in scoring. While I considered laxing this requirement, making sure the alleles are flipped correctly (which requires both alleles) seemed too important of a step to just throw out for nearly any reason. In the end 24 summary statistics were refined. For the record their names are: score_names &lt;- read.table(&quot;../analyze_score/other_scores/score_names&quot;) print(score_names) ## V1 V2 V3 V4 ## 1 PGS000007.new.ss PGS000014.new.ss PGS000020.new.ss PGS000039.new.ss ## 2 PGS000011.new.ss PGS000015.new.ss PGS000036.new.ss PGS000044.new.ss ## 3 PGS000013.new.ss PGS000016.new.ss PGS000037.new.ss PGS000045.new.ss ## V5 V6 V7 V8 ## 1 PGS000046.new.ss PGS000058.new.ss PGS000082.new.ss PGS000195.new.ss ## 2 PGS000047.new.ss PGS000067.new.ss PGS000084.new.ss PGS000196.new.ss ## 3 PGS000052.new.ss PGS000072.new.ss PGS000194.new.ss PGS000199.new.ss With the summary statistics made I continued on with scoring following nearly the same process as was carried out within the previous scoring section. In short I iterated through each score and chromosome, generating a score. At the end of this process I summed together all of the chromosomes to generate one score. To run in parallel a control script is nescessary, which looks very similar to the adjusting summary statistic control script. maxGo=3 rm temp_files/poss_go cat ~/athena/doc_score/qc/cv_files/train_eid.0.2.txt | cut -f1 &gt; temp_files/brit_eid cat ~/athena/doc_score/qc/cv_files/test_eid.0.8.txt | cut -f1 &gt;&gt; temp_files/brit_eid for (( i=1; i&lt;=$maxGo; i++ )); do echo $i &gt;&gt; temp_files/poss_go done echo 1 &gt; temp_files/counter ls refine_other_ss/ | while read scorename;do for cchr in {1..22};do counter_var=`cat temp_files/counter` echo $counter_var ./simple_score.sh $scorename $cchr $counter_var &amp;&gt; logs/log.${counter_var}.log &amp; echo $counter_var + 1 | bc &gt; temp_files/counter sleep $(( ( RANDOM % 10 ) + 1 )) goOn=False while [ $goOn == &quot;False&quot; ]; do openSlots=`cat temp_files/poss_go | wc -l` sizedir=`du temp_files/ | cut -f1` if [ $openSlots -gt 0 ]; then if [ $sizedir -lt 20164096 ];then echo NOW WE CAN GO goOn=True fi else echo MUST WAIT FOR ROOM TO GO sleep $(( ( RANDOM % 5 ) + 1 )) fi done done done The key line within this control script is the line that launches simple_score.sh. This sub-script creates the nescessary genotypic information from the larger UKBB imputed file, and then uses PLINK to create the score. ss_name=$1 chr=$2 i=$3 echo $ss_name $author $method $chr $i #Just logistics around controlling parallelism go_num=`head -1 temp_files/poss_go` grep -v -w $go_num temp_files/poss_go &gt; temp_files/temp_poss mv temp_files/temp_poss temp_files/poss_go if [ ! -e small_score_files/score.${ss_name}.${chr}.profile.zst ];then len=`cat refine_other_ss/${ss_name} | awk -v var=&quot;$chr&quot; &#39;$1 == var {print $0}&#39; | wc -l` if [ $len != 0 ];then cat refine_other_ss/${ss_name} | awk -v var=&quot;$chr&quot; &#39;$1 == var {print $0}&#39; &gt; temp_files/ss.${i} cat temp_files/ss.${i} | cut -f2 &gt; temp_files/rsids.${i} bgenix -g ~/athena/ukbiobank/imputed/ukbb.${chr}.bgen -incl-rsids temp_files/rsids.${i} &gt; temp_files/temp.${i}.bgen plink2_new --memory 12000 --threads 12 --bgen temp_files/temp.${i}.bgen ref-first --sample ~/athena/ukbiobank/imputed/ukbb.${chr}.sample --keep-fam temp_files/brit_eid --make-bed --out temp_files/geno.${i} plink --memory 12000 --threads 12 --bfile temp_files/geno.${i} --keep-allele-order --score temp_files/ss.${i} 2 3 4 sum --out small_score_files/score.${ss_name}.${chr} zstd --rm small_score_files/score.${ss_name}.${chr}.profile fi fi rm temp_files/ss.${i} rm temp_files/rsids.${i} rm temp_files/temp.${i}.bgen rm temp_files/geno.${i}.* #Just logistics around controlling parallelism echo $go_num &gt;&gt; temp_files/poss_go Finally, all of the scores are added together. library(data.table) all_files &lt;- list.files(&quot;small_score_files/&quot;, pattern = &quot;profile&quot;) split_files &lt;- strsplit(all_files, &quot;.&quot;, fixed = T) all_author &lt;- unlist(lapply(split_files, function(x) x[2])) all_chr &lt;- unlist(lapply(split_files, function(x) x[5])) brit_eid &lt;- read.table(&quot;temp_files/brit_eid&quot;, stringsAsFactors=F) new_name &lt;- unique(all_author) all_score &lt;- matrix(0, nrow = nrow(brit_eid), ncol = length(new_name)) colnames(all_score) &lt;- new_name i &lt;- 1 j &lt;- 1 for(i in 1:length(all_files)){ system(paste0(&quot;zstd -d small_score_files/&quot;, all_files[i])) sub_score &lt;- as.data.frame(fread(paste0(&quot;small_score_files/&quot;, substr(all_files[i], 1, nchar(all_files[i])-4)))) system(paste0(&quot;rm small_score_files/&quot;, substr(all_files[i], 1, nchar(all_files[i])-4))) all_score[,new_name == all_author[i]] &lt;- all_score[,new_name == all_author[i]] + sub_score$SCORESUM } all_score &lt;- all_score[,colSums(all_score) != 0] next_file &lt;- length(grep(&quot;RDS&quot;, list.files(&quot;final_scores&quot;, &quot;all_score&quot;))) + 1 write.table(all_score, paste0(&quot;final_scores/all_score.&quot;, next_file), row.names = F, col.names = T, quote = F, sep = &#39; &#39;) saveRDS(all_score, paste0(&quot;final_scores/all_score.&quot;, next_file, &quot;.RDS&quot;)) write.table(colnames(all_score), paste0(&quot;final_scores/done_names.&quot;, next_file), row.names = F, col.names = F, quote = F) system(paste0(&quot;gzip final_scores/all_score.&quot;, next_file)) If this process seemed a little too fast I encourage you to look at the 5th chapter that goes over many scoring processes and caveats. The end product are 24 polygenic risk scores that may be used to supplement future analyses of the phenotypes already discussed. 7.4 Other Covariates In order to get a better picture of how well the PGS is working, we collect other covariates that may be included in a linear prediction model. While this is a good idea, complications quickly emerge in determining which covariates should be included. One way forward is simple including a wide variety of covariates and then paring those away based on feature selection. While this is a fine idea, and is a good idea that I may follow in another project, it makes overfitting quite possible (which is not good) and is alot of work (which is not good). Therefore I will only include covariates which have been declared to be significant. The sources I am looking at for this significance is the Mayo Clinic, NIH and various respective professional organizations. The list of covariates for each disease under analysis includes: covar_names &lt;- read.table(&quot;../analyze_score/descript_defs/author_covar&quot;, sep = &quot;\\t&quot;) print(covar_names) ## V1 ## 1 Bentham ## 2 Christophersen ## 3 Demenais ## 4 Demontis ## 5 Dubois ## 6 Gormley ## 7 IMSGC ## 8 Jin ## 9 Kottgen ## 10 Liu1 ## 11 Liu2 ## 12 Mahajan ## 13 Malik ## 14 Michailidou ## 15 Namjou ## 16 Nikpay ## 17 Okada ## 18 Onengut ## 19 Phelan ## 20 Rheenen ## 21 Schumacher ## 22 Shah ## 23 Sklar ## 24 Tsoi ## 25 Wray ## 26 Xie ## V2 ## 1 sex ## 2 age,hypertension,congenital heart disease,cardiac arrest,coronary artery disease,alcohol,sleep apnea ## 3 allergic rhinitis,smoking,bmi ## 4 none ## 5 type 1 diabetes ## 6 age,sex,age menopause,hormone replacement therapy ## 7 age,sex,epstein barr virus ## 8 use of sun protection,melanona,non-hodgkins lymphoma ## 9 age,sex,obesity,hypertension,diabetes ## 10 smoking ## 11 smoking ## 12 age,sex,bmi,exercise,hypertension,hypocholesteroemia ## 13 age,sex,bmi,age started oral contraceptive,hypertension,hypocholesteroemia,smoking,alcohol,diabetes ## 14 age,sex,bmi,alcohol,age menarche,age menopause,pregnant ## 15 age,obesity,hypertension,hypocholesteroemia,diabetes ## 16 age,sex,bmi,hypocholesteroemia,hypertension,diabetes,smoking ## 17 age,sex,smoking,obesity,pregnant ## 18 none ## 19 age,bmi,hormone replacement therapy,pregnant,breast cancer ## 20 age,diabetes,obesity ## 21 age,obesity ## 22 cardiac arrest,hypertension,congenital heart defects,obesity,diabetes,arrythmia ## 23 none ## 24 smoking ## 25 alcohol,hormone replacement therapy,age menopause ## 26 age,sex,sle These other covariates are obtained in two very different ways as there are two very different types of covariates, those from the ICD records and those that are not. We will start off with the non-ICD covariates, as it is simpler. We start off by reading in all of the UK Biobank phenotypes, subsetting to make sure the EIDs are held within all of the files, then sort so all of the EIDs are in the same order. We then extract the columns that are within the author covariates shown above. The second part of the non-ICD covariate extraction process is some manual data cleaning. Some of the covariates have NA entries, which we either fill in with the mean value of the remaining non-NA entries, or we select the mode or other obvious answer that assumes the person did not do something. For example we take the mean for BMI and assume horome replacement therapy was not taken. A final data cleaning step sets NA for male individuals to female-specific features (such as age of menopause). We lastly write out the covariates into a text file. The exact process is shown above. library(vroom) defs &lt;- read.table(&quot;../descript_defs/covar_defs_singlecol&quot;, stringsAsFactors=F, header = T) preg_codes &lt;- strsplit(defs[which(defs[,1] == &quot;pregnant&quot;),2], &quot;,&quot;)[[1]] use_codes &lt;- c(defs$single_col[-which(defs[,1] == &quot;pregnant&quot;)], preg_codes) phen &lt;- as.data.frame(vroom(&quot;~/athena/ukbiobank/phenotypes/ukb26867.csv.gz&quot;, delim = &quot;,&quot;)) sub_phen_1 &lt;- phen[,colnames(phen) %in% c(use_codes, &quot;eid&quot;)] phen &lt;- as.data.frame(vroom(&quot;~/athena/ukbiobank/phenotypes/ukb33822.csv.gz&quot;, delim = &quot;,&quot;)) sub_phen_2 &lt;- phen[,colnames(phen) %in% c(use_codes, &quot;eid&quot;)] phen &lt;- as.data.frame(vroom(&quot;~/athena/ukbiobank/phenotypes/ukb42385.csv.gz&quot;, delim = &quot;,&quot;)) sub_phen_3 &lt;- phen[,colnames(phen) %in% c(use_codes, &quot;eid&quot;)] sub_phen_1 &lt;- sub_phen_1[sub_phen_1$eid %in% sub_phen_2$eid &amp; sub_phen_1$eid %in% sub_phen_3$eid,] sub_phen_2 &lt;- sub_phen_2[sub_phen_2$eid %in% sub_phen_1$eid &amp; sub_phen_2$eid %in% sub_phen_3$eid,] sub_phen_3 &lt;- sub_phen_3[sub_phen_3$eid %in% sub_phen_2$eid &amp; sub_phen_3$eid %in% sub_phen_1$eid,] sub_phen_2 &lt;- sub_phen_2[order(sub_phen_2$eid)[rank(sub_phen_1$eid)],] sub_phen_3 &lt;- sub_phen_3[order(sub_phen_3$eid)[rank(sub_phen_1$eid)],] new_phen &lt;- cbind(sub_phen_1, sub_phen_2[,-1, drop = F], sub_phen_3[,-1, drop = F]) preg_ans &lt;- (new_phen[[&quot;3140-0.0&quot;]] == 1 &amp; !is.na(new_phen[[&quot;3140-0.0&quot;]])) | (!is.na(new_phen[[&quot;2754-0.0&quot;]])) preg_ans &lt;- preg_ans*1 inds &lt;- 1:nrow(defs)[-10] for(i in inds){ colnames(new_phen)[colnames(new_phen) == defs[i,2]] &lt;- defs[i,1] } new_phen &lt;- new_phen[,!grepl(&quot;0.0&quot;, colnames(new_phen))] new_phen$pregnant &lt;- preg_ans ##################### CLEAN BY HAND ############################## new_phen$alcohol[is.na(new_phen$alcohol) | new_phen$alcohol == -3] &lt;- 4 new_phen$smoking[is.na(new_phen$smoking) | new_phen$smoking == -3] &lt;- 0 new_phen &lt;- new_phen[,-which(colnames(new_phen) == &quot;alcohol.1&quot;)] new_phen &lt;- new_phen[,-which(colnames(new_phen) == &quot;smoking.1&quot;)] new_phen$bmi[is.na(new_phen$bmi)] &lt;- mean(new_phen$bmi, na.rm = T) new_phen$exercise[is.na(new_phen$exercise) | new_phen$exercise == -3 | new_phen$exercise == -1] &lt;- 2 new_phen$use_of_sun_protection[is.na(new_phen$use_of_sun_protection) | new_phen$use_of_sun_protection == -3 | new_phen$use_of_sun_protection == -1] &lt;- 2 new_phen$age_menarche[is.na(new_phen$age_menarche) | new_phen$age_menarche == -1 | new_phen$age_menarche == -3] &lt;- mean(new_phen$age_menarche[!(is.na(new_phen$age_menarche) | new_phen$age_menarche == -1 | new_phen$age_menarche == -3 | new_phen$sex == 1)]) new_phen$age_menarche[new_phen$sex == 1] &lt;- NA new_phen$hormone_replacement_therapy[is.na(new_phen$hormone_replacement_therapy) | new_phen$hormone_replacement_therapy == -1 | new_phen$hormone_replacement_therapy == -3] &lt;- 0 new_phen$hormone_replacement_therapy[new_phen$sex == 1] &lt;- NA new_phen$had_menopause[is.na(new_phen$had_menopause) | new_phen$had_menopause == 2 | new_phen$had_menopause == 3] &lt;- 0 new_phen$had_menopause[new_phen$sex == 1] &lt;- NA new_phen$age_menopause[new_phen$had_menopause == 0] &lt;- NA new_phen$age_menopause[new_phen$sex == 0 &amp; is.na(new_phen$age_menopause)] &lt;- mean(new_phen$age_menopause, na.rm = T) new_phen$age_menopause[new_phen$sex == 1] &lt;- NA new_phen$ever_used_oral_contraceptive[is.na(new_phen$ever_used_oral_contraceptive) | new_phen$ever_used_oral_contraceptive == -3 | new_phen$ever_used_oral_contraceptive == -1] &lt;- 0 new_phen$ever_used_oral_contraceptive[new_phen$sex == 1] &lt;- NA new_phen$age_started_oral_contraceptive[new_phen$ever_used_oral_contraceptive == 0 | new_phen$age_started_oral_contraceptive &lt; 10] &lt;- NA new_phen$age_started_oral_contraceptive[new_phen$sex == 0 &amp; is.na(new_phen$age_started_oral_contraceptive)] &lt;- mean(new_phen$age_started_oral_contraceptive, na.rm = T) new_phen$age_started_oral_contraceptive[new_phen$sex == 1] &lt;- NA new_phen$epstein_barr_virus[is.na(new_phen$epstein_barr_virus)] &lt;- 0.5 new_phen$obesity &lt;- 0 new_phen$obesity[new_phen$bmi &gt; 30] &lt;- 1 ########################################################################## write.table(new_phen, &quot;covar_data/single_col_covars&quot;, row.names = F, col.names = T, quote = F, sep = &quot;\\t&quot;) The second group of the other covariates come from the ICD (and self-reported disease) records. For each of the disease traits that are considered covariates for any of the diseaes under the main analysis we need to get an ICD definition. This process was simply carried out through table and internet look-ups. The defintions used are as follows: covar_names &lt;- read.table(&quot;../analyze_score/descript_defs/covar_defs&quot;, sep = &quot;\\t&quot;, header = T) print(covar_names) ## name single_col ICD10 ICD9 ## 1 age 34-0.0 &lt;NA&gt; &lt;NA&gt; ## 2 sex 31-0.0 &lt;NA&gt; &lt;NA&gt; ## 3 hypertension &lt;NA&gt; I10 401 ## 4 congenital_heart_disease &lt;NA&gt; Q24 746 ## 5 cardiac_arrest &lt;NA&gt; I21,I46 410,4275 ## 6 coronary_artery_disease &lt;NA&gt; I25 414 ## 7 alcohol 1558-0.0 &lt;NA&gt; &lt;NA&gt; ## 8 sleep_apnea &lt;NA&gt; G473 &lt;NA&gt; ## 9 allergic_rhinitis &lt;NA&gt; J30 477 ## 10 smoking 20116-0.0 &lt;NA&gt; &lt;NA&gt; ## 11 bmi 21001-0.0 &lt;NA&gt; &lt;NA&gt; ## 12 type_1_diabetes &lt;NA&gt; E10 250 ## 13 exercise 884-0.0 &lt;NA&gt; &lt;NA&gt; ## 14 hypocholesteroemia &lt;NA&gt; E780 &lt;NA&gt; ## 15 age_started_oral_contraceptive 2784-0.0 &lt;NA&gt; &lt;NA&gt; ## 16 age_menarche 2714-0.0 &lt;NA&gt; &lt;NA&gt; ## 17 age_menopause 3581-0.0 &lt;NA&gt; &lt;NA&gt; ## 18 pregnant 2754-0.0,3140-0.0 &lt;NA&gt; &lt;NA&gt; ## 19 hormone_replacement_therapy 2814-0.0 &lt;NA&gt; &lt;NA&gt; ## 20 breast_cancer &lt;NA&gt; C50 2330 ## 21 epstein_barr_virus 23053-0.0 &lt;NA&gt; &lt;NA&gt; ## 22 use_of_sun_protection 2267-0.0 &lt;NA&gt; &lt;NA&gt; ## 23 diabetes &lt;NA&gt; E10,E11 250 ## 24 arrhythmia &lt;NA&gt; I47,I48 427 ## 25 sle &lt;NA&gt; M32 7100 ## 26 melanoma &lt;NA&gt; C43 172 ## 27 non-hodgkins_lymphoma &lt;NA&gt; C82,C83 &lt;NA&gt; ## self_diag self_diag_cancer ## 1 &lt;NA&gt; NA ## 2 &lt;NA&gt; NA ## 3 1065,1072 NA ## 4 &lt;NA&gt; NA ## 5 &lt;NA&gt; NA ## 6 &lt;NA&gt; NA ## 7 &lt;NA&gt; NA ## 8 1123 NA ## 9 1387 NA ## 10 &lt;NA&gt; NA ## 11 &lt;NA&gt; NA ## 12 1222 NA ## 13 &lt;NA&gt; NA ## 14 1473 NA ## 15 &lt;NA&gt; NA ## 16 &lt;NA&gt; NA ## 17 &lt;NA&gt; NA ## 18 &lt;NA&gt; NA ## 19 &lt;NA&gt; NA ## 20 &lt;NA&gt; 1002 ## 21 &lt;NA&gt; NA ## 22 &lt;NA&gt; NA ## 23 1220,1222,1223 NA ## 24 1077 NA ## 25 1381 NA ## 26 &lt;NA&gt; 1059 ## 27 &lt;NA&gt; 1053 While it could be possible to get the ICD covariates for all individuals for all diseases, this process is actually quite time intensive and therefore I have decided to only get the relavent disease covariates for each main disease under analysis. The specific covariates matched to each disease under analyis is: covar_names &lt;- read.table(&quot;../analyze_score/descript_defs/author_to_covar_hesin&quot;, sep = &quot;\\t&quot;, header = F) print(covar_names) ## V1 ## 1 Bentham ## 2 Christophersen ## 3 Demenais ## 4 Demontis ## 5 Dubois ## 6 Gormley ## 7 IMSGC ## 8 Jin ## 9 Kottgen ## 10 Liu1 ## 11 Liu2 ## 12 Mahajan ## 13 Malik ## 14 Michailidou ## 15 Namjou ## 16 Nikpay ## 17 Okada ## 18 Onengut ## 19 Phelan ## 20 Rheenen ## 21 Schumacher ## 22 Shah ## 23 Sklar ## 24 Tsoi ## 25 Wray ## 26 Xie ## V2 ## 1 &lt;NA&gt; ## 2 hypertension,congenital_heart_disease,cardiac_arrest,coronary_artery_disease,sleep_apnea ## 3 allergic_rhinitis ## 4 &lt;NA&gt; ## 5 type_1_diabetes ## 6 &lt;NA&gt; ## 7 &lt;NA&gt; ## 8 melanona,non-hodgkins_lymphoma ## 9 hypertension,diabetes ## 10 &lt;NA&gt; ## 11 &lt;NA&gt; ## 12 hypertension,hypocholesteroemia ## 13 hypertension,hypocholesteroemia,diabetes ## 14 &lt;NA&gt; ## 15 hypertension,hypocholesteroemia,diabetes ## 16 hypocholesteroemia,hypertension,diabetes ## 17 &lt;NA&gt; ## 18 &lt;NA&gt; ## 19 breast_cancer ## 20 diabetes ## 21 &lt;NA&gt; ## 22 cardiac_arrest,hypertension,congenital_heart_disese,diabetes,arrythmia ## 23 &lt;NA&gt; ## 24 &lt;NA&gt; ## 25 &lt;NA&gt; ## 26 &lt;NA&gt; Now that we know exactly what we are getting, let’s actually get the values. As I am lopping though alot of data I have opted to use a Python script rather than R. The script itself is highly similar to the phenotype extraction shown in the previous section, so I won’t go in too much detail on how it operates. I will instead just highlight a few things. First, I want to make sure that all of the disease covariates take place before the possible date of the primary disease. Therefore I read in the dates of the primary disease and use it to limit the number of disease diagnoses that I can look at for the covariates. Secondly, in this instance I am possible looking at more than one disease defintion (whereas before I only needed to know one defition). I then create a for loop within the loop for each indvidial to iterate over all posible covariates definitions. Third, wheras in making the phenotype defintion I kept 6 columns, one for each possible diagnosis source, in this instance I am assuming that if the individual has any positive covariate within either the ICD or self-reported sources I will assume that they do have the disease. Other than these changes everything is the same, as I attempt to intelligently iterate through all individuals, pulling out the meaningful ICD codes and subsetting by the date. The exact code is shown below: import numpy as np import datetime import time import pickle import pdb import gzip import os import sys import re import gzip author = &quot;Bentham&quot; phen_method = &quot;all&quot; #Still need to sort everything so that the extEid process works def normRead(fileName, withHeader = True, delim = &#39;\\t&#39;, removeQuote = False): totalData = [] if fileName[-2:] == &quot;gz&quot;: with gzip.open(fileName,&quot;r&quot;) as f: for line in f: totalData.append(line.decode().strip().split(delim)) else: with open(fileName,&quot;r&quot;,encoding = &quot;latin-1&quot;) as f: for line in f.read().splitlines(): #for line in f: if removeQuote: line = line.replace(&#39;&quot;&#39;, &#39;&#39;).strip() totalData.append(line.split(delim)) if withHeader: header=totalData[0] del totalData[0] else: header = None totalData=np.array(totalData) return(totalData,header) covar_defs, covar_header = normRead(&quot;../descript_defs/covar_defs_hesin&quot;, False) use_defs = [] for i in range(covar_defs.shape[0]): split_defs = [j.split(&quot;,&quot;) for j in covar_defs[i,2:]] use_defs.append(dict(zip([&quot;ICD10&quot;, &quot;ICD9&quot;, &quot;selfrep&quot;, &quot;cancer&quot;], split_defs))) date_ass,ass_header = normRead(&quot;../construct_defs/date_assessed.csv&quot;, True, &quot;,&quot;, True) self_rep, self_rep_header = normRead(&quot;../construct_defs/self_report_diag.csv&quot;, True, &quot;,&quot;, True) cancer_rep, cancer_rep_header = normRead(&quot;../construct_defs/self_report_cancer.csv&quot;, True, &quot;,&quot;, True) big_eid, eid_head = normRead(&quot;../construct_defs/eid.csv&quot;, True, &quot;,&quot;, True) date_ass = date_ass[big_eid[:,0].argsort(),:] self_rep = self_rep[big_eid[:,0].argsort(),:] cancer_rep = cancer_rep[big_eid[:,0].argsort(),:] big_eid = big_eid[big_eid[:,0].argsort(),:] cancer_phase = [x.split(&quot;-&quot;)[1].split(&quot;.&quot;)[0] for x in cancer_rep_header] self_phase = [x.split(&quot;-&quot;)[1].split(&quot;.&quot;)[0] for x in self_rep_header] diag, head_diag = normRead(&quot;/home/kulmsc/athena/ukbiobank/hesin/hesin_diag.txt&quot;) hesin, head_hesin = normRead(&quot;/home/kulmsc/athena/ukbiobank/hesin/hesin.txt&quot;) diag = diag[diag[:,0].argsort(),:] hesin = hesin[hesin[:,0].argsort(),:] diag_eid = np.unique(diag[:,0]) diag_max = diag.shape[0] - 1 diag_eid_list = diag[:,0].tolist() print(&quot;reading&quot;) known_diag, known_head = normRead(&quot;../construct_defs/pheno_defs/diag.&quot; + author.lower() + &quot;.txt.gz&quot;, False, &quot; &quot;) known_time, known_head = normRead(&quot;../construct_defs/pheno_defs/time.&quot; + author.lower() + &quot;.txt.gz&quot;, False, &quot; &quot;) new_time = np.tile(datetime.datetime.strptime(&quot;31/12/2020&quot;, &#39;%d/%m/%Y&#39;), (known_time.shape[0], known_time.shape[1])) print(&quot;read in&quot;) for i in range(known_time.shape[0]): for j in range(known_time.shape[1]): if known_time[i,j] != &#39;__________&#39;: if j == 0 or j == 1 or j == 5: new_time[i,j] = datetime.datetime.strptime(known_time[i,j], &quot;%Y-%m-%d&quot;) else: new_time[i,j] = datetime.datetime.strptime(known_time[i,j], &quot;%d/%m/%Y&quot;) known_time = new_time if phen_method == &quot;icd&quot;: known_diag = know_diag[:,2:4] known_time = known_time[:,2:4] elif phen_method == &quot;selfrep&quot;: known_diag = known_diag[:,0:2] known_time = known_time[:,0:2] elif phen_method == &quot;icd_selfrep&quot;: known_diag = known_diag[:,0:4] known_time = known_time[:,0:4] elif phen_method == &quot;double&quot;: known_diag = known_diag.astype(&quot;int&quot;) for_double = np.sum(known_diag, axis = 1) final_diag = [] final_time = [] for i in range(known_diag.shape[0]): if phen_method == &quot;double&quot;: if for_double[i] &gt; 1: final_diag.append(1) final_time.append(min(known_time[i,:])) else: final_diag.append(0) final_time.append(&quot;NA&quot;) else: if &quot;1&quot; in known_diag[i,:]: final_diag.append(1) final_time.append(min(known_time[i,:])) else: final_diag.append(0) final_time.append(&quot;NA&quot;) #STILL NEED TO FIGURE OUT HOW I WANT TO SPLIT THIS - right now assume I dont start_eid_diag = 0 df_occur = np.zeros((big_eid.shape[0], covar_defs.shape[0])) df_date = np.tile(&quot;_________&quot;, (big_eid.shape[0], covar_defs.shape[0])) #pdb.set_trace() for ind in range(big_eid.shape[0]): print(ind) print(big_eid[ind]) #pdb.set_trace() curr_eid = big_eid[ind][0] if ind % 10000 == 0: print(ind) for trait_ind in range(covar_defs.shape[0]): #CANCER SELF REPORT if covar_defs[trait_ind, 5] != &quot;NA&quot;: if any(np.isin(use_defs[trait_ind][&quot;cancer&quot;], cancer_rep[ind,:])): locs = np.where(np.isin(cancer_rep[ind,:], covar_defs[trait_ind, 5]))[0] poss_date = date_ass[ind, int(cancer_phase[locs[0]])] poss_date = datetime.datetime.strptime(poss_date, &quot;%Y-%m-%d&quot;) if poss_date &lt; final_time[i]: df_occur[ind, trait_ind] = 1 df_date[ind, trait_ind] = poss_date #CANCER SELF REPORT if covar_defs[trait_ind, 4] != &quot;NA&quot;: if any(np.isin(use_defs[trait_ind][&quot;selfrep&quot;], self_rep[ind,:])): locs = np.where(np.isin(self_rep[ind,:], covar_defs[trait_ind, 4]))[0] poss_date = date_ass[ind, int(self_phase[locs[0]])] poss_date = datetime.datetime.strptime(poss_date, &quot;%Y-%m-%d&quot;) if poss_date &lt; final_time[i]: df_occur[ind, trait_ind] = 1 df_date[ind, trait_ind] = poss_date #HESIN DIAG if curr_eid in diag_eid_list: if curr_eid != diag_eid_list[-1]: next_eid = np.unique(diag[start_eid_diag:(start_eid_diag+7000),0])[1] ext_eid = diag_eid_list.index(next_eid) else: ext_eid = diag_max #ICD -9 use_short_icd9_diag = [x[0:3] for x in diag[start_eid_diag:ext_eid,4]] if any(np.isin(use_defs[trait_ind][&quot;ICD9&quot;], use_short_icd9_diag)): short_icd9_locs = np.where(np.isin(use_short_icd9_diag, use_defs[trait_ind][&quot;ICD9&quot;]))[0][0] else: short_icd9_locs = 10000 if any(np.isin(use_defs[trait_ind][&quot;ICD9&quot;], diag[start_eid_diag:ext_eid,4])): long_icd9_locs = np.where(np.isin(diag[start_eid_diag:ext_eid,4], use_defs[trait_ind][&quot;ICD9&quot;]))[0][0] else: long_icd9_locs = 10000 if long_icd9_locs != 10000 or short_icd9_locs != 10000: icd9_locs = min((long_icd9_locs, short_icd9_locs)) icd9_ins_index = diag[start_eid_diag+icd9_locs,1] raw_date = hesin[np.logical_and(hesin[:,0] == curr_eid, hesin[:,1] == icd9_ins_index),5][0] if raw_date == &quot;&quot;: raw_date = hesin[np.logical_and(hesin[:,0] == curr_eid, hesin[:,1] == icd9_ins_index),21][0] if raw_date == &quot;&quot;: raw_date = hesin[np.logical_and(hesin[:,0] == curr_eid, hesin[:,1] == icd9_ins_index),4][0] pdb.set_trace() df_occur[ind,2] = 1 df_date[ind,2] = raw_date #ICD - 10 use_short_icd10_diag = [x[0:3] for x in diag[start_eid_diag:ext_eid,6]] if any(np.isin(use_defs[trait_ind][&quot;ICD10&quot;], use_short_icd10_diag)): short_icd10_locs = np.where(np.isin(use_short_icd10_diag, use_defs[trait_ind][&quot;ICD10&quot;]))[0][0] else: short_icd10_locs = 10000 if any(np.isin(use_defs[trait_ind][&quot;ICD10&quot;], diag[start_eid_diag:ext_eid,6])): long_icd10_locs = np.where(np.isin(diag[start_eid_diag:ext_eid,6], use_defs[trait_ind][&quot;ICD10&quot;]))[0][0] else: long_icd10_locs = 10000 if long_icd10_locs != 10000 or short_icd10_locs != 10000: icd10_locs = min((long_icd10_locs, short_icd10_locs)) icd10_ins_index = diag[start_eid_diag+icd10_locs,1] raw_date = hesin[np.logical_and(hesin[:,0] == curr_eid, hesin[:,1] == icd10_ins_index),5][0] if raw_date == &quot;&quot;: raw_date = hesin[np.logical_and(hesin[:,0] == curr_eid, hesin[:,1] == icd10_ins_index),21][0] if raw_date == &quot;&quot;: raw_date = hesin[np.logical_and(hesin[:,0] == curr_eid, hesin[:,1] == icd10_ins_index),4][0] pdb.set_trace() df_occur[ind,3] = 1 df_date[ind,3] = raw_date start_eid_diag = ext_eid print(&quot;end&quot;) "],["tuning.html", "8 Tuning 8.1 Generating Metrics 8.2 Choosing the Best Score 8.3 Plotting", " 8 Tuning Tuning is the process of converting the large array of polygenic risk scores into a single recommendation of the best polygenic risk score. To understand the motivation behind this section we have to broaden our understanding of the purpose of this study. So far this study has focused on evaluating methods that produce polygenic risk scores. However, these scores and the underlying methods are only as good as their absolute risk stratification, not a relative performance to the other methods. If we analyzed the entire dataset with all scores to generate this absolute performance we would be overfitting the data, as the best score might have simply benefitted from the random split of data rather than actually being the best (just the same as a false positive in a t-test). Therefore we must split the data such that only one score is ever allowed to access part of the data. This way we will not get any overfitting. Now that we understand the importance of tuning, or finding the best score on a subset of the data we move onto a large challenge of determining how to choose the best. While there are likely hundreds of metrics we can apply I have resolved to two forms of analyses for two different purposes. The first purpose is using the score as a covariate in downstream models that show links between the genetics of the score’s trait and some other trait or event. The second purpose is using the score to stratify a cohort of individuals such that one subset achieves high enough risk that they warrant different treatment than the remaining subset. In the first purpose we would likely want the score to be well performing for all possible individuals, in the second purpose we only really need the score to work well at the far tails. Now onto the two forms of analyses. The first form is logistic regression, as it is simple, used before, and generates metrics that can easily be interpreted by nearly everyone. The second form is cox proportional hazard models, a slightly more advanced technique that takes into account the progression of time (a very important cause of disease and consideration in treatment). For our first and second purpose in logistic regression the logical metrics are AUC and odds ratio. There are other similar things we can measure but they will ultimately be measuring nearly the same thing. For our first and second purpose in logistic regression the logical metrics are concordance and cumulative incidence. What point in time should we choose for a point cumulative incidence seems logically unclear, so I went with the last possible time point. Now that we have the metrics we want to make there is only one more key consideration. There are multiple different ways (in general) to create the metrics. The most basic would be to fit the model on all data possible and use the model to make a prediction upon the same data. This is simple and fast, but does not well recreate the scenario we will have when analyzing the testing data, where we form the model on one set of data then make a prediction on another set. Therefore we should go about some form of cross validation within our training dataset. Simple cross validation is nice, as it is again simple and fast, however with such small sample sizes we will only be able to run 3 folds leaving a very high variance in our metrics. In the effort to keep bias low while also lowering the variance I have decided to use repeated cross validation. In short 3-fold cross validation is run multiple times, each time picking a different way to splice up the data. Each person will still be used the same number of times as everyone else, it is just the group that person is with will change. As this code is both important and potentially confusing I will explain each part in turn. (Although before I do I want to lastly note that the code used to generate the results looks very slightly different as the base and score models are grouped together more tightly. This makes computation faster but it becomes harder to exaplin. If you want to see the other code please check out my GitHub. 8.1 Generating Metrics 8.1.1 Overall Set-Up The first part of our tuning script involves reading all nescessary data and generally sorting it. Although before we even do that we set-up some basic parameters including the name of the trait we are analyzing, the train/test split we are implementing across the entire UK Biobank, and lastly the number of folds and repeats within our cross validation scheme. We start our reading with the scores. After subsetting and combining them all into one object we apply a simple normalization that for each score value makes the lowest possible value 1 and highest value 100. We then read in the dates and convert them to R date format, which is tricky because there are different formats in different columns. We then condense these six columns down to one based upon which phenotype definition we are using. After completion we read in corresponding eids so the dates and phenotypes can be sorted correctly. Nearly at the end we read in raw death data, adding a dummy date for all people who are not within the death data. This way we can sort the death object so it lines up with everything else. Lastly we read in censor data and subset then sort. library(survival) library(pROC) library(epitools) author &lt;- &quot;IMSGC&quot; phen_method &lt;- &quot;all&quot; subrate_style &lt;- &quot;fast&quot; train_frac &lt;- 0.6 input_folds &lt;- 3 input_repeats &lt;- 3 #Read in the PGSs and sort down to training all_scores &lt;- readRDS(paste0(&quot;../../do_score/final_scores/all_score.&quot;, tolower(author), &quot;.RDS&quot;)) all_eid &lt;- read.table(&quot;~/athena/doc_score/do_score/all_specs/for_eid.fam&quot;, stringsAsFactors=F) train_eid &lt;- read.table(paste0(&quot;~/athena/doc_score/qc/cv_files/train_eid.&quot;, train_frac, &quot;.txt&quot;), stringsAsFactors=F) all_scores &lt;- all_scores[all_eid[,1] %in% train_eid[,1],] eid &lt;- all_eid[all_eid[,1] %in% train_eid[,1],1] #Normalize the scores scores &lt;- all_scores[,grepl(tolower(author), colnames(all_scores))] scores &lt;- scores[,apply(scores, 2, function(x) length(unique(x)) &gt; 3)] scores &lt;- apply(scores, 2, function(x) (x-mean(x)) / (max(abs((x-mean(x)))) * 0.01) ) #Read in the phenotypes, order is: cancer sr, noncancer sr, icd9, icd10, oper, meds #selfasses date: 2018-11-22; hesin date: 21/01/2000 pheno &lt;- read.table(paste0(&quot;../construct_defs/pheno_defs/diag.&quot;, tolower(author), &quot;.txt.gz&quot;), stringsAsFactors=F) dates &lt;- read.table(paste0(&quot;../construct_defs/pheno_defs/time.&quot;, tolower(author), &quot;.txt.gz&quot;), stringsAsFactors=F) for(i in 1:ncol(dates)){ if(i %in% c(1,2,6)){ dates[dates[,i] == &quot;__________&quot;, i] &lt;- &quot;2020-12-31&quot; dates[,i] &lt;- as.Date(dates[,i], &quot;%Y-%m-%d&quot;) } else { dates[dates[,i] == &quot;__________&quot;, i] &lt;- &quot;31/12/2020&quot; dates[,i] &lt;- as.Date(dates[,i], &quot;%d/%m/%Y&quot;) } } if(phen_method == &quot;icd&quot;){ pheno &lt;- pheno[,3:4] dates &lt;- dates[,3:4] } else if(phen_method == &quot;selfrep&quot;){ pheno &lt;- pheno[,1:2] dates &lt;- dates[,1:2] } else if(phen_method == &quot;icd_selfrep&quot;){ pheno &lt;- pheno[,1:4] dates &lt;- dates[,1:4] } else if(phen_method == &quot;all&quot; | phen_method == &quot;double&quot;){ print(&quot;doing nothing&quot;) } dates &lt;- apply(dates, 1, min) dates[dates == as.Date(&quot;2020-12-31&quot;)] &lt;- NA if(phen_method == &quot;double&quot;){ pheno &lt;- rowSums(pheno) pheno[pheno == 1] &lt;- 0 pheno[pheno &gt; 1] &lt;- 1 dates[pheno == 0] &lt;- NA } else { pheno &lt;- rowSums(pheno) pheno[pheno &gt; 1] &lt;- 1 } #Read in the eids used that are the same order as the pheno and dates, then subset the pheno and dates accordingly pheno_eids &lt;- read.table(&quot;../construct_defs/eid.csv&quot;, header = T) pheno_eids &lt;- pheno_eids[order(pheno_eids[,1]),] pheno_eids &lt;- pheno_eids[-length(pheno_eids)] dates &lt;- dates[pheno_eids %in% eid] pheno &lt;- pheno[pheno_eids %in% eid] pheno_eids &lt;- pheno_eids[pheno_eids %in% eid] dates &lt;- dates[order(pheno_eids)[rank(eid)]] pheno &lt;- pheno[order(pheno_eids)[rank(eid)]] #Read in the base covars covars &lt;- readRDS(&quot;../get_covars/base_covars.RDS&quot;) covars &lt;- covars[covars[,1] %in% eid,] covars &lt;- covars[order(covars[,1])[rank(eid)],] #Set up survival analysis data frame #Artifically decide start date is 1999, that way all are even, if date is prior then remove it #The current maximum date possible is 31 May 2020 death &lt;- read.table(&quot;~/athena/ukbiobank/hesin/death.txt&quot;, stringsAsFactors=F, header = T) death[,5] &lt;- unlist(lapply(death[,5], function(x) paste0(strsplit(x, &quot;/&quot;)[[1]][3], &quot;-&quot;, strsplit(x, &quot;/&quot;)[[1]][2], &quot;-&quot;, strsplit(x, &quot;/&quot;)[[1]][1]))) death &lt;- death[!duplicated(death[,1]),] death &lt;- death[death[,1] %in% eid,] add_on &lt;- death[1,] add_on[5] &lt;- &quot;&quot; add_eid &lt;- eid[!(eid %in% death[,1])] add_on &lt;- add_on[rep(1, length(add_eid)),] add_on$eid &lt;- add_eid death &lt;- rbind(death, add_on) death &lt;- death[order(death[,1])[rank(eid)],] censor &lt;- read.table(&quot;../get_covars/covar_data/censor_covars&quot;, stringsAsFactors=F, header = T, sep = &quot;,&quot;) censor &lt;- censor[censor[,1] %in% eid,] censor &lt;- censor[order(censor[,1])[rank(eid)],] At this point we have many different objects that are all lined up and the right size. 8.1.2 Survival Set-up The second part still involves set up, although now stop reading things in and move to forming a data frame for survival analysis. This process starts with establishing a start and end time for each person in our study. The start time is established within this doccumentation (http://biobank.ndph.ox.ac.uk/showcase/exinfo.cgi?src=Data_providers_and_dates). However, I have noticed that there are very few records before 1999, so just to be safe I am removing anyone with a diagnosis before that time and establishing 1999 as the start point. The end date is established within this doccumentation (http://biobank.ndph.ox.ac.uk/showcase/exinfo.cgi?src=timelines_all) and at my time of analysis it was 5/31/2020. However not everyone made it to this date. So we shorten the end date for people who have died, asked to be censored, or experienced our phenotype of interest. We then compile the difference in start and end date, a recording of whether the person was censored and which type, and other important covariates. While this work so far should be enough for a survival analysis astute modelers may be worried about competing risks, or the idea that if someone dies even though they would have otherwise experienced our phenotype then the model is flawed. To solve this problem we use Fine-Gray models from the amazing R survival package. The finegray function changes our original survival analysis data frame so that it contains extra weights and rows so it can run within the coxph function and generate proper Fine-Gray model estimates. We then split up the fine gray data frame so it contains either all scores or no scores. The last major thing going on is setting up our repeated cross validation. We create lists of lists that contain the set of training and testing eids needing in each round of modeling. start_date &lt;- rep(&quot;1999-01-01&quot;, nrow(scores)) end_date &lt;- rep(&quot;2020-05-31&quot;, nrow(scores)) end_date[censor[,2] != &quot;&quot;] &lt;- censor[censor[,2] != &quot;&quot;, 2] end_date[death[,5] != &quot;&quot;] &lt;- death[death[,5] != &quot;&quot;, 5] end_date[!is.na(dates)] &lt;- dates[!is.na(dates)] remove_eids &lt;- pheno_eids[as.Date(dates) &lt; as.Date(&quot;1999-01-01&quot;) &amp; !is.na(dates)] is_death_date &lt;- rep(0, nrow(scores)) is_death_date[death[,5] != &quot;&quot;] &lt;- 1 surv_df &lt;- data.frame(time = as.numeric(as.Date(end_date) - as.Date(start_date)), pheno, is_death_date, covars) df &lt;- data.frame(pheno, covars[,-1]) #need to remove people that had diagnosis before accepted start of the study scores &lt;- scores[surv_df$time &gt; 0,] df &lt;- df[surv_df$time &gt; 0,] covars &lt;- covars[surv_df$time &gt; 0,] pheno &lt;- pheno[surv_df$time &gt; 0] surv_df &lt;- surv_df[surv_df$time &gt; 0,] #Set up Fine and Gray print(&quot;finegray&quot;) event_type &lt;- rep(&quot;censor&quot;, nrow(surv_df)) event_type[surv_df$pheno == 1] &lt;- &quot;diagnosis&quot; event_type[surv_df$is_death_date == 1] &lt;- &quot;death&quot; surv_df$event_type &lt;- as.factor(event_type) fg_diag &lt;- finegray(Surv(time, event_type) ~ ., data = cbind(surv_df[,-which(colnames(surv_df) %in% c(&quot;is_death_date&quot;, &quot;pheno&quot;))], scores), etype=&quot;diagnosis&quot;) fg_death &lt;- finegray(Surv(time, event_type) ~ ., data = cbind(surv_df[,-which(colnames(surv_df) %in% c(&quot;is_death_date&quot;, &quot;pheno&quot;))], scores), etype=&quot;death&quot;) fg_scores_diag &lt;- fg_diag[,grepl(tolower(author), colnames(fg_diag))] fg_scores_death &lt;- fg_death[,grepl(tolower(author), colnames(fg_death))] fg_diag &lt;- fg_diag[,!grepl(&quot;ss&quot;, colnames(fg_diag))] fg_death &lt;- fg_death[,!grepl(&quot;ss&quot;, colnames(fg_death))] #Need to set up repeated cross validation input_folds &lt;- 3 input_repeats &lt;- 10 size_group &lt;- floor(nrow(covars)/input_folds) start_spots &lt;- floor(seq(1, size_group, length.out=input_repeats+1)) repeat_list &lt;- list() for(i in 1:input_repeats){ folds_list &lt;- list() for(j in 1:input_folds){ test_group &lt;- eid[(start_spots[i]+((j-1)*size_group)):(start_spots[i]+(j*size_group))] train_group &lt;- eid[!(eid %in% test_group)] train_group &lt;- train_group[!(train_group %in% remove_eids)] test_group &lt;- test_group[!(test_group %in% remove_eids)] folds_list[[j]] &lt;- list(&quot;train&quot; = train_group, &quot;test&quot; = test_group) } repeat_list[[i]] &lt;- folds_list } overall_counter &lt;- 1 all_conc_holder &lt;- list() all_survfit_holder &lt;- list() all_auc_holder &lt;- list() all_or_holder &lt;- list() all_base_holder &lt;- replicate(4, list()) I am aware that there are other methods available for handling competing risks. I have found that while Fine-Gray is not perfect it is generally well understood and implemented, so I have chosen to use it here. At this point we are finally ready to get some metrics. 8.1.3 Survival Base Metrics We begin with the more difficult survival analyses. Before even starting we split the data into their own training and testing groups. Then we fit a coxph (which is really Fine-Gray) model without any polygenic risk score included. We then use this model upon the testing set to generate a concordance value. We use the survConcordance function to get this value, which I will stress is not the orthodox implementation of survConcordance (see https://stats.stackexchange.com/questions/234164/how-to-validate-cox-proportional-hazards-model, with Dr. Harrell who inveneted many related statistics). However, at the end of the day I need a way to make a prediction and produce a global estimate of fit, and this function gets the job done without doing anything outright wrong. The next step is calculating cumulative incidence. This can be relatively easily calculated with the survfit function and pulling out the cumhaz object (comment on statistic names in the next paragraph). Things get complicated when we want to see how much greater the risk is for one group of people than another group of people (group because we cannot analyze everyone at the same time). A great guide to everything survival curve related is within https://cran.r-project.org/web/packages/survival/vignettes/adjcurve.pdf. Starting in section 5.2 the authors relate how we can basically compare dummy individuals where all of the covariates are held constant except for the group of interest. This clearly creates many problems, which is why a better approach is to model the precise suvival curve of every individual and then average them based on the group the individual is within. The trade-off is that the better approach is very slow and takes up a great deal of memory. An alternative approach is manually extracting the base hazard from the coxph model, then multiply by each individual’s covariates against the fit coefficients. This works particularly well when trying to get the hazard for just one timepoint. When going for all time points I would guess survfit is better. Therefore we will take the slower approach when doing the final testing but when analyzing every score over every fold we will go with the faster approach. #for(nrepeat in 1:input_repeats){ # for(nfold in 1:input_folds){ print(&quot;survival&quot;) # Set up the survival analysis data fg_diag_train &lt;- fg_diag[fg_diag$eid %in% repeat_list[[nrepeat]][[nfold]][[&quot;train&quot;]],] fg_diag_test &lt;- fg_diag[fg_diag$eid %in% repeat_list[[nrepeat]][[nfold]][[&quot;test&quot;]],] surv_df_train &lt;- surv_df[surv_df$eid %in% repeat_list[[nrepeat]][[nfold]][[&quot;train&quot;]],] surv_df_test &lt;- surv_df[surv_df$eid %in% repeat_list[[nrepeat]][[nfold]][[&quot;test&quot;]],] ########################################################### # SURVIVAL ANALYSES # ########################################################### base_mod &lt;- coxph(Surv(fgstart, fgstop, fgstatus) ~ age + sex + PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10, data = fg_diag_train, weight = fgwt) base_conc &lt;- survConcordance(Surv(fgstart, fgstop, fgstatus) ~ predict(base_mod, fg_diag_test), data = fg_diag_test, weight = fgwt) base_survfit &lt;- survfit(base_mod, fg_diag_test, se.fit = F) final_cumhaz &lt;- base_survfit$cumhaz[nrow(base_survfit$cumhaz),] group_factor &lt;- rep(1, length(final_cumhaz)) group_factor[final_cumhaz &lt; quantile(final_cumhaz, 0.2)] &lt;- 0 group_factor[final_cumhaz &gt; quantile(final_cumhaz, 0.8)] &lt;- 2 base_cumhaz &lt;- data.frame(time = base_survfit$time, mean_lo = apply(base_survfit$cumhaz[,group_factor==0], 1, mean), mean_mid = apply(base_survfit$cumhaz[,group_factor==1], 1, mean), mean_hi = apply(base_survfit$cumhaz[,group_factor==2], 1, mean), sd_lo = apply(base_survfit$cumhaz[,group_factor==0], 1, sd), sd_mid = apply(base_survfit$cumhaz[,group_factor==1], 1, sd), sd_hi = apply(base_survfit$cumhaz[,group_factor==2], 1, sd)) An additional note on grouping. I initially planned to evaluate this non-global metric just based on how well the polygenic risk score does in bringing about risk stratification. But following the logic from the AUC metrics, where we find far greater value in comparing the baseline AUC to an AUC that also considers the polygenic risk score, this non-global metric should likely do the same. Therefore we have a baseline cumualtive incidence based on all possible covariates and then a score enhanced cumulative incidence as well. And a final note on survival statistic names. I am far from an exper on this topic although I believe incidence and hazard can be used interchangeably (following the discussion https://cran.r-project.org/web/packages/survival/vignettes/compete.pdf). The idea is that by properly adjusting for the competing risk the hazard at any timepoint should be free from other effects and therefore is the ideal incidence that you are looking for. 8.1.4 Survival Score Metrics This code is nearly identical to the previous, except now we specify the fast and slow options that I explained in the previous section and iterate over each score, adding the score into the model before evaluating. all_conc &lt;- matrix(0, nrow = ncol(scores), ncol = 2) all_subrates &lt;- list() for(i in 1:nrow(all_conc)){ fg_diag_train$score &lt;- fg_scores_diag[fg_diag$eid %in% repeat_list[[nrepeat]][[nfold]][[&quot;train&quot;]],i] fg_diag_test$score &lt;- fg_scores_diag[fg_diag$eid %in% repeat_list[[nrepeat]][[nfold]][[&quot;test&quot;]],i] surv_df_train$score &lt;- scores[surv_df$eid %in% repeat_list[[nrepeat]][[nfold]][[&quot;train&quot;]],i] #Make the model score_mod &lt;- coxph(Surv(fgstart, fgstop, fgstatus) ~ age + sex + PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10 + score, data = fg_diag_train, weight = fgwt) #CONCORDANCE ################################### score_conc_obj &lt;- survConcordance(Surv(fgstart, fgstop, fgstatus) ~ predict(score_mod, fg_diag_test), data = fg_diag_test, weight = fgwt) all_conc[i,1] &lt;- score_conc_obj$conc all_conc[i,2] &lt;- score_conc_obj$std.err #SURVFIT ########################################## #SLOW if(subrate_style == &quot;slow&quot;){ score_survfit &lt;- survfit(score_mod, fg_diag_test, se.fit = F) final_cumhaz &lt;- score_survfit$cumhaz[nrow(score_survfit$cumhaz),] group_factor &lt;- rep(1, length(final_cumhaz)) group_factor[final_cumhaz &lt; quantile(final_cumhaz, 0.2)] &lt;- 0 group_factor[final_cumhaz &gt; quantile(final_cumhaz, 0.8)] &lt;- 2 pred_cumhaz_score &lt;- data.frame(time = score_survfit$time, mean_lo = apply(score_survfit$cumhaz[,group_factor==0], 1, mean), mean_mid = apply(score_survfit$cumhaz[,group_factor==1], 1, mean), mean_hi = apply(score_survfit$cumhaz[,group_factor==2], 1, mean), sd_lo = apply(score_survfit$cumhaz[,group_factor==0], 1, sd), sd_mid = apply(score_survfit$cumhaz[,group_factor==1], 1, sd), sd_hi = apply(score_survfit$cumhaz[,group_factor==2], 1, sd)) pred_cumhaz_score &lt;- pred_cumhaz_score[!duplicated(pred_cumhaz_score$mean_mid),] } else if(subrate_style == &quot;fast&quot;){ #FAST group_list &lt;- list() for(k in 1:length(names(score_mod$coef))){ group_list[[k]] &lt;- as.numeric(quantile(surv_df_train[[names(score_mod$coef)[k]]], c(0.1, 0.5, 0.9))) if(sign(score_mod$coef[k] == -1)){ group_list[[k]] &lt;- rev(group_list[[k]]) } } mean_df &lt;- data.frame(do.call(&quot;cbind&quot;, group_list)) colnames(mean_df) &lt;- names(score_mod$coef) if(sign(score_mod$coef[2]) == -1){ mean_df$sex &lt;- c(0.9, 0.5, 0.1) } else { mean_df$sex &lt;- c(0.1, 0.5, 0.9) } score_pred &lt;- survfit(score_mod, newdata = mean_df) pred_cumhaz_score &lt;- data.frame(score_pred$time, score_pred$cumhaz, score_pred$std.err) colnames(pred_cumhaz_score) &lt;- c(&quot;time&quot;, &quot;mean_lo&quot;, &quot;mean_mid&quot;, &quot;mean_hi&quot;, &quot;sd_lo&quot;, &quot;sd_mid&quot;, &quot;sd_hi&quot;) pred_cumhaz_score &lt;- pred_cumhaz_score[!duplicated(pred_cumhaz_score$mean_mid),] } all_subrates[[i]] &lt;- pred_cumhaz_score } 8.1.5 Logistic Regression Base Metrics Now we may move onto the relatively easier logistic regression metrics. The overall format of this code is similar to the survival base metrics, as in we first fit a base model and then calculate the AUC by making a prediction on the withheld dataset. Next we move onto the odds ratios, as explained previously the groups (or the exposed/non-exposed individuals) are determined by all the covariates in order to see how much the inclusion of the score improves the odds ratio. After producing the 2x2 contingency table through the full model prediction we get the odds ratio and the confidence intervals through the nice oddsratio.wald function. # Set up the normal model data print(&quot;normal&quot;) df &lt;- data.frame(pheno, covars[,-1]) df_train &lt;- df[covars[,1] %in% repeat_list[[nrepeat]][[nfold]][[&quot;train&quot;]],] df_test &lt;- df[covars[,1] %in% repeat_list[[nrepeat]][[nfold]][[&quot;test&quot;]],] scores_train &lt;- scores[covars[,1] %in% repeat_list[[nrepeat]][[nfold]][[&quot;train&quot;]],] scores_test &lt;- scores[covars[,1] %in% repeat_list[[nrepeat]][[nfold]][[&quot;test&quot;]],] pheno_test &lt;- pheno[covars[,1] %in% repeat_list[[nrepeat]][[nfold]][[&quot;test&quot;]]] ########################################################### # NORMAL MODELS # ########################################################### base_mod &lt;- glm(pheno ~ ., data = df_train, family = &quot;binomial&quot;) base_pred &lt;- predict(base_mod, df_test) base_roc &lt;- roc(pheno_test ~ base_pred) base_auc &lt;- as.numeric(ci.auc(base_roc)) base_group &lt;- rep(1, length(base_pred)) base_group[base_pred &lt; quantile(base_pred, 0.2)] &lt;- 0 base_group[base_pred &gt; quantile(base_pred, 0.8)] &lt;- 2 base_odds_table &lt;- matrix(c(sum(df_test$pheno == 1 &amp; base_group == 2), sum(df_test$pheno == 0 &amp; base_group == 2), sum(df_test$pheno == 1 &amp; base_group == 0), sum(df_test$pheno == 0 &amp; base_group == 0)), nrow = 2) base_odds_ratio &lt;- oddsratio.wald(base_odds_table) base_odds_ratio &lt;- base_odds_ratio$measure[2,c(2,1,3)] 8.1.6 Logistic Regression Score Metrics Again, this process is very similar to what was previously explained except now the models include the polygenic risk score. At the end of all the loops we also see how all of the metrics are collected together then saved. all_auc &lt;- matrix(0, nrow = ncol(scores), ncol = 3) all_odds_ratio &lt;- matrix(0, nrow = ncol(scores), ncol = 3) for(i in 1:ncol(scores)){ df_train$score &lt;- scores_train[,i] df_test$score &lt;- scores_test[,i] #Make the model score_mod &lt;- glm(pheno ~ ., data = df_train, family = &quot;binomial&quot;) score_pred &lt;- predict(score_mod, df_test) # AUC ##################################### score_roc &lt;- roc(pheno_test ~ score_pred) all_auc[i,] &lt;- as.numeric(ci.auc(score_roc)) # ODDS RATIO ############################# score_group &lt;- rep(1, length(score_pred)) score_group[score_pred &lt; quantile(score_pred, 0.2)] &lt;- 0 score_group[score_pred &gt; quantile(score_pred, 0.8)] &lt;- 2 score_odds_table &lt;- matrix(c(sum(df_test$pheno == 1 &amp; score_group == 2), sum(df_test$pheno == 0 &amp; score_group == 2), sum(df_test$pheno == 1 &amp; score_group == 0), sum(df_test$pheno == 0 &amp; score_group == 0)), nrow = 2) score_odds_ratio &lt;- oddsratio.wald(score_odds_table) all_odds_ratio[i,] &lt;- score_odds_ratio$measure[2,c(2,1,3)] } all_conc_holder[[overall_counter]] &lt;- all_conc all_survfit_holder[[overall_counter]] &lt;- all_subrates all_auc_holder[[overall_counter]] &lt;- all_auc all_or_holder[[overall_counter]] &lt;- all_odds_ratio all_base_holder[[1]][[overall_counter]] &lt;- base_conc all_base_holder[[2]][[overall_counter]] &lt;- base_cumhaz all_base_holder[[3]][[overall_counter]] &lt;- base_auc all_base_holder[[4]][[overall_counter]] &lt;- base_odds_ratio overall_counter &lt;- overall_counter + 1 #} #} final_obj &lt;- list(&quot;conc&quot; = all_conc_holder, &quot;survfit&quot; = all_survfit_holder, &quot;auc&quot; = all_auc_holder, &quot;or&quot; = all_or_holder) saveRDS(final_obj, paste0(&quot;tune_results/&quot;, author, &quot;_res.RDS&quot;)) 8.2 Choosing the Best Score Now that we have all of the performance metrics all we need to do to pick the best score is average over all of the repats and folds, then find the maximum. All of these are accomplished in a rather straightforward manner in the following script. #Read in the starting information all_author &lt;- unlist(lapply(strsplit(list.files(&quot;tune_results/&quot;, &quot;res&quot;), &quot;_&quot;), function(x) x[1])) for(author in all_author){ all_res &lt;- readRDS(paste0(&quot;tune_results/&quot;, author, &quot;_res.RDS&quot;)) #Average all of the results mean_conc &lt;- Reduce(&quot;+&quot;, all_res[[&quot;conc&quot;]])/length(all_res[[&quot;conc&quot;]]) mean_survfit &lt;- matrix(0, nrow = length(all_res[[&quot;survfit&quot;]][[1]]), ncol = 6) for(i in 1:length(all_res[[&quot;survfit&quot;]])){ for(j in 1:length(all_res[[&quot;score_names&quot;]])){ mean_survfit[j,] &lt;- mean_survfit[j,] + as.numeric(tail(all_res[[&quot;survfit&quot;]][[i]][[j]],1)[-1]) } } mean_survfit &lt;- mean_survfit/length(all_res[[&quot;survfit&quot;]]) mean_auc &lt;- Reduce(&quot;+&quot;, all_res[[&quot;auc&quot;]])/length(all_res[[&quot;auc&quot;]]) mean_or &lt;- Reduce(&quot;+&quot;, all_res[[&quot;or&quot;]])/length(all_res[[&quot;or&quot;]]) #Get the corresponding best score name conc_best_name &lt;- all_res[[&quot;score_names&quot;]][which.max(mean_conc[,2])] survfit_best_name &lt;- all_res[[&quot;score_names&quot;]][which.max(mean_survfit[,3]/mean_survfit[,1])] auc_best_name &lt;- all_res[[&quot;score_names&quot;]][which.max(mean_auc[,2])] or_best_name &lt;- all_res[[&quot;score_names&quot;]][which.max(mean_or[,2])] #Write the result to_write &lt;- rbind(conc_best_name, survfit_best_name, auc_best_name, or_best_name) write.table(to_write, paste0(&quot;tune_results/&quot;, tolower(author), &quot;.best.ss&quot;), row.names = T, col.names = F, quote = F, sep = &#39;\\t&#39;) #Get name for each method method_name &lt;- unlist(lapply(strsplit(all_res[[&quot;score_names&quot;]], &quot;.&quot;, fixed = T), function(x) x[3])) umethod_name &lt;- unique(method_name) best_method_name &lt;- rep(&quot;&quot;, length(umethod_name)) for(i in 1:length(umethod_name)){ best_method_name[i] &lt;- all_res[[&quot;score_names&quot;]][method_name == umethod_name[i]][which.max(mean_conc[method_name == umethod_name[i], 1])] } write.table(best_method_name, paste0(&quot;tune_results/&quot;, tolower(author), &quot;.methods.ss&quot;), row.names = F, col.names = F, quote = F) } We can now go onto the testing phase, quickly and easily picking out the score name that corresponds to our preferred metric. 8.3 Plotting Plotting is the final step in this process, converting all of the raw statistics into nice graphs that can be easily interpreted and checked for indications there are underlying errors in the code. I oddly have to break plotting into this final chunk as I am unable to make plots of my academic computing system, and instead do it locally on my laptop. The plotting script that I have written locally is really just one large function that allows for easy selection of which scores and stats to include in the output plots. However, no matter what plots are ultimately made there are 3 basic steps that are carried out. First we read in the results for a specific disease and extract all of the score and method names that are evaluated. Then the function begins. We start by averaging over all the cross validation iterations to get one statistic value for each score. We similarly do this for the base statistics (predictions that did not include any score). For the survfit predictions we are only looking at the last row, or the cumulative incidence of the last recorded time. The code is: library(stringr) library(ggplot2) library(cowplot) theme_set(theme_cowplot()) author &lt;- &quot;Kottgen&quot; res &lt;- readRDS(paste0(&quot;tune_results/&quot;, author, &quot;_res.RDS&quot;)) split_score_names &lt;- str_split(res[[&quot;score_names&quot;]], fixed(&quot;.&quot;), simplify = T) simple_name &lt;- paste0(split_score_names[,3], &quot;-&quot;, split_score_names[,2]) method_name &lt;- split_score_names[,3] #do_plot_series &lt;- function(subset_inds, draw_plot_option = &quot;none&quot;, save_option = FALSE, best_stat = &quot;auc&quot;){ if(length(unique(method_name[subset_inds])) == 1){ plot_ext &lt;- unique(method_name[subset_inds]) } else { plot_ext &lt;- &quot;best&quot; } ############################################################################## #Average all of the results mean_conc &lt;- Reduce(&quot;+&quot;, res[[&quot;conc&quot;]])/length(res[[&quot;conc&quot;]]) mean_survfit &lt;- matrix(0, nrow = length(res[[&quot;survfit&quot;]][[1]]), ncol = 6) for(i in 1:length(res[[&quot;survfit&quot;]])){ for(j in 1:length(res[[&quot;score_names&quot;]])){ mean_survfit[j,] &lt;- mean_survfit[j,] + as.numeric(tail(res[[&quot;survfit&quot;]][[i]][[j]],1)[-1]) } } mean_survfit &lt;- mean_survfit/length(res[[&quot;survfit&quot;]]) mean_auc &lt;- Reduce(&quot;+&quot;, res[[&quot;auc&quot;]])/length(res[[&quot;auc&quot;]]) mean_or &lt;- Reduce(&quot;+&quot;, res[[&quot;or&quot;]])/length(res[[&quot;or&quot;]]) ########################################################################### #Average for the base items base_conc &lt;- rep(0, 3) for(i in 1:length(res[[&quot;base&quot;]][[1]])){ base_conc &lt;- base_conc + as.numeric(c(res[[&quot;base&quot;]][[1]][[i]]$concordance, res[[&quot;base&quot;]][[1]][[i]]$std.err, res[[&quot;base&quot;]][[1]][[i]]$std.err * 1.96)) } base_conc &lt;- base_conc/length(res[[&quot;base&quot;]][[1]]) base_conc_mat &lt;- data.frame(&quot;base&quot;, &quot;base&quot;, t(base_conc), stringsAsFactors = F) colnames(base_conc_mat) &lt;- c(&quot;score_name&quot;, &quot;method&quot;, &quot;conc&quot;, &quot;se&quot;, &quot;ci&quot;) base_survfit &lt;- matrix(0, nrow = 1, ncol = 6) for(i in 1:length(res[[&quot;base&quot;]][[2]])){ base_survfit &lt;- base_survfit + as.numeric(tail(res[[&quot;base&quot;]][[2]][[i]],1)[-1]) } base_survfit &lt;- base_survfit/9 base_auc &lt;- 0 for(i in 1:length(res[[&quot;base&quot;]][[3]])){ base_auc &lt;- res[[&quot;base&quot;]][[3]][[i]] + base_auc } base_auc &lt;- base_auc/length(res[[&quot;base&quot;]][[3]]) base_or &lt;- 0 for(i in 1:length(res[[&quot;base&quot;]][[4]])){ base_or &lt;- res[[&quot;base&quot;]][[4]][[i]] + base_or } base_or &lt;- base_or/length(res[[&quot;base&quot;]][[4]]) Second we actually construct the plots. The main plotting philosophy I try to follow is show the plain data without abstraction, keep it visually appealing while also detailed. For example, plotting points instead of bars and error bars wherever available. Specific to this investigation is the added requirement to include the base performance while differentiating it from the score performance. The code used is below, and the related plots are at the bottom of this section. ################################################################# #CONC PLOT conc &lt;- data.frame(simple_name, method_name, mean_conc) conc &lt;- conc[subset_inds,] colnames(conc) &lt;- c(&quot;score_name&quot;, &quot;method&quot;, &quot;conc&quot;, &quot;se&quot;) conc$ci &lt;- conc$se * 1.96 conc$score_name &lt;- factor(conc$score_name, levels = conc$score_name[order(conc$conc)]) the_conc_plot &lt;- ggplot(conc, aes(conc, score_name)) + geom_point() + geom_errorbarh(aes(xmin = conc-ci, xmax = conc+ci, height = 0.4)) + labs(x = &quot;Concordance&quot;, y = &quot;Score Name&quot;) + geom_vline(xintercept = base_conc[1], linetype = &quot;dashed&quot;, alpha = 0.3) #AUC PLOT auc &lt;- data.frame(simple_name, method_name, mean_auc) auc &lt;- auc[subset_inds,] colnames(auc) &lt;- c(&quot;score_name&quot;, &quot;method&quot;, &quot;ci_lo&quot;, &quot;auc&quot;, &quot;ci_hi&quot;) auc$score_name &lt;- factor(auc$score_name, levels = auc$score_name[order(auc$auc)]) the_auc_plot &lt;- ggplot(auc, aes(auc, score_name)) + geom_point() + geom_errorbarh(aes(xmin = ci_lo, xmax = ci_hi, height = 0.4)) + labs(x = &quot;AUC&quot;, y = &quot;Score Name&quot;) + geom_vline(xintercept = base_auc[2], linetype = &quot;dashed&quot;, alpha = 0.3) #EVENT RATE km_df &lt;- mean_survfit[subset_inds,] km_df &lt;- data.frame(mean_vals = as.numeric(t(km_df[,1:3])), sd_vals = as.numeric(t(km_df[,4:6]))) km_df$group &lt;- as.factor(rep(1:3, nrow(km_df)/3)) km_df$simple_name &lt;- rep(simple_name[subset_inds], each = 3) km_df$method_name &lt;- rep(method_name[subset_inds], each = 3) km_df$simple_name &lt;- factor(km_df$simple_name, levels = km_df$simple_name[km_df$group == 3][ order(km_df$mean_vals[km_df$group == 3])]) the_km_plot &lt;- ggplot(km_df, aes(simple_name, mean_vals, color = group, ymin = mean_vals - sd_vals, ymax = mean_vals + sd_vals)) + geom_point(position = position_dodge(width = 0.1)) + geom_errorbar(position = position_dodge(width = 0.1), width = 0.2) + labs(y = &quot;Cumulative Hazard&quot;, x = &quot;Score Name&quot;, color = &quot;Risk\\nGroup&quot;) + theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) + geom_hline(yintercept = base_survfit[1], linetype = &quot;dashed&quot;, alpha = 0.3) + geom_hline(yintercept = base_survfit[2], linetype = &quot;solid&quot;, alpha = 0.3) + geom_hline(yintercept = base_survfit[3], linetype = &quot;dashed&quot;, alpha = 0.3) #ODDS RATIO odds_df &lt;- data.frame(mean_or, simple_name, method_name) odds_df &lt;- odds_df[subset_inds,] colnames(odds_df) &lt;- c(&quot;lo&quot;, &quot;or&quot;, &quot;hi&quot;, &quot;simple_name&quot;, &quot;method_name&quot;) odds_df$simple_name &lt;- factor(simple_name[subset_inds], simple_name[subset_inds][order(odds_df$or)]) the_or_plot &lt;- ggplot(odds_df, aes(or, simple_name)) + geom_point() + geom_errorbarh(aes(xmin = lo, xmax = hi), height = 0.5) + labs(x = &quot;Odds Ratio&quot;, y = &quot;Score Name&quot;) + geom_vline(xintercept = base_or[2], linetype = &quot;dashed&quot;, alpha = 0.3) Third we create rules to determine precisely which plots should be made. In theory we could create a plot for each statistic by score by disease. This would be thousands of plots and therefore not very helpful at all. We can combine all scores together but this would be over 100 scores on a single plot, making it very hard to read. The compromise I am currently going for is to plot the best score for each method for each statistic and all scores for each method for AUC only, thereby meaning we only need 4 + 12 plots per disease are made. The function I have written allows for more customization. We can set save option to TRUE and plot everything, or choose a best stat only. Additionaly, the input to the plotting function selects which scores I am looking at, they can be only the indices for a given method or the best methods. The code is below: #Get best name among the subsetinds ################################################################# if(best_stat == &quot;conc&quot;){ best_name &lt;- as.character(conc$score_name[which.max(conc$conc)]) }else if(best_stat == &quot;auc&quot;){ best_name &lt;- as.character(auc$score_name[which.max(auc$auc)]) }else if(best_stat == &quot;km&quot;){ comp_km &lt;- data.frame(name = km_df$simple_name[km_df$group == 1], ratio = km_df$mean_vals[km_df$group == 3]/km_df$mean_vals[km_df$group == 1]) comp_km$ratio[is.na(comp_km$ratio)] &lt;- 0 best_name &lt;- as.character(comp_km$name[which.max(comp_km$ratio)]) }else if(best_stat == &quot;or&quot;){ best_name &lt;- as.character(odds_df$simple_name[which.max(odds_df$or)]) } #make the plots ################################################################# if(draw_plot_option == &quot;all&quot;){ plot(the_auc_plot) plot(the_conc_plot) plot(the_or_plot) plot(the_km_plot) if(save_option){ ggsave(paste0(&quot;output_plots/&quot;, tolower(author), &quot;.&quot;, plot_ext, &quot;.conc.tune.png&quot;), the_conc_plot + theme(plot.margin=unit(c(1,1,1,1), &quot;cm&quot;)), &quot;png&quot;, width = 5, height = 5) ggsave(paste0(&quot;output_plots/&quot;, tolower(author), &quot;.&quot;, plot_ext, &quot;.auc.tune.png&quot;), the_auc_plot + theme(plot.margin=unit(c(1,1,1,1), &quot;cm&quot;)), &quot;png&quot;, width = 5, height = 5) ggsave(paste0(&quot;output_plots/&quot;, tolower(author), &quot;.&quot;, plot_ext, &quot;.or.tune.png&quot;), the_or_plot + theme(plot.margin=unit(c(1,1,1,1), &quot;cm&quot;)), &quot;png&quot;, width = 5, height = 5) ggsave(paste0(&quot;output_plots/&quot;, tolower(author), &quot;.&quot;, plot_ext, &quot;.km.tune.png&quot;), the_km_plot + theme(plot.margin=unit(c(1,1,1,1), &quot;cm&quot;)), &quot;png&quot;, width = 7, height = 6) } } else if(draw_plot_option == &quot;choose_stat&quot;){ if(best_stat == &quot;conc&quot;){ plot(the_conc_plot) if(save_option){ ggsave(paste0(&quot;output_plots/&quot;, tolower(author), &quot;.&quot;, plot_ext, &quot;.conc.tune.png&quot;), the_conc_plot + theme(plot.margin=unit(c(1,1,1,1), &quot;cm&quot;)), &quot;png&quot;, width = 5, height = 5) } }else if(best_stat == &quot;auc&quot;){ plot(the_auc_plot) if(save_option){ ggsave(paste0(&quot;output_plots/&quot;, tolower(author), &quot;.&quot;, plot_ext, &quot;.auc.tune.png&quot;), the_auc_plot + theme(plot.margin=unit(c(1,1,1,1), &quot;cm&quot;)), &quot;png&quot;, width = 5, height = 5) } }else if(best_stat == &quot;km&quot;){ plot(the_km_plot) if(save_option){ ggsave(paste0(&quot;output_plots/&quot;, tolower(author), &quot;.&quot;, plot_ext, &quot;.km.tune.png&quot;), the_km_plot + theme(plot.margin=unit(c(1,1,1,1), &quot;cm&quot;)), &quot;png&quot;, width = 7, height = 6) } }else if(best_stat == &quot;or&quot;){ plot(the_or_plot) if(save_option){ ggsave(paste0(&quot;output_plots/&quot;, tolower(author), &quot;.&quot;, plot_ext, &quot;.or.tune.png&quot;), the_or_plot + theme(plot.margin=unit(c(1,1,1,1), &quot;cm&quot;)), &quot;png&quot;, width = 5, height = 5) } } } return(best_name) #} best_names &lt;- rep(&quot;&quot;, length(unique(method_name))) for(i in 1:length(unique(method_name))){ method_inds &lt;- which(method_name %in% unique(method_name)[i]) best_names[i] &lt;- do_plot_series(method_inds) } final_best_name &lt;- do_plot_series(which(simple_name %in% best_names), &quot;all&quot;, TRUE) Now the plots. There are 4 plots for each type of statistic, they appear as: Figure 8.1: Tuning AUC Plot Figure 8.2: Tuning OR Plot Figure 8.3: Tuning Concordance Plot Figure 8.4: Tuning Kaplan-Meir Analysis Plot For all plots please see: https://wcm.box.com/s/h4xrik195rdp57a0hyhjdkgf55kcju0j . "],["testing.html", "9 Testing 9.1 Obtaining the Statistics 9.2 Plotting", " 9 Testing 9.1 Obtaining the Statistics The testing process is quite similar to the tuning section in the code that is written, but very different in the motivation of the larger project. Up to this point the focus of the project has largely been attempting to determine what is the best method and parameter combination for a given disease. But now we want to go beyond just categorization of the best method to a precise quantization of how good the method is. This evaluation is important, for example a method could be the best out of 1000 but if the AUC in a validation set is only 0.51 that method is nevertheless quite worthless. With this changed understanding of the motivation, we can now move onto the code. As previously stated the code is extremely similar to the tuning code, the main difference is that we now need to read in the full possible dataset, split it into the training and testing, then finally use these new datasets throughout for making predictions and related statistics. There are a few other differences that while not as important are still critical. First of which is the addition of possible covariates or additional scores. As a quick reminder the additional covariates originate from a literature review that reports significant risk factors that may minimize the polygenic risk score effect, and the additional scores are other scores not from this project but releveant to the disease of interest and available in the PGS catalog. Each of these possible feature sets are included in a model and compared to each other, just as the base and score models are compared. For simplicity, these additional models are only analyzed in relation to non-survival related analyses. The second notable difference is the addition of PR or precision-recall curves. PR curves are very similar to ROC curves in both analysis and construction. The third and final difference is the saving of more data than compared to training, specifically the full Kaplan-Meier curve data. Seeing as all of these changes are implicit in how the code is written or scattered throughout the entire script, I will just put the code below without splitting it up or including extensive explanations. There are however comments in the code where the testing is particularly different from the training. library(survival) library(PRROC) library(pROC) library(epitools) #author &lt;- &quot;Shah&quot; #Liu-2, Malik, Nikpay, Okada, Onengut, Phelan, Rheenen author &lt;- &quot;Michailidou&quot; #author &lt;- commandArgs(trailingOnly=TRUE) phen_method &lt;- &quot;icd_selfrep&quot; score_method &lt;- &quot;auc_best_name&quot; subrate_style &lt;- &quot;slow&quot; train_frac &lt;- 0.6 test_frac &lt;- 1 - train_frac #THERE MAY BE PROBLEMS WITH SURV_DF #Read in the PGSs #Right at the top we read in the train and test eids explicitly all_scores &lt;- readRDS(paste0(&quot;../../do_score/final_scores/all_score.&quot;, tolower(author), &quot;.RDS&quot;)) all_eid &lt;- read.table(&quot;~/athena/doc_score/do_score/all_specs/for_eid.fam&quot;, stringsAsFactors=F) train_eid &lt;- read.table(paste0(&quot;~/athena/doc_score/qc/cv_files/train_eid.&quot;, train_frac, &quot;.txt&quot;), stringsAsFactors=F) test_eid &lt;- read.table(paste0(&quot;~/athena/doc_score/qc/cv_files/test_eid.&quot;, test_frac, &quot;.txt&quot;), stringsAsFactors=F) eid &lt;- all_eid[,1] all_scores &lt;- all_scores[eid %in% train_eid[,1] | eid %in% test_eid[,1],] eid &lt;- eid[eid %in% train_eid[,1] | eid %in% test_eid[,1]] #Normalize the scores best_score &lt;- read.table(paste0(&quot;../tune_score/tune_results/&quot;, tolower(author), &quot;.best.ss&quot;), stringsAsFactors=F) best_score &lt;- best_score[best_score[,1] == score_method,2] scores &lt;- all_scores[,grepl(tolower(author), colnames(all_scores))] scores &lt;- scores[,apply(scores, 2, function(x) length(unique(x)) &gt; 3)] scores &lt;- apply(scores, 2, function(x) (x-mean(x)) / (max(abs((x-mean(x)))) * 0.01) ) scores &lt;- scores[,colnames(scores) == best_score,drop=F] # NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW # NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW # ADDED COVARIATES # # NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW # NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW #get other scores - scores that I did not compile directly if they are available #First check to see if there are any additional scores for the disease currently under analysis #Then if so (in the for loop) we read in the other scores and sort them appropriately other_scores &lt;- readRDS(&quot;../other_scores/final_scores/all_score.1.RDS&quot;) other_defs &lt;- read.table(&quot;../descript_defs/author_scores&quot;, stringsAsFactors=F, header=T) other_defs &lt;- other_defs[other_defs[,1] == author,] if(any(colnames(other_scores) %in% other_defs$PGS_Catalog_name)){ run_other_scores &lt;- TRUE other_scores &lt;- other_scores[,colnames(other_scores) %in% other_defs$PGS_Catalog_name,drop=F] other_eid &lt;- read.table(&quot;../other_scores/final_scores/eid&quot;, stringsAsFactors=F) other_scores &lt;- data.frame(eid = other_eid, other_scores) } else { run_other_scores &lt;- FALSE } # END NEW ######################################################################################### # END NEW ######################################################################################### #Read in the phenotypes, order is: cancer sr, noncancer sr, icd9, icd10, oper, meds #selfasses date: 2018-11-22; hesin date: 21/01/2000 pheno &lt;- read.table(paste0(&quot;../construct_defs/pheno_defs/diag.&quot;, tolower(author), &quot;.txt.gz&quot;), stringsAsFactors=F) dates &lt;- read.table(paste0(&quot;../construct_defs/pheno_defs/time.&quot;, tolower(author), &quot;.txt.gz&quot;), stringsAsFactors=F) for(i in 1:ncol(dates)){ if(i %in% c(1,2,6)){ dates[dates[,i] == &quot;__________&quot;, i] &lt;- &quot;2020-12-31&quot; dates[,i] &lt;- as.Date(dates[,i], &quot;%Y-%m-%d&quot;) } else { dates[dates[,i] == &quot;__________&quot;, i] &lt;- &quot;31/12/2020&quot; dates[,i] &lt;- as.Date(dates[,i], &quot;%d/%m/%Y&quot;) } } if(phen_method == &quot;icd&quot;){ pheno &lt;- pheno[,3:4] dates &lt;- dates[,3:4] } else if(phen_method == &quot;selfrep&quot;){ pheno &lt;- pheno[,1:2] dates &lt;- dates[,1:2] } else if(phen_method == &quot;icd_selfrep&quot;){ pheno &lt;- pheno[,1:4] dates &lt;- dates[,1:4] } else if(phen_method == &quot;all&quot; | phen_method == &quot;double&quot;){ print(&quot;doing nothing&quot;) } dates &lt;- apply(dates, 1, min) dates[dates == as.Date(&quot;2020-12-31&quot;)] &lt;- NA if(phen_method == &quot;double&quot;){ pheno &lt;- rowSums(pheno) pheno[pheno == 1] &lt;- 0 pheno[pheno &gt; 1] &lt;- 1 dates[pheno == 0] &lt;- NA } else { pheno &lt;- rowSums(pheno) pheno[pheno &gt; 1] &lt;- 1 } #exit() #Read in the eids used that are the same order as the pheno and dates, then subset the pheno and dates accordingly pheno_eids &lt;- read.table(&quot;../construct_defs/eid.csv&quot;, header = T) pheno_eids &lt;- pheno_eids[order(pheno_eids[,1]),] pheno_eids &lt;- pheno_eids[-length(pheno_eids)] scores &lt;- scores[eid %in% pheno_eids, , drop = F] eid &lt;- eid[eid %in% pheno_eids] train_eid &lt;- train_eid[train_eid[,1] %in% pheno_eids,] test_eid &lt;- test_eid[test_eid[,1] %in% pheno_eids,] dates &lt;- dates[pheno_eids %in% eid] pheno &lt;- pheno[pheno_eids %in% eid] pheno_eids &lt;- pheno_eids[pheno_eids %in% eid] scores &lt;- scores[eid %in% pheno_eids, , drop = F] eid &lt;- eid[eid %in% pheno_eids] dates &lt;- dates[order(pheno_eids)[rank(eid)]] pheno &lt;- pheno[order(pheno_eids)[rank(eid)]] #eid is the correct order #Read in the base covars covars &lt;- readRDS(&quot;../get_covars/base_covars.RDS&quot;) covars &lt;- covars[covars[,1] %in% eid,] covars &lt;- covars[order(covars[,1])[rank(eid)],] #Set up survival analysis data frame #Artifically decide start date is 1999, that way all are even, if date is prior then remove it #The current maximum date possible is 31 May 2020 death &lt;- read.table(&quot;~/athena/ukbiobank/hesin/death.txt&quot;, stringsAsFactors=F, header = T) death[,5] &lt;- unlist(lapply(death[,5], function(x) paste0(strsplit(x, &quot;/&quot;)[[1]][3], &quot;-&quot;, strsplit(x, &quot;/&quot;)[[1]][2], &quot;-&quot;, strsplit(x, &quot;/&quot;)[[1]][1]))) death &lt;- death[!duplicated(death[,1]),] death &lt;- death[death[,1] %in% eid,] add_on &lt;- death[1,] add_on[5] &lt;- &quot;&quot; add_eid &lt;- eid[!(eid %in% death[,1])] add_on &lt;- add_on[rep(1, length(add_eid)),] add_on$eid &lt;- add_eid death &lt;- rbind(death, add_on) death &lt;- death[order(death[,1])[rank(eid)],] censor &lt;- read.table(&quot;../get_covars/covar_data/censor_covars&quot;, stringsAsFactors=F, header = T, sep = &quot;,&quot;) if(sum(!(eid %in% censor[,1])) &gt; 0){ add_on &lt;- matrix(0, nrow = sum(!(eid %in% censor[,1])), ncol = 3) add_on[,1] &lt;- eid[!(eid %in% censor[,1])] colnames(add_on) &lt;- colnames(censor) censor &lt;- rbind(censor, add_on) } censor &lt;- censor[censor[,1] %in% eid,] censor &lt;- censor[order(censor[,1])[rank(eid)],] start_date &lt;- rep(&quot;1999-01-01&quot;, nrow(scores)) end_date &lt;- rep(&quot;2020-05-31&quot;, nrow(scores)) end_date[censor[,2] != &quot;&quot;] &lt;- censor[censor[,2] != &quot;&quot;, 2] end_date[death[,5] != &quot;&quot;] &lt;- death[death[,5] != &quot;&quot;, 5] end_date[!is.na(dates)] &lt;- dates[!is.na(dates)] is_death_date &lt;- rep(0, nrow(scores)) is_death_date[death[,5] != &quot;&quot;] &lt;- 1 surv_df &lt;- data.frame(time = as.numeric(as.Date(end_date) - as.Date(start_date)), pheno, is_death_date, covars, score = scores[,1]) df &lt;- data.frame(pheno, covars[,-1], score = scores[,1]) #need to remove people that had diagnosis before accepted start of the study eid &lt;- eid[surv_df$time &gt; 0] df &lt;- df[surv_df$time &gt; 0,] covars &lt;- covars[surv_df$time &gt; 0,] pheno &lt;- pheno[surv_df$time &gt; 0] surv_df &lt;- surv_df[surv_df$time &gt; 0,] # NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW # NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW # ADDED COVARIATES # # NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW # NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW #get the other covariates #Specifically, if there are covariates other than age and sex that other resources believe are risk factors for this disease then we read them in and order them such that they align with the already existing covariates #We can pull these additional covariates from two different place however, from the ICD or non ICD records #If from the non-ICD we first get the names from extra covars, and then subset those names out of the single_col_covars poss_covars &lt;- read.table(&quot;../descript_defs/author_covar&quot;, stringsAsFactors=F, sep = &quot;\\t&quot;) poss_author &lt;- gsub(&quot;-&quot;, &quot;&quot;, author) extra_covars &lt;- strsplit(poss_covars[poss_covars[,1] == poss_author,2], &quot;,&quot;)[[1]] extra_covars &lt;- gsub(&quot; &quot;, &quot;_&quot;, extra_covars) single_col_covars &lt;- read.table(&quot;../get_covars/covar_data/single_col_covars&quot;, stringsAsFactors=F, header=T) single_col_covars &lt;- single_col_covars[,colnames(single_col_covars) %in% c(&quot;eid&quot;, extra_covars), drop = F] single_col_covars &lt;- single_col_covars[,!colnames(single_col_covars) %in% c(&quot;age&quot;, &quot;sex&quot;),drop=F] if(ncol(single_col_covars) &gt; 1){ single_col_covars &lt;- single_col_covars[single_col_covars$eid %in% eid,,drop=F] single_col_covars &lt;- single_col_covars[order(single_col_covars$eid)[rank(eid)],] #nrow(single_col_covars) may be &lt; length(eid) single_col_covars &lt;- single_col_covars[,-1,drop=F] } else { single_col_covars &lt;- NULL } #If from the ICD record we read in the specific covariate file made from the ICDs that goes with the disease #Similar with non-ICD we first have to check if there are any non-ICD covariates relevant, and then if so we go on and read them in and proceed with sorting #With non-ICD or ICD covariates we leave the covariate file NULL if there is nothing relevant hesin_decode &lt;- read.table(&quot;../descript_defs/author_to_covar_hesin&quot;, stringsAsFactors=F) hesin_decode &lt;- strsplit(hesin_decode[hesin_decode[,1] == poss_author,2], &quot;,&quot;)[[1]] sort_covar &lt;- read.table(&quot;../descript_defs/covar_defs_hesin&quot;, stringsAsFactors=F) hesin_decode &lt;- sort_covar[sort_covar[,1] %in% hesin_decode,1] if(any(grepl(tolower(author), list.files(&quot;../get_covars/hesin_covars/&quot;)))){ hesin_covar &lt;- read.table(paste0(&quot;../get_covars/hesin_covars/diag.coding.&quot;, tolower(author), &quot;.txt.gz&quot;), stringsAsFactors=F, header=F) hesin_eid &lt;- read.table(paste0(&quot;../get_covars/hesin_covars/eid.txt.gz&quot;), stringsAsFactors=F, header=F) colnames(hesin_covar) &lt;- hesin_decode hesin_covar &lt;- hesin_covar[hesin_eid[,1] %in% eid,,drop=F] hesin_covar &lt;- hesin_covar[order(hesin_eid[,1])[rank(eid)],,drop=F] hesin_covar &lt;- hesin_covar[,colSums(hesin_covar) &gt; 0,drop=F] } else { hesin_covar &lt;- NULL } #We finish this extra covariate process by combining the ICD and non-ICD files into a singe extra_covar #Also we set a variable indicating whether or not we should try to run models with extra covariates run_extra_covar &lt;- TRUE if(!is.null(single_col_covars) &amp; !is.null(hesin_covar)){ extra_covar &lt;- cbind(single_col_covars, hesin_covar) } else if(!is.null(single_col_covars)){ extra_covar &lt;- single_col_covars } else if(!is.null(hesin_covar)){ extra_covar &lt;- hesin_covar } else { run_extra_covar &lt;- FALSE } # END NEW #################################################################################### ############################################################################################## #add in the other interesting covariates if(run_other_scores){ other_scores &lt;- other_scores[other_scores[,1] %in% eid,] other_scores &lt;- other_scores[order(other_scores[,1])[rank(eid)],] other_scores &lt;- other_scores[,-1,drop=F] } if(run_other_scores &amp; run_extra_covar){ df &lt;- cbind(df, extra_covar, other_scores) surv_df &lt;- cbind(surv_df, extra_covar, other_scores) } else if(run_other_scores){ df &lt;- cbind(df, other_scores) surv_df &lt;- cbind(surv_df, other_scores) } else if(run_extra_covar){ df &lt;- cbind(df, extra_covar) surv_df &lt;- cbind(surv_df, extra_covar) } #Subset the sex author_defs &lt;- read.table(&quot;../descript_defs/author_defs&quot;, stringsAsFactors=F, header=T) subset_sex &lt;- author_defs$sex[author_defs$author == author] if(subset_sex == &quot;F&quot;){ eid &lt;- eid[df$sex == 0] df &lt;- df[df$sex == 0,] surv_df &lt;- surv_df[surv_df$sex == 0,] df &lt;- df[,-which(colnames(df) == &quot;sex&quot;)] surv_df &lt;- surv_df[,-which(colnames(surv_df) == &quot;sex&quot;)] base_covars &lt;- c(&quot;age + PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10&quot;) }else if(subset_sex == &quot;M&quot;){ eid &lt;- eid[df$sex == 1] df &lt;- df[df$sex == 1,] surv_df &lt;- surv_df[surv_df$sex == 1,] df &lt;- df[,-which(colnames(df) == &quot;sex&quot;)] surv_df &lt;- surv_df[,-which(colnames(surv_df) == &quot;sex&quot;)] base_covars &lt;- c(&quot;age + PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10&quot;) } else { base_covars &lt;- c(&quot;age + sex + PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10&quot;) } #Set up Fine and Gray print(&quot;finegray&quot;) event_type &lt;- rep(&quot;censor&quot;, nrow(surv_df)) event_type[surv_df$pheno == 1] &lt;- &quot;diagnosis&quot; event_type[surv_df$is_death_date == 1] &lt;- &quot;death&quot; surv_df$event_type &lt;- as.factor(event_type) surv_df$eid &lt;- eid fg_diag &lt;- finegray(Surv(time, event_type) ~ ., data = surv_df[,-which(colnames(surv_df) %in% c(&quot;is_death_date&quot;, &quot;pheno&quot;))], etype=&quot;diagnosis&quot;) fg_death &lt;- finegray(Surv(time, event_type) ~ ., data = surv_df[,-which(colnames(surv_df) %in% c(&quot;is_death_date&quot;, &quot;pheno&quot;))], etype=&quot;death&quot;) fg_scores_diag &lt;- fg_diag[,grepl(tolower(author), colnames(fg_diag))] fg_scores_death &lt;- fg_death[,grepl(tolower(author), colnames(fg_death))] fg_diag &lt;- fg_diag[,!grepl(&quot;ss&quot;, colnames(fg_diag))] fg_death &lt;- fg_death[,!grepl(&quot;ss&quot;, colnames(fg_death))] df_train &lt;- df[eid %in% train_eid[,1],] df_test &lt;- df[eid %in% test_eid[,1],] surv_df_train &lt;- surv_df[eid %in% train_eid[,1],] surv_df_test &lt;- surv_df[eid %in% test_eid[,1],] fg_diag_train &lt;- fg_diag[fg_diag$eid %in% train_eid[,1],] fg_diag_test &lt;- fg_diag[fg_diag$eid %in% test_eid[,1],] fg_death_train &lt;- fg_death[fg_death$eid %in% train_eid[,1],] fg_death_test &lt;- fg_death[fg_death$eid %in% test_eid[,1],] #exit() ########################################################### # SURVIVAL ANALYSES # ########################################################### #BASE ############################### base_mod &lt;- coxph(as.formula(paste0(&quot;Surv(fgstart, fgstop, fgstatus) ~ &quot;, base_covars)), data = fg_diag_train, weight = fgwt) base_conc_obj &lt;- survConcordance(Surv(fgstart, fgstop, fgstatus) ~ predict(base_mod, fg_diag_test), data = fg_diag_test, weight = fgwt) base_conc &lt;- c(base_conc_obj$conc, base_conc_obj$std.err) base_survfit &lt;- survfit(base_mod, fg_diag_test, se.fit = F) base_full_cumhaz &lt;- base_survfit$cumhaz[,!duplicated(fg_diag_test$eid)] final_cumhaz &lt;- base_full_cumhaz[nrow(base_survfit$cumhaz),] group_factor &lt;- rep(1, length(final_cumhaz)) group_factor[final_cumhaz &lt; quantile(final_cumhaz, 0.2)] &lt;- 0 group_factor[final_cumhaz &gt; quantile(final_cumhaz, 0.8)] &lt;- 2 base_avg_cumhaz &lt;- data.frame(time = base_survfit$time, mean_lo = apply(base_full_cumhaz[,group_factor==0], 1, mean), mean_mid = apply(base_full_cumhaz[,group_factor==1], 1, mean), mean_hi = apply(base_full_cumhaz[,group_factor==2], 1, mean), sd_lo = apply(base_full_cumhaz[,group_factor==0], 1, sd), sd_mid = apply(base_full_cumhaz[,group_factor==1], 1, sd), sd_hi = apply(base_full_cumhaz[,group_factor==2], 1, sd)) #WITH SCORE ########################### #Make the model score_mod &lt;- coxph(as.formula(paste0(&quot;Surv(fgstart, fgstop, fgstatus) ~ &quot;, base_covars, &quot; + score&quot;)), data = fg_diag_train, weight = fgwt) #CONCORDANCE ################################### score_conc_obj &lt;- survConcordance(Surv(fgstart, fgstop, fgstatus) ~ predict(score_mod, fg_diag_test), data = fg_diag_test, weight = fgwt) score_conc &lt;- c(score_conc_obj$conc, score_conc_obj$std.err) #SURVFIT ########################################## #SLOW if(subrate_style == &quot;slow&quot;){ all_cumhaz &lt;- list() all_time &lt;- list() start_vals &lt;- seq(1, nrow(surv_df_test), 1000) end_vals &lt;- c(start_vals[-1]-1, nrow(surv_df_test)) for(k in 1:length(start_vals)){ g1 &lt;- surv_df_test$eid[start_vals[k]:end_vals[k]] score_survfit &lt;- survfit(score_mod, fg_diag_test[fg_diag_test$eid %in% g1,], se.fit = F) all_cumhaz[[k]] &lt;- score_survfit$cumhaz[,!duplicated(fg_diag_test$eid[fg_diag_test$eid %in% g1])] all_time[[k]] &lt;- score_survfit$time } score_full_cumhaz &lt;- do.call(&quot;cbind&quot;, all_cumhaz) final_cumhaz &lt;- score_full_cumhaz[nrow(score_survfit$cumhaz),] group_factor &lt;- rep(1, length(final_cumhaz)) group_factor[final_cumhaz &lt; quantile(final_cumhaz, 0.2)] &lt;- 0 group_factor[final_cumhaz &gt; quantile(final_cumhaz, 0.8)] &lt;- 2 score_avg_cumhaz &lt;- data.frame(time = score_survfit$time, mean_lo = apply(score_full_cumhaz[,group_factor==0], 1, mean), mean_mid = apply(score_full_cumhaz[,group_factor==1], 1, mean), mean_hi = apply(score_full_cumhaz[,group_factor==2], 1, mean), sd_lo = apply(score_full_cumhaz[,group_factor==0], 1, sd), sd_mid = apply(score_full_cumhaz[,group_factor==1], 1, sd), sd_hi = apply(score_full_cumhaz[,group_factor==2], 1, sd)) score_avg_cumhaz &lt;- score_avg_cumhaz[!duplicated(score_avg_cumhaz$mean_mid),] } else if(subrate_style == &quot;fast&quot;){ #FAST group_list &lt;- list() for(k in 1:length(names(score_mod$coef))){ group_list[[k]] &lt;- as.numeric(quantile(surv_df_train[[names(score_mod$coef)[k]]], c(0.1, 0.5, 0.9))) if(sign(score_mod$coef[k] == -1)){ group_list[[k]] &lt;- rev(group_list[[k]]) } } mean_df &lt;- data.frame(do.call(&quot;cbind&quot;, group_list)) colnames(mean_df) &lt;- names(score_mod$coef) if(sign(score_mod$coef[2]) == -1){ mean_df$sex &lt;- c(0.9, 0.5, 0.1) } else { mean_df$sex &lt;- c(0.1, 0.5, 0.9) } score_pred &lt;- survfit(score_mod, newdata = mean_df) score_full_cumhaz &lt;- NULL score_avg_cumhaz &lt;- data.frame(score_pred$time, score_pred$cumhaz, score_pred$std.err) colnames(score_avg_cumhaz) &lt;- c(&quot;time&quot;, &quot;mean_lo&quot;, &quot;mean_mid&quot;, &quot;mean_hi&quot;, &quot;sd_lo&quot;, &quot;sd_mid&quot;, &quot;sd_hi&quot;) score_avg_cumhaz &lt;- score_avg_cumhaz[!duplicated(score_avg_cumhaz$mean_mid),] } # Set up the normal model data print(&quot;normal&quot;) ########################################################### # NORMAL MODELS # ########################################################### base_mod &lt;- glm(as.formula(paste0(&quot;pheno ~ &quot;, base_covars)), data = df_train, family = &quot;binomial&quot;) base_pred &lt;- predict(base_mod, df_test) base_roc &lt;- roc(df_test$pheno ~ base_pred, quiet=T) base_auc &lt;- as.numeric(ci.auc(base_roc)) base_pr &lt;- pr.curve(scores.class0 = base_pred, weights.class0 = df_test$pheno, curve = T) # NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW # if there are additional covariates then I should create a model that includes these covariates # then with this model form a complementary prediction from which ROC and PR curves can be drawn # this is the same process that happens in the odds ratio for loop after if(run_extra_covar) ... # NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW if(run_extra_covar){ df_train_extra &lt;- df_train[complete.cases(df_train),] df_test_extra &lt;- df_test[complete.cases(df_test),] extra_base_mod &lt;- glm(as.formula(paste0(&quot;pheno ~ &quot;, base_covars, &quot;+&quot;, paste(colnames(extra_covar), collapse = &quot;+&quot;))), data = df_train_extra, family = &quot;binomial&quot;) extra_base_pred &lt;- predict(extra_base_mod, df_test_extra) extra_base_roc &lt;- roc(df_test_extra$pheno ~ extra_base_pred, quiet=T) extra_base_auc &lt;- as.numeric(ci.auc(extra_base_roc)) extra_base_pr &lt;- pr.curve(scores.class0 = extra_base_pred, weights.class0 = df_test_extra$pheno, curve = T) } all_base_odds_ratio &lt;- matrix(0, nrow = 6, ncol = 3) all_extra_base_odds_ratio &lt;- matrix(0, nrow = 6, ncol = 3) k &lt;- 1 for(cut_off in c(0.5, 0.8, 0.9, 0.95, 0.99, 0.995)){ base_group &lt;- rep(1, length(base_pred)) base_group[base_pred &lt; quantile(base_pred, 0.2)] &lt;- 0 base_group[base_pred &gt; quantile(base_pred, cut_off)] &lt;- 2 base_odds_table &lt;- matrix(c(sum(df_test$pheno == 1 &amp; base_group == 2), sum(df_test$pheno == 0 &amp; base_group == 2), sum(df_test$pheno == 1 &amp; base_group == 0), sum(df_test$pheno == 0 &amp; base_group == 0)), nrow = 2) base_odds_ratio &lt;- oddsratio.wald(base_odds_table) all_base_odds_ratio[k,] &lt;- base_odds_ratio$measure[2,c(2,1,3)] if(run_extra_covar){ base_group &lt;- rep(1, length(extra_base_pred)) base_group[extra_base_pred &lt; quantile(extra_base_pred, 0.2)] &lt;- 0 base_group[extra_base_pred &gt; quantile(extra_base_pred, cut_off)] &lt;- 2 base_odds_table &lt;- matrix(c(sum(df_test_extra$pheno == 1 &amp; base_group == 2), sum(df_test_extra$pheno == 0 &amp; base_group == 2), sum(df_test_extra$pheno == 1 &amp; base_group == 0), sum(df_test_extra$pheno == 0 &amp; base_group == 0)), nrow = 2) base_odds_ratio &lt;- oddsratio.wald(base_odds_table) all_extra_base_odds_ratio[k,] &lt;- base_odds_ratio$measure[2,c(2,1,3)] } k &lt;- k + 1 } #Make the model score_mod &lt;- glm(as.formula(paste0(&quot;pheno ~&quot;, base_covars, &quot; + score&quot;)), data = df_train, family = &quot;binomial&quot;) score_pred &lt;- predict(score_mod, df_test) # NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW # just here as above we create models similar to the basic score model, although now we need additional covariates # the first if statements will add extra covariates to this mode, the second statement adds the extra scores # This series if statements will come up again several times after each type of statistic is prepared (AUC, OR, PR) # NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW NEW if(run_extra_covar){ extra_score_mod &lt;- glm(as.formula(paste0(&quot;pheno ~ &quot;, base_covars, &quot; + score +&quot;, paste(colnames(extra_covar), collapse = &quot;+&quot;))), data = df_train_extra, family = &quot;binomial&quot;) extra_score_pred &lt;- predict(extra_score_mod, df_test_extra) } if(run_other_scores){ all_other_score_mod &lt;- list() all_other_score_pred &lt;- list() all_other_score_roc &lt;- list() all_other_score_auc &lt;- list() all_other_score_pr &lt;- list() for(k in 1:ncol(other_scores)){ all_other_score_mod[[k]] &lt;- glm(as.formula(paste0(&quot;pheno ~ &quot;, base_covars, &quot; + &quot;, colnames(other_scores)[k])), data = df_train, family = &quot;binomial&quot;) all_other_score_pred[[k]] &lt;- predict(all_other_score_mod[[k]], df_test) } } # AUC ##################################### score_roc &lt;- roc(df_test$pheno ~ score_pred, quiet=T) score_auc &lt;- as.numeric(ci.auc(score_roc)) if(run_extra_covar){ extra_score_roc &lt;- roc(df_test_extra$pheno ~ extra_score_pred, quiet=T) extra_score_auc &lt;- as.numeric(ci.auc(extra_score_roc)) } if(run_other_scores){ for(k in 1:ncol(other_scores)){ all_other_score_roc[[k]] &lt;- roc(df_test$pheno ~ all_other_score_pred[[k]], quiet=T) all_other_score_auc[[k]] &lt;- as.numeric(ci.auc(all_other_score_roc[[k]])) } } # PR ##################################### score_pr &lt;- pr.curve(scores.class0 = score_pred, weights.class0 = df$pheno, curve = T) if(run_extra_covar){ extra_score_pr &lt;- pr.curve(scores.class0 = extra_score_pred, weights.class0 = df_test_extra$pheno, curve = T) } if(run_other_scores){ for(k in 1:ncol(other_scores)){ all_other_score_pr[[k]] &lt;- pr.curve(scores.class0 = all_other_score_pred[[k]], weights.class0 = df_test$pheno, curve = T) } } # ODDS RATIO ############################# all_other_score_odds_ratio &lt;- rep(list(matrix(0, nrow = 6, ncol = 3)), ncol(other_scores)) all_extra_score_odds_ratio &lt;- matrix(0, nrow = 6, ncol = 3) all_score_odds_ratio &lt;- matrix(0, nrow = 6, ncol = 3) k &lt;- 1 for(cut_off in c(0.5, 0.8, 0.9, 0.95, 0.99, 0.995)){ score_group &lt;- rep(1, length(score_pred)) score_group[score_pred &lt; quantile(score_pred, 0.2)] &lt;- 0 score_group[score_pred &gt; quantile(score_pred, cut_off)] &lt;- 2 score_odds_table &lt;- matrix(c(sum(df_test$pheno == 1 &amp; score_group == 2), sum(df_test$pheno == 0 &amp; score_group == 2), sum(df_test$pheno == 1 &amp; score_group == 0), sum(df_test$pheno == 0 &amp; score_group == 0)), nrow = 2) score_odds_ratio &lt;- oddsratio.wald(score_odds_table) all_score_odds_ratio[k,] &lt;- score_odds_ratio$measure[2,c(2,1,3)] if(run_extra_covar){ score_group &lt;- rep(1, length(extra_score_pred)) score_group[extra_score_pred &lt; quantile(extra_score_pred, 0.2)] &lt;- 0 score_group[extra_score_pred &gt; quantile(extra_score_pred, cut_off)] &lt;- 2 score_odds_table &lt;- matrix(c(sum(df_test_extra$pheno == 1 &amp; score_group == 2), sum(df_test_extra$pheno == 0 &amp; score_group == 2), sum(df_test_extra$pheno == 1 &amp; score_group == 0), sum(df_test_extra$pheno == 0 &amp; score_group == 0)), nrow = 2) score_odds_ratio &lt;- oddsratio.wald(score_odds_table) all_extra_score_odds_ratio[k,] &lt;- score_odds_ratio$measure[2,c(2,1,3)] } if(run_other_scores){ for(l in 1:ncol(other_scores)){ score_group &lt;- rep(1, length(all_other_score_pred[[l]])) score_group[all_other_score_pred[[l]] &lt; quantile(all_other_score_pred[[l]], 0.2)] &lt;- 0 score_group[all_other_score_pred[[l]] &gt; quantile(all_other_score_pred[[l]], cut_off)] &lt;- 2 score_odds_table &lt;- matrix(c(sum(df_test$pheno == 1 &amp; score_group == 2), sum(df_test$pheno == 0 &amp; score_group == 2), sum(df_test$pheno == 1 &amp; score_group == 0), sum(df_test$pheno == 0 &amp; score_group == 0)), nrow = 2) score_odds_ratio &lt;- oddsratio.wald(score_odds_table) all_other_score_odds_ratio[[l]][k,] &lt;- score_odds_ratio$measure[2,c(2,1,3)] } } k &lt;- k + 1 } #Get answers together ################################################## #previously also held the base_full_cumhaz but memory gets to be alot all_base_holder &lt;- list(&quot;conc&quot; = base_conc, &quot;survfit&quot; = base_avg_cumhaz, &quot;auc&quot; = list(base_roc, base_auc), &quot;or&quot; = all_base_odds_ratio, &quot;pr&quot; = base_pr) if(run_extra_covar){ all_extra_holder &lt;- list(&quot;base_auc&quot; = list(extra_base_roc, extra_base_auc), &quot;base_pr&quot; = extra_base_pr, &quot;base_or&quot; = all_extra_base_odds_ratio, &quot;auc&quot; = list(extra_score_roc, extra_score_auc), &quot;pr&quot; = extra_score_pr, &quot;or&quot; = all_extra_score_odds_ratio) } else { all_extra_holder &lt;- list(NULL) } if(run_other_scores){ all_other_holder &lt;- list(&quot;auc&quot; = list(all_other_score_roc, all_other_score_auc), &quot;pr&quot; = all_other_score_pr, &quot;or&quot; = all_other_score_odds_ratio) } else { all_other_holder &lt;- list(NULL) } misc_info &lt;- list(&quot;phen_method&quot; = phen_method, &quot;subrate_style&quot; = subrate_style, &quot;train_frac&quot; = train_frac, &quot;score_method&quot; = score_method) final_obj &lt;- list(&quot;conc&quot; = score_conc, &quot;survfit&quot; = score_avg_cumhaz, &quot;auc&quot; = list(score_roc, score_auc), &quot;or&quot; = all_score_odds_ratio, &quot;pr&quot; = score_pr, &quot;base&quot; = all_base_holder, &quot;score_names&quot; = best_score, &quot;misc&quot; = misc_info, &quot;extra&quot; = all_extra_holder, &quot;other&quot; = all_other_holder) saveRDS(final_obj, paste0(&quot;final_stats/&quot;, author, &quot;_res.RDS&quot;)) 9.2 Plotting Once again, the plotting process of testing is very similar to the plotting process of tuning. There are a few notable diffrences however. First, we now need to (possibly) plot added covariates or scores. Second, as we only have one score per disease we can go into greater analytical detail of how the score is working. Since these two differences lead to structurally diffrence code I will briefly break up the larger script and explain what has been done. 9.2.1 Concordance The first plot compared the concordance value of nested cox-proportional hazard models. The smaller model includes age, sex, 10 PCs and the larger model also includes the polygenic risk score. In the effort to keep things simpler, I went super simple and just have two points with error bars. CODE GOES HERE Figure 9.1: Testing comparison of concordance values 9.2.2 Survival Curve Fit The second set of plots attempt to display the full set of fit survival curves. Previously in the tuning section this type of object could have breen created two ways. The first, fast way, by looking at people with average covariates other than the score which is given definite quantiles; the second, slow way, fits every single person individually and the averages together the survival curves for groups of people that fall in different polygenic risk score quantiles. To make things more accurate we now only use the slower method, and instead of just showing the final time point of the fit curves we show the full curve (along with the end time point). Specifically, the first two plots show these averaged curves for different polygenic risk score quantiles, the first with a standard error cone and the second comparing the base and score model generated curves. The final plot compared the base and score models at the final timepoint. CODE GOES HERE Figure 9.2: Kaplain-Meier style curve stratified by polygenic risk score quantiles Figure 9.3: Kaplan-Meier style curves comparing groups stratified by polygenic risk score with two predictions, one that includes the score and one that does not, for each group Figure 9.4: The estimed risk for the final time point in the previous plot, including confidence intervals 9.2.3 ROC and AUC The plots derived from the ROC curve are very similar to concordance. The only difference is the addition of a plot that shows the ROC curves, comparing the score and base models. CODE GOES HERE Figure 9.5: Comparison of the base and polygenic risk score included models through their ROC curves Figure 9.6: Comparison of the AUC values and their confidence intervals of the previous two ROC curves 9.2.4 Odds Ratios In the same theme as the last few plots the single odds ratio plot compares the odds ratio from both the score and base models. This plot differs from the tuning as it includes multiple cut-off values, or points in which the respective model risk probability was cut to create an “exposed” and “non-exposed” group. CODE GOES HERE Figure 9.7: Comparison of odds ratios between the base and polygenic risk score included models 9.2.5 PR Curves The plot for the PR Curves are completely novel relative to the tuning plots. However, the actual form of the plots is highly similar to the ROC plots, in the fact it compares the score and base model through curves. In this plot specifically the area under the PR curves is included as a caption. CODE GOES HERE Figure 9.8: Comparison of the PR curves, and the area there under, between the base and polygenic risk score included models 9.2.6 Other Scores While I have tried very hard to make the polygenic risk score so far analyzed to be the best polygenic risk score possible, there were countless decisions I have made in this process that could have been made differently by other researchers. To determine whether or not those other decisions would have been better I have downloaded the polygenic risk scores from PGS Catalog, analyzed them then plotted just the AUC comparison. I figure showing the other statistics would be largely redundant. The simple plot is: CODE GOES HERE Figure 9.9: Comparison of the internal polygenic risk score analyzed so far and an externally prepared score (by other researchers) 9.2.7 Extra Covariates Even though I have computed the effect of extra covariates within a model and their impact on odds ratio and PR, I have elected to only plot their effect on AUC. The thinkning is that the effect of the extra covariates will likely be the same across statistics so this is just a neater way. For my single AUC plot I am producing a figure that is very similar to the previous AUC plot although now there are colors to denote whether the model includes the extra covariates on top of the base covariates. CODE GOES HERE Figure 9.10: Comparison of the base model with and without the polygenic risk score, and with and without additional possible risk factors 9.2.8 Saving The very last part of this process is saving all of the plots. Similar to tuning I leave the option to specify which plots one wants to save, but since we have already greatly reduced the number of plots under analysis saving everything does not seem like that large of a burden (and therefore saving everything is the default option). CODE GOES HERE "],["additional-testing-statistics.html", "10 Additional Testing Statistics 10.1 Calculating the Statistics 10.2 Making the Plots", " 10 Additional Testing Statistics Soon after carrying out the framework for polygenic risk score analyses reported in the previous section I realized that far more statistics exist that can be computed. Even better, these statistics are often far more interpretable by a clinical audience, the audience that matters. I therefore set about writing code that simply computed all of these additional statistics and later on plotting them in a clear way. I will pull out the relavent code for each statistic and describe why it is being computed. At the end I will include the full code (each of the statistical computations are intertwined into the base and score and extra covariate modelling). 10.1 Calculating the Statistics 10.1.1 Brier Score The Brier Score measures the accuracy of probabilistic predictions in a similar way as root mean squared error measured the accuracy of a linear model fit. Specifically, the Brier score is the sum of squared difference between the forecast and observed measure divided by all of the forecasting instances. Wikipedia provides a few examples: If the forecast is 70% (P = 0.70) and it rains, then the Brier Score is (0.70−1)2 = 0.09. In contrast, if the forecast is 70% (P = 0.70) and it does not rain, then the Brier Score is (0.70−0)2 = 0.49. Similarly, if the forecast is 30% (P = 0.30) and it rains, then the Brier Score is (0.30−1)2 = 0.49. This seems like a nice and proper way to evaulate a model, and with the underlying motivation of the project is the construction of an extremely comprehensive analysis I included the Brier score. The computation was done library(DescTools) base_brier &lt;- BrierScore(base_mod) 10.1.2 Reclassification Statistics (NRI and IDI) The reclassification based statistics come from a 2007 publication by Pencina et al., specifically the net reclassification index (NRI) is defined as “The improvement in reclassification can be quantified as a sum of differences in proportions of individuals moving up minus the proportion moving down for people who develop events, and the proportion of individuals moving down minus the proportion moving up for people who do not develop events. We call this sum the NRI.” While this statistic seems very intuitive it is in fact very difficult to interpret. There are two fractions with different denominators, and therefore the NRI is not simply the proportion of individuals who become better classified with the addition of a new statistic. The other statistic is the integrated discrimination improvement, which makes things even more complicated mathematically speaking. The statistic is comparable to NRI although no cut-off need be defined. This is later extended and refined as a continous NRI or NRI(&gt;0). Many critiques of NRI and IDI have been raised, which have led to even more statistic re-workings. I have stuck with this original definition, which may be biased but is as simple and interpretable as I can get it. Although, the only working interpretation I can raise is to determine whether or not the NRI is significantly greater than 0. The magnitude of the value itself is confusing and the idea behind it can be better measured by other statistics. The process of computing the NRI and IDI involves the reclassification function, which does not return the NRI and IDI exactly, but rather a print-out. While there is likely a more sophisticated way to do this, I wrote the print-out to a file, then spliced out the values I wanted and read them back in as the NRI and IDI. Since the NRI is defined based on a specific reclassification against a cut-off, a few different cut-offs were used, following the same pattern as in the odds ratio calculations. The full code is. library(PredictABEL) reclass_func &lt;- function(data, base_mod, new_mod, quant){ sink(&quot;sink-examp.txt&quot;) reclassification(data=data, cOutcome=1, predrisk1=predRisk(base_mod, data = data), predrisk=predRisk(new_mod, data = data), c(0,quantile(summary(predRisk(base_mod, data = data)), quant),1)) sink() system(&quot;cat sink-examp.txt | fgrep Cate | cut -f5,7,9 -d&#39; &#39; &gt; NRI_est&quot;) system(&quot;cat sink-examp.txt | fgrep IDI | cut -f5,7,9 -d&#39; &#39; &gt; IDI_est&quot;) nri &lt;- read.table(&quot;NRI_est&quot;) idi &lt;- read.table(&quot;IDI_est&quot;) return(data.frame(nri, idi)) } all_score_reclass &lt;- list() for(cut_off in c(0.5, 0.8, 0.9, 0.95, 0.99, 0.995)){ score_group &lt;- rep(1, length(score_pred)) score_group[score_pred &lt; quantile(score_pred, 0.2)] &lt;- 0 score_group[score_pred &gt; quantile(score_pred, cut_off)] &lt;- 2 base_group &lt;- rep(1, length(base_pred)) base_group[base_pred &lt; quantile(base_pred, 0.2)] &lt;- 0 base_group[base_pred &gt; quantile(base_pred, cut_off)] &lt;- 2 all_score_reclass[[k]] &lt;- reclass_func(df_test, base_mod, score_mod, cut_off) } 10.1.3 True and False Positive Rates After making two sophisticated statistics that seem really useful but in reality are difficult to interpret I followed the advice of a few papers and decided to just analyze the true and false positive rates directly. The reason I did not do this directly before however is that there are thousands of possible true and false positive rates as any threshold can be used. To simplify things I decided to use the cut-offs that have been used for the odds ratios before. When using these cut-offs I did not keep the false positive rate, perhaps a bad omission but I think it simplifies things to just focus on the true positives. In addition to the preset cut-offs I wanted a threshold that would best suit each individual disease. The threshold that maximized 1 - TPR - FPR has been hypothesized as optimal, and it was therefore chosen. In this second TPR and FPR selection process I pulled the values from the ROC curve. The exact code for this process is: roc_df &lt;- data.frame(&quot;fpr&quot; = rev(1 - roc_obj$specificities), &quot;tpr&quot; = rev(roc_obj$sensitivities)) score_rates &lt;- roc_df[which.min(abs(1 - rowSums(roc_df))),] all_score_pred &lt;- list() for(cut_off in c(0.5, 0.8, 0.9, 0.95, 0.99, 0.995)){ score_group &lt;- rep(1, length(score_pred)) score_group[score_pred &lt; quantile(score_pred, 0.2)] &lt;- 0 score_group[score_pred &gt; quantile(score_pred, cut_off)] &lt;- 2 base_group &lt;- rep(1, length(base_pred)) base_group[base_pred &lt; quantile(base_pred, 0.2)] &lt;- 0 base_group[base_pred &gt; quantile(base_pred, cut_off)] &lt;- 2 all_score_preds[[k]] &lt;- c(sum(df_test$pheno == 1 &amp; score_group == 2), sum(score_group == 2)) } 10.1.4 Reclassification Values Along with the true and false positive rate recommendations from the papers that critique NRI, we went with a somewhat additional obvious computation of the reclassification numbers. Following the exact same cut-offs of the odds ratios, we gathered the IDs of the individuals that are originally in the high-risk group under the base model, and the IDs of the individuals that are in the high-risk group under the score model. The total number of people in this group minus the intersection between these two groups is the number reclassified. The exact code for this is: all_score_preds &lt;- list() all_score_reclass &lt;- list() all_score_in_out &lt;- matrix(0, nrow = 6, ncol = 3) k &lt;- 1 for(cut_off in c(0.5, 0.8, 0.9, 0.95, 0.99, 0.995)){ score_group &lt;- rep(1, length(score_pred)) score_group[score_pred &lt; quantile(score_pred, 0.2)] &lt;- 0 score_group[score_pred &gt; quantile(score_pred, cut_off)] &lt;- 2 base_group &lt;- rep(1, length(base_pred)) base_group[base_pred &lt; quantile(base_pred, 0.2)] &lt;- 0 base_group[base_pred &gt; quantile(base_pred, cut_off)] &lt;- 2 all_score_in_out[k,1] &lt;- length(intersect(which(score_group == 2), which(base_group == 2))) all_score_in_out[k,2] &lt;- sum(score_group == 2) all_score_in_out[k,3] &lt;- all_score_in_out[k,2] - all_score_in_out[k,3] } 10.1.5 Decision Curve Analyses Lastly, analyses that are still highly interpretable but gain a sense of sophistication were sought. Decision curve analyses were found. The curve is composed of net benitis calculated at various thresholds as the true positive rate minus the false positive rate times a penalty that corresponds to the original threshold. the net benfits are similar to financial profits, and therefore form a means to provide convincing proof that one decision methedology is better than another. A nice package was used to encapsulate all of the decision curve computations, and the code is shown below. library(rmda) dc_df &lt;- data.frame(&quot;pheno&quot; = df_test$pheno, &quot;pred&quot; = base_pred) base_dc &lt;- decision_curve(pheno ~ pred, data = dc_df, study.design = &quot;cohort&quot;, policy = &quot;opt-in&quot;) 10.2 Making the Plots Lastly, plots are made for each of the statistics. Just as was done in the tuning and testing sections, plots for each disease were first done in a loop, then overall plots were created that span across all diseases. There is not a significant amount to say about this plotting process. Once again I followed my plotting philosiphy of keeping things as clean and simple as possible. For the decision curve analyses I did a bit of a deeper dive into when one curve is greater than another, but for all of the other plots the direct statistic was plot alone. As there is not a great deal to say I will include a few examples of the plots and then the extended code that follows, without intervening notes, for completness. Figure 10.1: Example plot of the NRI Figure 10.2: Example plot of the True Positive Rates Figure 10.3: Example plot of the Reclassifications Figure 10.4: Example plot of the Decision Curve And now the code: library(stringr) library(ggplot2) library(cowplot) library(pROC) library(reshape2) library(rmda) theme_set(theme_cowplot()) convert_names &lt;- function(x, the_dict = method_dict){ y &lt;- rep(NA, length(x)) for(i in 1:length(x)){ if(x[i] %in% the_dict[,1]){ y[i] &lt;- the_dict[the_dict[,1] == x[i], 2] } } return(y) } method_names &lt;- read.table(&quot;local_info/method_names&quot;, stringsAsFactors = F) disease_names &lt;- read.table(&quot;local_info/disease_names&quot;, stringsAsFactors = F, sep = &quot;\\t&quot;) all_authors &lt;- unique(str_split(list.files(&quot;test_results/&quot;, &quot;class_data&quot;), &quot;_&quot;, simplify = T)[,1]) if(any(all_authors == &quot;Xie&quot;)){ all_authors &lt;- all_authors[-which(all_authors == &quot;Xie&quot;)] } #in or out full_count_in_out &lt;- list() full_pro_in_out &lt;- list() extra_full_count_in_out &lt;- list() extra_pro_in_out &lt;- list() #brier brier_normal &lt;- list() brier_extra &lt;- list() #reclass reclass_normal &lt;- list() reclass_extra &lt;- list() #rates rates_normal &lt;- list() rates_extra &lt;- list() #true positive tp_normal &lt;- list() tp_extra &lt;- list() #decision curves dc_best_normal &lt;- list() dc_normal &lt;- list() dc_best_extra &lt;- list() dc_extra &lt;- list() dc_range_normal &lt;- list() dc_range_extra &lt;- list() for(author in all_authors){ print(author) res &lt;- readRDS(paste0(&quot;test_results/&quot;, author, &quot;_class_data.RDS&quot;)) ################################################################################################ # IN OR OUT #### ################################################################################################# plot_labels &lt;- c(&quot;Number of Individuals&quot;, &quot;Proportion of Individuals&quot;) for(opt in c(&quot;full&quot;, &quot;pro&quot;)){ #In or Out #################################################### risky_df &lt;- data.frame(res[[&quot;score&quot;]][[&quot;in_out&quot;]]) risky_df[,3] &lt;- risky_df[,2] - risky_df[,1] colnames(risky_df) &lt;- c(&quot;intersect&quot;, &quot;total&quot;, &quot;diff&quot;) if(opt == &quot;pro&quot;){ risky_df$intersect &lt;- risky_df$intersect/risky_df$total risky_df$diff &lt;- risky_df$diff/risky_df$total } risky_df$cut_off &lt;- as.factor(c(0.5, 0.8, 0.9, 0.95, 0.99, 0.995)) if(opt == &quot;full&quot;){ full_count_in_out[[which(all_authors == author)]] &lt;- risky_df[4,] full_count_in_out[[which(all_authors == author)]]$author &lt;- author } else { full_pro_in_out[[which(all_authors == author)]] &lt;- risky_df[4,] full_pro_in_out[[which(all_authors == author)]]$author &lt;- author } risky_df &lt;- melt(risky_df[,-2], id.vars = &quot;cut_off&quot;) risky_df$type &lt;- &quot;normal&quot; if(!is.null(res[[&quot;extra&quot;]][[1]])){ print(&quot;extra extra&quot;) extra_risky_df &lt;- data.frame(res[[&quot;extra&quot;]][[&quot;score&quot;]][[&quot;in_out&quot;]]) extra_risky_df[,3] &lt;- extra_risky_df[,2] - extra_risky_df[,1] colnames(extra_risky_df) &lt;- c(&quot;intersect&quot;, &quot;total&quot;, &quot;diff&quot;) if(opt == &quot;pro&quot;){ extra_risky_df$intersect &lt;- extra_risky_df$intersect/extra_risky_df$total extra_risky_df$diff &lt;- extra_risky_df$diff/extra_risky_df$total } extra_risky_df$cut_off &lt;- as.factor(c(0.5, 0.8, 0.9, 0.95, 0.99, 0.995)) if(opt == &quot;full&quot;){ extra_full_count_in_out[[which(all_authors == author)]] &lt;- extra_risky_df[4,] extra_full_count_in_out[[which(all_authors == author)]]$author &lt;- author } else { extra_pro_in_out[[which(all_authors == author)]] &lt;- extra_risky_df[4,] extra_pro_in_out[[which(all_authors == author)]]$author &lt;- author } extra_risky_df &lt;- melt(extra_risky_df[,-2], id.vars = &quot;cut_off&quot;) extra_risky_df$type &lt;- &quot;extra&quot; plot_df &lt;- rbind(extra_risky_df, risky_df) the_plot &lt;- ggplot(plot_df, aes(type, value, fill = variable)) + geom_bar(stat=&quot;identity&quot;) + facet_grid( ~ cut_off) + labs(x = &quot;Covariate Type&quot;, y = plot_labels[which(c(&quot;full&quot;, &quot;pro&quot;) == opt)], fill = &quot;Source Model&quot;) + scale_fill_discrete(labels = c(&quot;Orig. Base&quot;, &quot;Score Added&quot;)) + theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) ggsave(paste0(&quot;addon_test_plots/&quot;, tolower(author), &quot;.&quot;, opt, &quot;.in_out.png&quot;), the_plot, &quot;png&quot;, height=6, width=7) } else { the_plot &lt;- ggplot(risky_df, aes(cut_off, value, fill = variable)) + geom_bar(stat = &quot;identity&quot;) + labs(x = &quot;Cut Off&quot;, y = plot_labels[which(c(&quot;full&quot;, &quot;pro&quot;) == opt)], fill = &quot;Source Model&quot;) + scale_fill_discrete(labels = c(&quot;Orig. Base&quot;, &quot;Score Added&quot;)) plot(the_plot) ggsave(paste0(&quot;addon_test_plots/&quot;, tolower(author), &quot;.&quot;, opt, &quot;.in_out.png&quot;), the_plot, &quot;png&quot;, height=6, width=7) } } ################################################################################################ # BRIER #### ################################################################################################# brier_normal[[which(all_authors == author)]] &lt;- c(res[[&quot;base&quot;]][[&quot;brier&quot;]], res[[&quot;score&quot;]][[&quot;brier&quot;]]) if(!is.null(res[[&quot;extra&quot;]][[1]])){ brier_extra[[which(all_authors == author)]] &lt;- c(res[[&quot;extra&quot;]][[&quot;base&quot;]][[&quot;brier&quot;]], res[[&quot;extra&quot;]][[&quot;score&quot;]][[&quot;brier&quot;]]) } else { brier_extra[[which(all_authors == author)]] &lt;- c(NA, NA) } ################################################################################################ # RECLASS #### ################################################################################################# #nri, idi reclass_df &lt;- do.call(&quot;rbind&quot;, res[[&quot;score&quot;]][[&quot;reclass&quot;]]) colnames(reclass_df) &lt;- c(&quot;nri_est&quot;, &quot;nri_lo&quot;, &quot;nri_hi&quot;, &quot;idi_est&quot;, &quot;idi_lo&quot;, &quot;idi_hi&quot;) reclass_df$cut_off &lt;- as.factor(c(0.5, 0.8, 0.9, 0.95, 0.99, 0.995)) reclass_normal[[which(all_authors == author)]] &lt;- reclass_df reclass_normal[[which(all_authors == author)]]$disease &lt;- convert_names(author, disease_names) reclass_df$stat &lt;- &quot;None&quot; temp_df &lt;- reclass_df if(!is.null(res[[&quot;extra&quot;]][[1]])){ reclass_df &lt;- do.call(&quot;rbind&quot;, res[[&quot;extra&quot;]][[&quot;score&quot;]][[&quot;reclass&quot;]]) colnames(reclass_df) &lt;- c(&quot;nri_est&quot;, &quot;nri_lo&quot;, &quot;nri_hi&quot;, &quot;idi_est&quot;, &quot;idi_lo&quot;, &quot;idi_hi&quot;) reclass_df$cut_off &lt;- as.factor(c(0.5, 0.8, 0.9, 0.95, 0.99, 0.995)) reclass_extra[[which(all_authors == author)]] &lt;- reclass_df reclass_extra[[which(all_authors == author)]]$disease &lt;- convert_names(author, disease_names) reclass_df$stat &lt;- &quot;Extra&quot; reclass_df &lt;- rbind(reclass_df, temp_df) the_plot &lt;- ggplot(reclass_df, aes(nri_est, cut_off, color = stat)) + geom_point() + geom_errorbar(aes(xmin = nri_lo, xmax = nri_hi, width = 0)) + labs(x = &quot;Net Reclassification Improvement&quot;, y = &quot;Cut Off&quot;, color = &quot;Covars&quot;) plot(the_plot) ggsave(paste0(&quot;addon_test_plots/&quot;, tolower(author), &quot;.nri.reclass.png&quot;), the_plot, &quot;png&quot;, height=5, width=5) the_plot &lt;- ggplot(reclass_df, aes(idi_est, cut_off, color = stat)) + geom_point() + geom_errorbar(aes(xmin = idi_lo, xmax = idi_hi, width = 0)) + labs(x = &quot;Integrated Discrimination Improvement&quot;, y = &quot;Cut Off&quot;, color = &quot;Covars&quot;) plot(the_plot) ggsave(paste0(&quot;addon_test_plots/&quot;, tolower(author), &quot;.idi.reclass.png&quot;), the_plot, &quot;png&quot;, height=5, width=5) } else { reclass_extra[[which(all_authors == author)]] &lt;- NULL the_plot &lt;- ggplot(reclass_df, aes(nri_est, cut_off)) + geom_point() + geom_errorbar(aes(xmin = nri_lo, xmax = nri_hi, width = 0)) + labs(x = &quot;Net Reclassification Improvement&quot;, y = &quot;Cut Off&quot;) plot(the_plot) ggsave(paste0(&quot;addon_test_plots/&quot;, tolower(author), &quot;.nri.reclass.png&quot;), the_plot, &quot;png&quot;, height=5, width=5) the_plot &lt;- ggplot(reclass_df, aes(idi_est, cut_off)) + geom_point() + geom_errorbar(aes(xmin = idi_lo, xmax = idi_hi, width = 0)) + labs(x = &quot;Integrated Discrimination Improvement&quot;, y = &quot;Cut Off&quot;) plot(the_plot) ggsave(paste0(&quot;addon_test_plots/&quot;, tolower(author), &quot;.idi.reclass.png&quot;), the_plot, &quot;png&quot;, height=5, width=5) } ################################################################################################ # TPR FPR RATES #### ################################################################################################# rate_df &lt;- rbind(res[[&quot;score&quot;]][[&quot;rates&quot;]], res[[&quot;base&quot;]][[&quot;rates&quot;]], res[[&quot;score&quot;]][[&quot;rates&quot;]] - res[[&quot;base&quot;]][[&quot;rates&quot;]]) rate_df$type &lt;- c(&quot;score&quot;, &quot;base&quot;, &quot;diff&quot;) rate_df$disease &lt;- convert_names(author, disease_names) rates_normal[[which(all_authors == author)]] &lt;- rate_df if(!is.null(res[[&quot;extra&quot;]][[1]])){ extra_rate_df &lt;- rbind(res[[&quot;extra&quot;]][[&quot;score&quot;]][[&quot;rates&quot;]], res[[&quot;extra&quot;]][[&quot;base&quot;]][[&quot;rates&quot;]], res[[&quot;extra&quot;]][[&quot;score&quot;]][[&quot;rates&quot;]] - res[[&quot;extra&quot;]][[&quot;base&quot;]][[&quot;rates&quot;]]) extra_rate_df$type &lt;- c(&quot;score&quot;, &quot;base&quot;, &quot;diff&quot;) extra_rate_df$disease &lt;- convert_names(author, disease_names) rates_extra[[which(all_authors == author)]] &lt;- extra_rate_df } else { rates_extra[[which(all_authors == author)]] &lt;- NULL } ################################################################################################ # TRUE POSITIVES #### ################################################################################################# tp_df &lt;- as.data.frame(do.call(&quot;rbind&quot;, res[[&quot;score&quot;]][[&quot;preds&quot;]])) colnames(tp_df) &lt;- c(&quot;score_tp&quot;, &quot;total&quot;) tp_df$score_rate &lt;- tp_df$score_tp/tp_df$total tp_df$base_tp &lt;- do.call(&quot;rbind&quot;, res[[&quot;base&quot;]][[&quot;preds&quot;]])[,1] tp_df$base_rate &lt;- tp_df$base_tp/tp_df$total tp_df$cut_off &lt;- as.factor(c(0.5, 0.8, 0.9, 0.95, 0.99, 0.995)) tp_df$disease &lt;- convert_names(author, disease_names) plot_df &lt;- data.frame(&quot;rate&quot; = c(tp_df$score_rate, tp_df$base_rate, tp_df$score_rate - tp_df$base_rate), &quot;count&quot; = c(tp_df$score_tp, tp_df$base_tp, tp_df$score_tp - tp_df$base_tp), &quot;type&quot; = c(rep(&quot;Score&quot;, nrow(tp_df)), rep(&quot;Base&quot;, nrow(tp_df)), rep(&quot;diff&quot;, nrow(tp_df))), &quot;cut_off&quot; = rep(tp_df$cut_off, 3), &quot;disease&quot; = c(tp_df$disease, tp_df$disease, tp_df$disease)) temp_df &lt;- plot_df tp_normal[[which(all_authors == author)]] &lt;- plot_df if(!is.null(res[[&quot;extra&quot;]][[1]])){ extra_tp_df &lt;- as.data.frame(do.call(&quot;rbind&quot;, res[[&quot;extra&quot;]][[&quot;score&quot;]][[&quot;preds&quot;]])) colnames(extra_tp_df) &lt;- c(&quot;score_tp&quot;, &quot;total&quot;) extra_tp_df$score_rate &lt;- extra_tp_df$score_tp/extra_tp_df$total extra_tp_df$base_tp &lt;- do.call(&quot;rbind&quot;, res[[&quot;extra&quot;]][[&quot;base&quot;]][[&quot;preds&quot;]])[,1] extra_tp_df$base_rate &lt;- extra_tp_df$base_tp/extra_tp_df$total extra_tp_df$cut_off &lt;- as.factor(c(0.5, 0.8, 0.9, 0.95, 0.99, 0.995)) extra_tp_df$disease &lt;- convert_names(author, disease_names) plot_df &lt;- data.frame(&quot;rate&quot; = c(extra_tp_df$score_rate, extra_tp_df$base_rate, extra_tp_df$score_rate - extra_tp_df$base_rate), &quot;count&quot; = c(extra_tp_df$score_tp, extra_tp_df$base_tp, extra_tp_df$score_tp - extra_tp_df$base_tp), &quot;type&quot; = c(rep(&quot;Score&quot;, nrow(extra_tp_df)), rep(&quot;Base&quot;, nrow(extra_tp_df)), rep(&quot;diff&quot;, nrow(extra_tp_df))), &quot;cut_off&quot; = rep(extra_tp_df$cut_off, 3), &quot;disease&quot; = c(extra_tp_df$disease, extra_tp_df$disease, extra_tp_df$disease)) tp_extra[[which(all_authors == author)]] &lt;- plot_df plot_df$ex &lt;- &quot;Extra&quot; temp_df$ex &lt;- &quot;None&quot; plot_df &lt;- rbind(plot_df, temp_df) the_plot &lt;- ggplot(plot_df[plot_df$type != &quot;diff&quot;,], aes(cut_off, rate, color = type)) + geom_point() + labs(x = &quot;Cut Off&quot;, y = &quot;True Positive Rate&quot;, color = &quot;Model&quot;) + facet_grid(cols = vars(ex)) plot(the_plot) ggsave(paste0(&quot;addon_test_plots/&quot;, tolower(author), &quot;.true_pos.png&quot;), the_plot, &quot;png&quot;, height=5, width=7) } else { tp_extra[[which(all_authors == author)]] &lt;- NULL the_plot &lt;- ggplot(plot_df[plot_df$type != &quot;diff&quot;,], aes(cut_off, rate, color = type)) + geom_point() + labs(x = &quot;Cut Off&quot;, y = &quot;True Positive Rate&quot;, color = &quot;Model&quot;) plot(the_plot) ggsave(paste0(&quot;addon_test_plots/&quot;, tolower(author), &quot;.true_pos.png&quot;), the_plot, &quot;png&quot;, height=5, width=6) } ################################################################################################ # DECISION CURVE #### ################################################################################################# #plot_decision_curve(list(res[[&quot;score&quot;]][[&quot;dc&quot;]], res[[&quot;base&quot;]][[&quot;dc&quot;]]), curve.names = c(&quot;score&quot;, &quot;base&quot;)) best_ind &lt;- which.max(res[[&quot;score&quot;]][[&quot;dc&quot;]]$derived.data$sNB - res[[&quot;base&quot;]][[&quot;dc&quot;]]$derived.data$sNB) get_dc_df &lt;- function(subres, the_ind){ best_vals &lt;- data.frame(t(c(subres[[&quot;base&quot;]][[&quot;dc&quot;]]$derived.data$sNB[the_ind], subres[[&quot;score&quot;]][[&quot;dc&quot;]]$derived.data$sNB[the_ind]))) colnames(best_vals) &lt;- c(&quot;base&quot;, &quot;score&quot;) best_vals$diff &lt;- best_vals[1,2] - best_vals[1,1] best_vals$thresh &lt;- subres[[&quot;score&quot;]][[&quot;dc&quot;]]$derived.data$thresholds[the_ind] best_vals$cb_ratio &lt;- subres[[&quot;score&quot;]][[&quot;dc&quot;]]$derived.data$thresholds[the_ind] best_vals$just_nb &lt;- subres[[&quot;score&quot;]][[&quot;dc&quot;]]$derived.data$NB[the_ind] return(best_vals) } get_dc_range &lt;- function(subres){ bool &lt;- (subres[[&quot;score&quot;]][[&quot;dc&quot;]]$derived.data$sNB - subres[[&quot;base&quot;]][[&quot;dc&quot;]]$derived.data$sNB) &gt; 0.001 bool[is.na(bool)] &lt;- FALSE better_range &lt;- subres[[&quot;score&quot;]][[&quot;dc&quot;]]$derived.data$thresholds[bool] return(c(min(better_range), max(better_range))) } dc_range_normal[[which(all_authors == author)]] &lt;- get_dc_range(res) dc_best_normal[[which(all_authors == author)]] &lt;- get_dc_df(res, best_ind) dc_normal[[which(all_authors == author)]] &lt;- rbind(get_dc_df(res, 2), get_dc_df(res, 6), get_dc_df(res, 13)) png(paste0(&quot;addon_test_plots/&quot;, tolower(author), &quot;.decision_curve.none.png&quot;), width = 580, height = 480) plot_decision_curve(list(res[[&quot;score&quot;]][[&quot;dc&quot;]], res[[&quot;base&quot;]][[&quot;dc&quot;]]), curve.names = c(&quot;Score&quot;, &quot;Base&quot;), xlim = c(0,0.3), confidence.intervals = F) dev.off() if(!is.null(res[[&quot;extra&quot;]][[1]])){ dc_range_extra[[which(all_authors == author)]] &lt;- get_dc_range(res[[&quot;extra&quot;]]) best_ind &lt;- which.max(res[[&quot;extra&quot;]][[&quot;score&quot;]][[&quot;dc&quot;]]$derived.data$sNB - res[[&quot;extra&quot;]][[&quot;base&quot;]][[&quot;dc&quot;]]$derived.data$sNB) dc_best_extra[[which(all_authors == author)]] &lt;- get_dc_df(res[[&quot;extra&quot;]], best_ind) dc_extra[[which(all_authors == author)]] &lt;- rbind(get_dc_df(res[[&quot;extra&quot;]], 2), get_dc_df(res[[&quot;extra&quot;]], 6), get_dc_df(res[[&quot;extra&quot;]], 13)) png(paste0(&quot;addon_test_plots/&quot;, tolower(author), &quot;.decision_curve.extra.png&quot;), width = 580, height = 480) plot_decision_curve(list(res[[&quot;extra&quot;]][[&quot;score&quot;]][[&quot;dc&quot;]], res[[&quot;extra&quot;]][[&quot;base&quot;]][[&quot;dc&quot;]]), curve.names = c(&quot;score&quot;, &quot;base&quot;), xlim = c(0,0.3), confidence.intervals = F) dev.off() } else { dc_best_extra[[which(all_authors == author)]] &lt;- NULL dc_extra[[which(all_authors == author)]] &lt;- NULL } } #$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$ ################################################################################################ # OVERALL OVERALL OVERALL #### ################################################################################################# #$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$ ################################################################################################ # IN OR OUT #### ################################################################################################# for(i in 1:length(all_authors)){ if(is.null(extra_full_count_in_out[[i]])){ extra_full_count_in_out[[i]] &lt;- full_count_in_out[[i]] extra_pro_in_out[[i]] &lt;- full_pro_in_out[[i]] } } plot_overall_in_out &lt;- function(count_list, pro_list, covar_type, write_supp = FALSE){ count_plot_df &lt;- do.call(&quot;rbind&quot;, count_list) for_supp &lt;- data.frame(count_plot_df) for_supp$disease &lt;- convert_names(for_supp$author, disease_names) plot_df &lt;- melt(count_plot_df, id.vars = c(&quot;author&quot;, &quot;cut_off&quot;)) plot_df$disease &lt;- convert_names(plot_df$author, disease_names) plot_df$disease &lt;- factor(plot_df$disease, levels = plot_df$disease[plot_df$variable == &quot;diff&quot;][order(plot_df$value[plot_df$variable == &quot;diff&quot;])]) the_plot &lt;- ggplot(plot_df[plot_df$variable != &quot;total&quot;,], aes(value, disease, fill = variable)) + geom_bar(stat = &quot;identity&quot;) + labs(x = &quot;Number of Individuals&quot;, y = &quot;&quot;, fill = &quot;Source Model&quot;) + scale_fill_discrete(labels = c(&quot;Orig. Base&quot;, &quot;Score Added&quot;)) plot(the_plot) ggsave(paste0(&quot;addon_test_plots/meta/in_out.count.&quot;, covar_type, &quot;.png&quot;), the_plot, &quot;png&quot;, height=6, width=7) if(write_supp){ plot_df &lt;- plot_df[plot_df$variable != &quot;total&quot;,c(5, 3, 4)] plot_df$diff &lt;- plot_df$value[plot_df$variable == &quot;diff&quot;] plot_df &lt;- plot_df[plot_df$variable != &quot;diff&quot;,] colnames(plot_df) &lt;- c(&quot;Disease&quot;, &quot;x&quot;, &quot;Orig. Base&quot;, &quot;Score Added&quot;) write.table(plot_df[,-2], paste0(&quot;supp_tables/count.&quot;, covar_type, &quot;.inout.txt&quot;), row.names = F, col.names = T, sep = &quot;\\t&quot;, quote = F) } pro_plot_df &lt;- do.call(&quot;rbind&quot;, pro_list) for_supp &lt;- data.frame(&quot;disease&quot; = for_supp$disease, &quot;count_new&quot; = for_supp$diff, &quot;count_intersect&quot; = for_supp$intersect, &quot;pro_new&quot; = pro_plot_df$diff, &quot;pro_count&quot; = pro_plot_df$intersect) write.table(for_supp, &quot;supp_tables/in_out_all.txt&quot;, row.names = F, col.names = T, sep = &quot;\\t&quot;, quote = F) plot_df &lt;- melt(pro_plot_df, id.vars = c(&quot;author&quot;, &quot;cut_off&quot;)) plot_df$disease &lt;- convert_names(plot_df$author, disease_names) plot_df$disease &lt;- factor(plot_df$disease, levels = plot_df$disease[plot_df$variable == &quot;diff&quot;][ order(plot_df$value[plot_df$variable == &quot;diff&quot;])]) the_plot &lt;- ggplot(plot_df[plot_df$variable != &quot;total&quot;,], aes(value, disease, fill = variable)) + geom_bar(stat = &quot;identity&quot;) + labs(x = &quot;Proportion of Individuals&quot;, y = &quot;&quot;, fill = &quot;Source Model&quot;) + scale_fill_discrete(labels = c(&quot;Orig. Base&quot;, &quot;Score Added&quot;)) plot(the_plot) ggsave(paste0(&quot;addon_test_plots/meta/in_out.pro.&quot;, covar_type, &quot;.png&quot;), the_plot, &quot;png&quot;, height=6, width=7) if(write_supp){ plot_df &lt;- plot_df[plot_df$variable != &quot;total&quot;,c(5, 3, 4)] plot_df$diff &lt;- plot_df$value[plot_df$variable == &quot;diff&quot;] plot_df &lt;- plot_df[plot_df$variable != &quot;diff&quot;,] colnames(plot_df) &lt;- c(&quot;Disease&quot;, &quot;x&quot;, &quot;Orig. Base&quot;, &quot;Score Added&quot;) write.table(plot_df[,-2], paste0(&quot;supp_tables/pro.&quot;, covar_type, &quot;.inout.txt&quot;), row.names = F, col.names = T, sep = &quot;\\t&quot;, quote = F) } } plot_overall_in_out(full_count_in_out, full_pro_in_out, &quot;norm&quot;, TRUE) plot_overall_in_out(extra_full_count_in_out, extra_pro_in_out, &quot;extra&quot;) #********************************************************************************* ############################## FIGURE PLOT ######################################## #********************************************************************************** pro_plot_df &lt;- do.call(&quot;rbind&quot;, full_pro_in_out) spec_author &lt;- read.table(&quot;spec_authors&quot;, stringsAsFactors = F) tp_df &lt;- do.call(&quot;rbind&quot;, tp_normal) tp_df &lt;- tp_df[tp_df$cut_off == 0.95,] tp_df &lt;- tp_df[tp_df$type != &quot;diff&quot;,] plot_df &lt;- melt(pro_plot_df, id.vars = c(&quot;author&quot;, &quot;cut_off&quot;)) plot_df$disease &lt;- convert_names(plot_df$author, disease_names) plot_df$disease &lt;- factor(plot_df$disease, levels = plot_df$disease[plot_df$variable == &quot;diff&quot;][ order(plot_df$value[plot_df$variable == &quot;diff&quot;])]) the_plot &lt;- ggplot(plot_df[plot_df$variable != &quot;total&quot;,], aes(value, disease, fill = variable)) + geom_bar(stat = &quot;identity&quot;) + labs(x = &quot;Proportion of Individuals&quot;, y = &quot;&quot;, fill = &quot;Source Model:&quot;) + scale_fill_discrete(labels = c(&quot;Base&quot;, &quot;Score Incl.&quot;)) + theme(legend.position = &quot;top&quot;) i &lt;- 1 tp_vars &lt;- c(&quot;Score&quot;, &quot;Base&quot;) reclass_vars &lt;- c(&quot;diff&quot;, &quot;intersect&quot;) for(curr_disease in levels(plot_df$disease)){ for(j in 1:2){ tp_val &lt;- as.character(round(tp_df[tp_df$disease == curr_disease &amp; tp_df$type == tp_vars[j], 1]*100, 1)) if(j == 1){ xpos &lt;- plot_df[plot_df$disease == curr_disease &amp; plot_df$variable == reclass_vars[j], 4]/2 } else { xpos &lt;- plot_df[plot_df$disease == curr_disease &amp; plot_df$variable == reclass_vars[j-1], 4] + plot_df[plot_df$disease == curr_disease &amp; plot_df$variable == reclass_vars[j], 4]/2 } the_plot &lt;- the_plot + annotate(geom = &quot;text&quot;, label = tp_val, x = xpos, y = i, color = &quot;white&quot;, size = 3) } i &lt;- i + 1 } plot(the_plot) ggsave(paste0(&quot;addon_test_plots/meta/hopeful_fig.png&quot;), the_plot, &quot;png&quot;, height=6, width=7) ################################################################################################ # BRIER #### ################################################################################################# plot_brier &lt;- function(brier_list, covar_type, write_supp = FALSE){ brier_vals &lt;- data.frame(do.call(&quot;rbind&quot;, brier_list)) colnames(brier_vals) &lt;- c(&quot;base&quot;, &quot;score&quot;) brier_vals$diff &lt;- brier_vals[,2] - brier_vals[,1] brier_vals$disease &lt;- convert_names(all_authors, disease_names) brier_vals &lt;- melt(brier_vals, id.vars = &quot;disease&quot;) brier_vals$variable &lt;- str_to_title(brier_vals$variable) brier_vals$disease &lt;- factor(brier_vals$disease, unique(brier_vals$disease)[ order(brier_vals$value[brier_vals$variable ==&quot;Score&quot;])]) the_plot &lt;- ggplot(brier_vals[brier_vals$variable != &quot;Diff&quot;,], aes(value, disease, color = variable)) + geom_point() + labs(x = &quot;Brier Value&quot;, y = &quot;&quot;, color = &quot;Model&quot;) plot(the_plot) ggsave(paste0(&quot;addon_test_plots/meta/brier.&quot;, covar_type, &quot;.png&quot;), the_plot, &quot;png&quot;, height=6, width=7) brier_vals$disease &lt;- factor(brier_vals$disease, unique(brier_vals$disease)[ order(brier_vals$value[brier_vals$variable ==&quot;Diff&quot;])]) the_plot &lt;- ggplot(brier_vals[brier_vals$variable == &quot;Diff&quot;,], aes(value, disease)) + geom_point() + labs(x = &quot;Brier Value Diff.&quot;, y = &quot;&quot;) plot(the_plot) if(write_supp){ brier_vals &lt;- data.frame(&quot;disease&quot; = brier_vals$disease[brier_vals$variable == &quot;Base&quot;], &quot;Base&quot; = signif(brier_vals$value[brier_vals$variable == &quot;Base&quot;], 3), &quot;Score&quot; = signif(brier_vals$value[brier_vals$variable == &quot;Score&quot;], 3)) write.table(brier_vals, &quot;supp_tables/brier_vals.txt&quot;, quote = F, sep = &quot;\\t&quot;, col.names = T, row.names = F) } } plot_brier(brier_normal, &quot;norm&quot;, TRUE) plot_brier(brier_extra, &quot;extra&quot;) ################################################################################################ # RECLASS #### ################################################################################################# plot_reclass &lt;- function(reclass_list, covar_type, write_supp = FALSE){ reclass_df &lt;- do.call(&quot;rbind&quot;, reclass_list) reclass_df &lt;- reclass_df[reclass_df$cut_off == 0.95,] reclass_df$disease &lt;- factor(reclass_df$disease, levels = reclass_df$disease[order(reclass_df$nri_est)]) the_plot &lt;- ggplot(reclass_df, aes(nri_est, disease)) + geom_point() + labs(x = &quot;Net Reclassification Improvement&quot;, y = &quot;&quot;) + geom_errorbar(aes(xmin = nri_lo, xmax = nri_hi, width = 0)) plot(the_plot) ggsave(paste0(&quot;addon_test_plots/meta/reclass.nri.&quot;, covar_type, &quot;.png&quot;), the_plot, &quot;png&quot;, height=6, width=6) reclass_df$disease &lt;- factor(reclass_df$disease, levels = reclass_df$disease[order(reclass_df$idi_est)]) the_plot &lt;- ggplot(reclass_df, aes(idi_est, disease)) + geom_point() + labs(x = &quot;Integrated Discrimination Improvement&quot;, y = &quot;&quot;) + geom_errorbar(aes(xmin = idi_lo, xmax = idi_hi, width = 0)) plot(the_plot) ggsave(paste0(&quot;addon_test_plots/meta/reclass.idi.&quot;, covar_type, &quot;.png&quot;), the_plot, &quot;png&quot;, height=6, width=6) if(write_supp){ write.table(reclass_df[,c(8,1:3)], &quot;supp_tables/nri_vals.txt&quot;, quote = F, sep = &quot;\\t&quot;, col.names = T, row.names = F) write.table(reclass_df[,c(8,4:6)], &quot;supp_tables/idi_vals.txt&quot;, quote = F, sep = &quot;\\t&quot;, col.names = T, row.names = F) } } plot_reclass(reclass_normal, &quot;norm&quot;, TRUE) plot_reclass(reclass_extra, &quot;extra&quot;) pval_reclass &lt;- do.call(&quot;rbind&quot;, reclass_normal) pval_reclass &lt;- pval_reclass[pval_reclass$cut_off == 0.95,] ################################################################################################ # TPR FPR RATES #### ################################################################################################# plot_rates &lt;- function(rates_list, covar_type, write_supp = FALSE){ rate_vals &lt;- data.frame(do.call(&quot;rbind&quot;, rates_list)) rate_vals &lt;- melt(rate_vals, id.vars = c(&quot;type&quot;, &quot;disease&quot;)) rate_vals$disease &lt;- factor(rate_vals$disease, levels = unique(rate_vals$disease)[ order(rate_vals$value[rate_vals$variable == &quot;tpr&quot; &amp; rate_vals$type == &quot;score&quot;])]) rate_vals$type &lt;- str_to_title(rate_vals$type) the_plot &lt;- ggplot(rate_vals[rate_vals$type != &quot;Diff&quot; &amp; rate_vals$variable == &quot;tpr&quot;,], aes(value, disease, color = type)) + geom_point() + labs(x = &quot;True Positive Rate&quot;, y = &quot;&quot;, color = &quot;Model&quot;) plot(the_plot) ggsave(paste0(&quot;addon_test_plots/meta/tpr.&quot;, covar_type, &quot;.png&quot;), the_plot, &quot;png&quot;, height=6, width=6) rate_vals$disease &lt;- factor(rate_vals$disease, levels = unique(rate_vals$disease)[ order(rate_vals$value[rate_vals$variable == &quot;tpr&quot; &amp; rate_vals$type == &quot;Diff&quot;])]) the_plot &lt;- ggplot(rate_vals[rate_vals$type == &quot;Diff&quot; &amp; rate_vals$variable == &quot;tpr&quot;,], aes(value, disease)) + geom_point() + labs(x = &quot;True Positive Rate Diff.&quot;, y = &quot;&quot;) plot(the_plot) if(write_supp){ write_df &lt;- data.frame(&quot;disease&quot; = rate_vals$disease[rate_vals$type == &quot;Score&quot; &amp; rate_vals$variable == &quot;fpr&quot;], &quot;TPR - Base&quot; = signif(rate_vals$value[rate_vals$type == &quot;Base&quot; &amp; rate_vals$variable == &quot;tpr&quot;], 3), &quot;FPR - Base&quot; = signif(rate_vals$value[rate_vals$type == &quot;Base&quot; &amp; rate_vals$variable == &quot;fpr&quot;], 3), &quot;TPR - Score&quot; = signif(rate_vals$value[rate_vals$type == &quot;Score&quot; &amp; rate_vals$variable == &quot;tpr&quot;], 3), &quot;FPR - Score&quot; = signif(rate_vals$value[rate_vals$type == &quot;Score&quot; &amp; rate_vals$variable == &quot;fpr&quot;], 3)) write.table(write_df, &quot;supp_tables/tpr_fpr_vals.txt&quot;, quote = F, sep = &quot;\\t&quot;, col.names = T, row.names = F) } } plot_rates(rates_normal, &quot;norm&quot;, TRUE) plot_rates(rates_extra, &quot;extra&quot;) ################################################################################################ # TRUE POSITIVES #### ################################################################################################# plot_tp &lt;- function(tp_list, covar_type){ tp_df &lt;- do.call(&quot;rbind&quot;, tp_list) tp_df &lt;- tp_df[tp_df$cut_off == 0.95,] tp_df$type &lt;- str_to_title(tp_df$type) tp_df$disease &lt;- factor(tp_df$disease, levels = unique(tp_df$disease)[order(tp_df$rate[tp_df$type == &quot;Diff&quot;])]) the_plot &lt;- ggplot(tp_df[tp_df$type == &quot;Diff&quot;,], aes(rate, disease)) + geom_point() + labs(x = &quot;True Positive Rate Diff.&quot;, y = &quot;&quot;) plot(the_plot) tp_df$disease &lt;- factor(tp_df$disease, levels = unique(tp_df$disease)[order(tp_df$rate[tp_df$type == &quot;Score&quot;])]) the_plot &lt;- ggplot(tp_df[tp_df$type != &quot;Diff&quot;,], aes(rate, disease, color = type)) + geom_point() + labs(x = &quot;True Positive Rate&quot;, y = &quot;&quot;, color = &quot;Model&quot;) plot(the_plot) ggsave(paste0(&quot;addon_test_plots/meta/risky_tp.&quot;, covar_type, &quot;.png&quot;), the_plot, &quot;png&quot;, height=6, width=6) } plot_tp(tp_normal, &quot;norm&quot;) plot_tp(tp_extra, &quot;extra&quot;) exit() df &lt;- do.call(&quot;rbind&quot;, tp_normal) x &lt;- df[df$cut_off == 0.95 &amp; df$type == &quot;Score&quot;,] y &lt;- df[df$cut_off == 0.95 &amp; df$type == &quot;Base&quot;,] supp_df &lt;- data.frame(&quot;disease&quot; = df[df$type == &quot;Score&quot; &amp; df$cut_off == 0.95,5], &quot;Base&quot; = signif(df[df$type == &quot;Base&quot; &amp; df$cut_off == 0.95,1], 3), &quot;Score&quot; = signif(df[df$type == &quot;Score&quot; &amp; df$cut_off == 0.95,1], 3)) write.table(supp_df, &quot;supp_tables/simple_tp.txt&quot;, row.names = F, col.names = T, quote = F, sep = &quot;\\t&quot;) ################################################################################################ # DECISION CURVES #### ################################################################################################# dc_plot &lt;- function(dc_best, dc_all, dc_range, cov_type, write_supp = FALSE){ disease_bool &lt;- unlist(lapply(dc_best, function(x) x$thresh != 0)) new_disease_names &lt;- convert_names(all_authors, disease_names)[disease_bool] dc_df &lt;- do.call(&quot;rbind&quot;, dc_best) dc_df &lt;- dc_df[disease_bool,] dc_df$disease &lt;- new_disease_names dc_df &lt;- dc_df[dc_df$score != 1,] dc_df &lt;- melt(dc_df, id.vars = c(&quot;thresh&quot;, &quot;cb_ratio&quot;, &quot;disease&quot;)) dc_df$disease &lt;- factor(dc_df$disease, levels = unique(dc_df$disease)[order(dc_df$value[dc_df$variable == &quot;score&quot;])]) dc_df$variable &lt;- str_to_title(dc_df$variable) dc_df$variable[dc_df$variable == &quot;Base&quot;] &lt;- &quot;Base&quot; dc_df$variable[dc_df$variable == &quot;Score&quot;] &lt;- &quot;Score Incl.&quot; the_plot &lt;- ggplot(dc_df[dc_df$variable %in% c(&quot;Base&quot;, &quot;Score Incl.&quot;),], aes(value, disease, color = variable)) + geom_point() + labs(x = &quot;Standardized Net Benefit&quot;, y = &quot;&quot;, color = &quot;Model:&quot;) + theme(legend.position = &quot;top&quot;, legend.text = element_text(size = 10)) plot(the_plot) ggsave(paste0(&quot;addon_test_plots/meta/dc.best.&quot;, cov_type, &quot;.png&quot;), the_plot, &quot;png&quot;, height=6, width=4.5) if(write_supp){ write_df &lt;- dc_df[dc_df$variable != &quot;Diff&quot;,] write_df &lt;- data.frame(&quot;disease&quot; = write_df$disease[write_df$variable == &quot;Base&quot;], &quot;Base NB&quot; = signif(write_df$value[write_df$variable == &quot;Base&quot;],3), &quot;Base Thresh&quot; = write_df$thresh[write_df$variable == &quot;Base&quot;], &quot;Score NB&quot; = signif(write_df$value[write_df$variable == &quot;Score Incl.&quot;],3), &quot;Score Thresh&quot; = write_df$thresh[write_df$variable == &quot;Score Incl.&quot;]) write.table(write_df, &quot;supp_tables/dc_best.txt&quot;, quote = F, sep = &quot;\\t&quot;, col.names = T, row.names = F) } dc_df &lt;- do.call(&quot;rbind&quot;, dc_all) dc_df$disease &lt;- rep(convert_names(all_authors, disease_names), each = 3) dc_df &lt;- dc_df[dc_df$score != 1,] dc_df &lt;- melt(dc_df, id.vars = c(&quot;thresh&quot;, &quot;cb_ratio&quot;, &quot;disease&quot;)) dc_df$disease &lt;- factor(dc_df$disease, levels = unique(dc_df$disease)[ order(dc_df$value[dc_df$variable == &quot;score&quot; &amp; dc_df$thresh == 0.05])]) dc_df$variable &lt;- str_to_title(dc_df$variable) dc_df$variable[dc_df$variable == &quot;Base&quot;] &lt;- &quot;Base&quot; dc_df$variable[dc_df$variable == &quot;Score&quot;] &lt;- &quot;Score Incl.&quot; dc_df$thresh &lt;- paste0(&quot;Thresh. = &quot;, dc_df$thresh) the_plot &lt;- ggplot(dc_df[dc_df$variable %in% c(&quot;Base&quot;, &quot;Score Incl.&quot;),], aes(value, disease, color = variable)) + geom_point() + labs(x = &quot;Standardized Net Benefit&quot;, y = &quot;&quot;, color = &quot;Model:&quot;) + facet_grid(cols = vars(thresh)) + theme(legend.position = &quot;top&quot;) plot(the_plot) ggsave(paste0(&quot;addon_test_plots/meta/dc.many.&quot;, cov_type, &quot;.png&quot;), the_plot, &quot;png&quot;, height=6, width=8) if(write_supp){ write_df &lt;- dc_df[dc_df$variable != &quot;Diff&quot;,] write_df &lt;- data.frame(&quot;disease&quot; = write_df$disease[write_df$variable == &quot;Base&quot; &amp; write_df$cb_ratio == 0.01], &quot;Base NB - 0.01&quot; = signif(write_df$value[write_df$variable == &quot;Base&quot; &amp; write_df$cb_ratio == 0.01],3), &quot;Base NB - 0.05&quot; = signif(write_df$value[write_df$variable == &quot;Base&quot; &amp; write_df$cb_ratio == 0.05],3), &quot;Base NB - 0.12&quot; = signif(write_df$value[write_df$variable == &quot;Base&quot; &amp; write_df$cb_ratio == 0.12],3), &quot;Score NB - 0.01&quot; = signif(write_df$value[write_df$variable == &quot;Score Incl.&quot; &amp; write_df$cb_ratio == 0.01],3), &quot;Score NB - 0.05&quot; = signif(write_df$value[write_df$variable == &quot;Score Incl.&quot; &amp; write_df$cb_ratio == 0.05],3), &quot;Score NB - 0.12&quot; = signif(write_df$value[write_df$variable == &quot;Score Incl.&quot; &amp; write_df$cb_ratio == 0.12],3)) write.table(write_df, &quot;supp_tables/dc_all.txt&quot;, quote = F, sep = &quot;\\t&quot;, col.names = T, row.names = F) } dc_range &lt;- data.frame(do.call(&quot;rbind&quot;, dc_range)) colnames(dc_range) &lt;- c(&quot;start&quot;, &quot;end&quot;) dc_range &lt;- dc_range[disease_bool,] dc_range$disease &lt;- new_disease_names #dc_range &lt;- dc_range[!is.infinite(dc_range[,1]),] dc_range$disease &lt;- factor(dc_range$disease, levels = dc_range$disease[order(dc_range$end - dc_range$start)]) the_plot &lt;- ggplot(dc_range, aes(start, disease)) + geom_point(size = 0) + geom_errorbarh(aes(xmin = start, xmax = end, height = 0)) + labs(x = &quot;Positive Net Benefit Threshold&quot;, y = &quot;&quot;) plot(the_plot) ggsave(paste0(&quot;addon_test_plots/meta/dc.range.&quot;, cov_type, &quot;.png&quot;), the_plot, &quot;png&quot;, height=6, width=6) dc_df$thresh[dc_df$thresh == &quot;Thresh. = 0.05&quot;] &lt;- &quot;Thresh. = 95%&quot; dc_df$thresh[dc_df$thresh == &quot;Thresh. = 0.01&quot;] &lt;- &quot;Thresh. = 99%&quot; dc_df$thresh[dc_df$thresh == &quot;Thresh. = 0.12&quot;] &lt;- &quot;Thresh. = 88%&quot; dc_df &lt;- dc_df[dc_df$disease %in% dc_range$disease[(dc_range$end - dc_range$start) &gt; 0.10],] the_plot &lt;- ggplot(dc_df[dc_df$variable %in% c(&quot;Base&quot;, &quot;Score Incl.&quot;),], aes(value, disease, color = variable)) + geom_point() + labs(x = &quot;Standardized Net Benefit&quot;, y = &quot;&quot;, color = &quot;Model:&quot;) + facet_grid(cols = vars(thresh)) + theme(legend.position = &quot;top&quot;) plot(the_plot) ggsave(paste0(&quot;addon_test_plots/meta/dc.for_fig.&quot;, cov_type, &quot;.png&quot;), the_plot, &quot;png&quot;, height=3.8, width=8) if(write_supp){ write_df &lt;- dc_range write.table(write_df, &quot;supp_tables/dc_range.txt&quot;, quote = F, sep = &quot;\\t&quot;, col.names = T, row.names = F) } } dc_plot(dc_best_normal, dc_normal, dc_range_normal, &quot;norm&quot;, TRUE) dc_plot(dc_best_extra, dc_extra, dc_range_extra, &quot;extra&quot;) ex &lt;- do.call(&quot;rbind&quot;, dc_best_extra) norm &lt;- do.call(&quot;rbind&quot;, dc_best_normal) ex &lt;- ex[ex[,1] != 1,] norm &lt;- norm[norm[,1] != 1 &amp; unlist(lapply(dc_best_extra, function(x) !is.null(x))),] write_df &lt;- data.frame(convert_names(all_authors, disease_names), matrix(0, nrow = 23, ncol = 4)) j=1 for(i in 1:23){ write_df[i,j+2] &lt;- signif(dc_best_normal[[i]]$base, 3) write_df[i,j+1] &lt;- signif(dc_best_normal[[i]]$score, 3) if(!is.null(dc_best_extra[[i]])){ write_df[i,j+4] &lt;- signif(dc_best_extra[[i]]$base, 3) write_df[i,j+3] &lt;- signif(dc_best_extra[[i]]$score, 3) } } write_df &lt;- write_df[write_df[,2] != 1,] colnames(write_df) &lt;- c(&quot;Disease&quot;, &quot;Score-No&quot;, &quot;Base-No&quot;, &quot;Score-Extra&quot;, &quot;Base-Extra&quot;) write.table(write_df, &quot;supp_tables/dc_extra.txt&quot;, row.names = F, col.names = T, quote = F, sep = &#39;\\t&#39;) "],["non-predictive-evaluation.html", "11 Non-Predictive Evaluation 11.1 Individual Score Evaluation", " 11 Non-Predictive Evaluation There are many facets of polygenic risk scores that are important in understanding if a score is best, that have nothing to do with its predictive value. These facets include the score size, the variation in response to phenotype definition, application differences in racial groups, and differences between sibling types. There are likely even more facets but these are the facets that I could think of and are likely the most critical and easy to do. Some of these sub-analyses require more than just a little R code, and I will go into the set-up in each respective section. Additional descriptions on what certain sub-analyses mean will also be in their respective sections. While these non-predictive evaluations may seem purely supplementary, I believe they are of paramount importance in truly understanding the quality of a polygenic risk score. 11.1 Individual Score Evaluation I perform two major sets of evaluations, those that apply to each and every score (often in the effort of determining “model” fit and score qualities) and those that require multiple scores in order to establish comparisons (determine correlations between scores, parameters, meta-statistics). The first set of evaluations are of the former type. 11.1.1 Set Up All of the nonpredictive evaluations are done within a single script, one author at a time. Before each of the previously mentioned evaluations can be carried out set up must be completed in which the scores and other nescessary files are read in. This set up is highly similar to what is done in the beginning of the tune script so I won’t go into much detail. The only major difference is that much of the code is duplicated (not a great practice but it works) so that the scores and remaining data for British individuals and non-British individuals are kept seperately. Remember that all of the other analyses are only done on a homogenous (mostly) British population, but here we want to check out what happens if it is not so homogenous. The script ultimately produces scores, phenotypes, dates and covariates. The details are shown below: library(survival) library(data.table) library(pROC) library(epitools) author &lt;- &quot;Mahajan&quot; #author &lt;- commandArgs(trailingOnly=TRUE) #read in scores all_scores &lt;- readRDS(paste0(&quot;../../do_score/final_scores/all_score.&quot;, tolower(author), &quot;.RDS&quot;)) score_eids &lt;- read.table(&quot;~/athena/doc_score/do_score/all_specs/for_eid.fam&quot;, stringsAsFactors=F) other_scores &lt;- readRDS(paste0(&quot;~/athena/doc_score/do_score/ethnic_scoring/final_scores/all_score.&quot;, tolower(author), &quot;.RDS&quot;)) ethnic_eids &lt;- read.table(&quot;~/athena/doc_score/qc/ethnic_eids&quot;, stringsAsFactors=F) #normalize the scores scores &lt;- all_scores[,grepl(tolower(author), colnames(all_scores))] scores &lt;- scores[,apply(scores, 2, function(x) length(unique(x)) &gt; 3)] scores &lt;- apply(scores, 2, function(x) (x-mean(x)) / (max(abs((x-mean(x)))) * 0.01) ) rm(all_scores) escores &lt;- other_scores[,grepl(tolower(author), colnames(other_scores))] escores &lt;- escores[,apply(escores, 2, function(x) length(unique(x)) &gt; 3)] escores &lt;- apply(escores, 2, function(x) (x-mean(x)) / (max(abs((x-mean(x)))) * 0.01) ) rm(other_scores) #read in phenotype and covars pheno &lt;- read.table(paste0(&quot;../construct_defs/pheno_defs/diag.&quot;, tolower(author), &quot;.txt.gz&quot;), stringsAsFactors=F) dates &lt;- read.table(paste0(&quot;../construct_defs/pheno_defs/time.&quot;, tolower(author), &quot;.txt.gz&quot;), stringsAsFactors=F) covars &lt;- readRDS(&quot;../get_covars/base_covars.RDS&quot;) #sort the phenotypes pheno_eids &lt;- read.table(&quot;../construct_defs/eid.csv&quot;, header = T) pheno_eids &lt;- pheno_eids[order(pheno_eids[,1]),] pheno_eids &lt;- pheno_eids[-length(pheno_eids)] #split covars brit_covars &lt;- covars[(covars[,1] %in% score_eids[,1]) &amp; (covars[,1] %in% pheno_eids),] brit_covars &lt;- brit_covars[order(brit_covars[,1]),] ethnic_covars &lt;- covars[(covars[,1] %in% ethnic_eids[,1]) &amp; (covars[,1] %in% pheno_eids),] ethnic_covars &lt;- ethnic_covars[order(ethnic_covars[,1]),] #split pheno, dates brit_pheno &lt;- pheno[(pheno_eids %in% score_eids[,1]) &amp; (pheno_eids %in% covars[,1]),] brit_dates &lt;- dates[(pheno_eids %in% score_eids[,1]) &amp; (pheno_eids %in% covars[,1]),] brit_pheno_eids &lt;- pheno_eids[(pheno_eids %in% score_eids[,1]) &amp; (pheno_eids %in% covars[,1])] ethnic_pheno &lt;- pheno[(pheno_eids %in% ethnic_eids[,1]) &amp; (pheno_eids %in% covars[,1]),] ethnic_dates &lt;- dates[(pheno_eids %in% ethnic_eids[,1]) &amp; (pheno_eids %in% covars[,1]),] ethnic_pheno_eids &lt;- pheno_eids[(pheno_eids %in% ethnic_eids[,1]) &amp; (pheno_eids %in% covars[,1])] #split scores brit_scores &lt;- scores[(score_eids[,1] %in% pheno_eids) &amp; (score_eids[,1] %in% covars[,1]),] brit_score_eids &lt;- score_eids[(score_eids[,1] %in% pheno_eids) &amp; (score_eids[,1] %in% covars[,1]),] brit_scores &lt;- brit_scores[order(brit_score_eids[,1]),] brit_eid &lt;- brit_score_eids[order(brit_score_eids[, 1]), 1] ethnic_scores &lt;- escores[(ethnic_eids[,1] %in% pheno_eids) &amp; (ethnic_eids[,1] %in% covars[,1]),] ethnic_score_eids &lt;- ethnic_eids[(ethnic_eids[,1] %in% pheno_eids) &amp; (ethnic_eids[,1] %in% covars[,1]),,drop=F] ethnic_scores &lt;- ethnic_scores[order(ethnic_score_eids[,1]),] ethnic_eid &lt;- ethnic_score_eids[order(ethnic_score_eids[, 1]), 1] exit() rm(scores) rm(escores) #get the british eids brit_train &lt;- read.table(&quot;../../qc/cv_files/train_eid.0.6.txt&quot;, stringsAsFactors=F) brit_test &lt;- read.table(&quot;../../qc/cv_files/test_eid.0.4.txt&quot;, stringsAsFactors=F) #remove possible sex group author_defs &lt;- read.table(&quot;../descript_defs/author_defs&quot;, stringsAsFactors=F, header=T) sex_group &lt;- author_defs[author_defs[,1] == author, 3] if(sex_group == &quot;M&quot;){ all_sex &lt;- read.table(&quot;all_sex&quot;, stringsAsFactors=F, sep=&quot;,&quot;, header=T) all_sex &lt;- all_sex[all_sex[,1] %in% ethnic_eid,] all_sex &lt;- all_sex[order(all_sex[,1])[rank(ethnic_eid)],] brit_scores &lt;- brit_scores[brit_covars$sex == 1,] brit_eid &lt;- brit_eid[brit_covars$sex == 1] brit_pheno &lt;- brit_pheno[brit_covars$sex == 1,] brit_dates &lt;- brit_dates[brit_covars$sex == 1,] brit_covars &lt;- brit_covars[brit_covars$sex == 1,] ethnic_scores &lt;- ethnic_scores[all_sex[,2] == 1,] ethnic_eid &lt;- ethnic_eid[all_sex[,2] == 1] ethnic_pheno &lt;- ethnic_pheno[all_sex[,2] == 1,] ethnic_dates &lt;- ethnic_dates[all_sex[,2] == 1,] ethnic_covars &lt;- ethnic_covars[all_sex[,2] == 1,] }else if(sex_group == &quot;F&quot;){ all_sex &lt;- read.table(&quot;all_sex&quot;, stringsAsFactors=F, sep=&quot;,&quot;, header=T) all_sex &lt;- all_sex[all_sex[,1] %in% ethnic_eid,] all_sex &lt;- all_sex[order(all_sex[,1])[rank(ethnic_eid)],] brit_scores &lt;- brit_scores[brit_covars$sex == 0,] brit_eid &lt;- brit_eid[brit_covars$sex == 0] brit_pheno &lt;- brit_pheno[brit_covars$sex == 0,] brit_dates &lt;- brit_dates[brit_covars$sex == 0,] brit_covars &lt;- brit_covars[brit_covars$sex == 0,] ethnic_scores &lt;- ethnic_scores[all_sex[,2] == 0,] ethnic_eid &lt;- ethnic_eid[all_sex[,2] == 0] ethnic_pheno &lt;- ethnic_pheno[all_sex[,2] == 0,] ethnic_dates &lt;- ethnic_dates[all_sex[,2] == 0,] ethnic_covars &lt;- ethnic_covars[all_sex[,2] == 0,] } 11.1.2 Analysis of Score Sizes Once the set-up is complete the first major analysis entail the score sizes and distribution of effects. This outcomes of this analysis can be telling. If the scores contain many SNPs than the underlying disease architechture is likely highly polygenic, but if that score focuses on a few SNPs with high effect, than we know our previous assumption about polygenicity may be wrong. Therefore we must analyze not only the size but also the distribution of effects. Further sub-analyses that focus on a method, or parameter set within a method can be telling of future expected behavoir, perhaps even indicating the most likely method that should be applied to a disease not yet scored. The code that carries out this analysis collects 4 important measures of a score to better understand it. First is simply the number of SNPs. Second are the deciles of the absolute effect. The third and fourth measures get more complicated, and involve a splitter function that seperates the score SNPs into 4 groups such that each have nearly the equivalent sum of their absolute effect. The third measure is then the size of each of these 4 groups. The fourth measure is the mean absolute effect of each of these 4 groups. The motivation behind splitting the SNPs into groups is to determine whether a few SNPs carry the vast majority of the weight across all SNPs and therefore could be used on their own. The exact code is shown below: ############################################## ########### SCORE SIZES #################### ############################################## splitter &lt;- function(values, N){ inds = c(0, sapply(1:N, function(i) which.min(abs(cumsum(as.numeric(values)) - sum(as.numeric(values))/N*i)))) dif = diff(inds) if(any(dif == 0)){ dif[1] &lt;- dif[1] - sum(dif == 0) dif[dif == 0] &lt;- 1 } re = rep(1:length(dif), times = dif) return(split(values, re)) } all_equal_splits_len &lt;- matrix(0, nrow = ncol(brit_scores), ncol = 4) all_equal_splits_mean &lt;- matrix(0, nrow = ncol(brit_scores), ncol = 4) all_quantiles &lt;- matrix(0, nrow = ncol(brit_scores), ncol = 10) all_len &lt;- rep(0, ncol(brit_scores)) for(i in 1:ncol(brit_scores)){ score_name &lt;- colnames(brit_scores)[i] split_name &lt;- strsplit(score_name, &quot;.&quot;, fixed = T)[[1]] score_files &lt;- list.files(paste0(&quot;~/athena/doc_score/mod_sets/&quot;, author, &quot;/&quot;), glob2rx(paste0(split_name[1], &quot;*&quot;, split_name[3], &quot;.&quot;, split_name[2], &quot;.ss&quot;))) score_list &lt;- list() for(j in 1:length(score_files)){ #score_list[[j]] &lt;- read.table(paste0(&quot;~/athena/doc_score/mod_sets/&quot;, author, &quot;/&quot;, score_files[j]), stringsAsFactors = F, header = F) score_list[[j]] &lt;- as.data.frame(fread(paste0(&quot;~/athena/doc_score/mod_sets/&quot;, author, &quot;/&quot;, score_files[j]))) colnames(score_list[[j]]) &lt;- c(&quot;CHR&quot;, &quot;BP&quot;, &quot;RSID&quot;, &quot;A1&quot;, &quot;A2&quot;, &quot;SE&quot;, &quot;BETA&quot;, &quot;P&quot;, &quot;ESS&quot;) } ss &lt;- do.call(&quot;rbind&quot;, score_list) ss &lt;- ss[!is.na(ss[,7]),] if(ss[1,7] == &quot;BETA&quot;){ ss &lt;- ss[ss[,7] != &quot;BETA&quot;,] ss[,7] &lt;- as.numeric(ss[,7]) } ss[,7] &lt;- as.numeric(ss[,7]) ss &lt;- ss[!is.na(ss[,7]) &amp; ss[,7] != 0,] ss$eff &lt;- abs(ss[,7]) ss &lt;- ss[order(ss$eff),] if(nrow(ss) &gt; 10){ all_equal_splits_len[i,] &lt;- unlist(lapply(splitter(ss$eff, 4), length)) all_equal_splits_mean[i,] &lt;- unlist(lapply(splitter(ss$eff, 4), mean)) } else { all_equal_splits_len[i,] &lt;- rep(NA, 4) all_equal_splits_mean[i,] &lt;- rep(NA, 4) } if(nrow(ss) &gt; 100){ all_quantiles[i,] &lt;- quantile(ss$eff, 1:10/10) } else { all_quantiles[i,] &lt;- rep(NA, 10) } all_len[i] &lt;- length(ss$eff) } return_score_sizes &lt;- list(&quot;all_equal_splits_len&quot; = all_equal_splits_len, &quot;all_equal_splits_mean&quot; = all_equal_splits_mean, &quot;all_quantiles&quot; = all_quantiles, &quot;all_len&quot; = all_len) 11.1.3 Analysis of Phenotype Definitions The second major analysis slightly breaks the definition of a non-predictive evaluation, as this analysis computes the AUC of each score using multiple phenotype definitions. As a quick reminder, there are multiple places within the UK Biobank that may indicate a person has a disease. Within the main tuning section we assume that if either the ICD records contain or the individual self-reports as having the disease we assume that they do. However, we could instead look at just the ICD records, creating a different phenotype definition. In this analysis we look at six different phenotype definitions: ICD records only; self-reported only; ICD records or self-reported; ICD records, self-reported, OPCS records or associated medication; and the previous definition but two conditions are met instead of any. While a looser definition may have a grater number of individuals that did not truly have the disease, perhaps the increased sample size of true individuals will make up for it. This is the type of trade-off this analysis is attempting to examine. To get a respective AUC value a logistic regression model is created with the covariates of age, sex, PC1-10 and the polygenic risk score. The model is then used to form a prediction on the testing set and placed within the ROC function. While this continual use of the testing set would be bad news if I was going to report the final AUC value as something that can be replicated, that is not what I am doing. These values are simply useful in a relative sense to one another. As a final note, I am also storing the number of cases in each phenotype definiton to compare which creates the largest sample size. The exact code is shown below: ############################################## ########### PHENOTYPE DEFINITIONS #################### ############################################## icd_phen &lt;- apply(brit_pheno[,3:4], 1, function(x) any(x==1))*1 selfrep_phen &lt;- apply(brit_pheno[,1:2], 1, function(x) any(x==1))*1 diag_phen &lt;- apply(brit_pheno[,1:5], 1, function(x) any(x==1))*1 any_phen &lt;- apply(brit_pheno, 1, function(x) any(x==1))*1 double_phen &lt;- apply(brit_pheno, 1, function(x) sum(x) &gt; 1)*1 all_phens &lt;- list(icd_phen, selfrep_phen, diag_phen, any_phen, double_phen) all_phen_auc &lt;- matrix(0, nrow = ncol(brit_scores), ncol = 15) phen_type_starts &lt;- seq(1, 15, 3) for(i in 1:5){ df &lt;- data.frame(phen = all_phens[[i]], brit_covars) for(j in 1:ncol(brit_scores)){ if(any(df$phen == 1)){ df$score &lt;- brit_scores[,j] train_df &lt;- df[df$eid %in% brit_train[,1],] test_df &lt;- df[df$eid %in% brit_test[,1],] mod &lt;- glm(phen ~ age + sex + PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10 + score, data = train_df, family = &quot;binomial&quot;) test_roc &lt;- roc(test_df$phen ~ predict(mod, test_df)) all_phen_auc[j,(phen_type_starts[i]):(phen_type_starts[i]+2)] &lt;- as.numeric(ci.auc(test_roc)) } else { all_phen_auc[j,(phen_type_starts[i]):(phen_type_starts[i]+2)] &lt;- c(NA, NA, NA) } } } return_pheno_defs &lt;- list(&quot;all_phen_auc&quot; = all_phen_auc, &quot;total_phens&quot; = unlist(lapply(all_phens, sum))) 11.1.4 Comparison Between the Sexes In several publications concern has been raised on the idea that polygenic risk scores may work far better for males compared to females (or vice versa). Some people have even constructed scores specifically for either males or females in the hope that stratifying would raise accuracy. While I have clearly not done that here it may still be worthwhile to see if there is a large prediction difference. To compare I follow a procedure very similar to the phenotype comparison set up, in which I get the training data, seperate it between males and females, construct two models, form two predictions on the testing set and finally get 2 AUC values. The exact code is: ############################################## ########### SEX DIFFERENCES #################### ############################################## diag_phen &lt;- apply(brit_pheno[,1:5], 1, function(x) any(x==1))*1 if(sex_group == &quot;A&quot;){ all_sex_auc &lt;- matrix(0, nrow = ncol(brit_scores), ncol = 6) df &lt;- data.frame(phen = diag_phen, brit_covars) sex_auc_p &lt;- rep(NA, ncol(brit_scores)) for(j in 1:ncol(brit_scores)){ df$score &lt;- brit_scores[,j] train_df &lt;- df[df$eid %in% brit_train[,1],] test_df &lt;- df[df$eid %in% brit_test[,1],] roc_holder &lt;- list() for(sex in c(0,1)){ sub_train_df &lt;- train_df[train_df$sex == sex,] sub_test_df &lt;- test_df[test_df$sex == sex,] sub_train_df &lt;- sub_train_df[,-which(colnames(sub_train_df) == &quot;sex&quot;)] sub_test_df &lt;- sub_test_df[,-which(colnames(sub_test_df) == &quot;sex&quot;)] mod &lt;- glm(phen ~ age + PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10 + score, data = sub_train_df, family = &quot;binomial&quot;) test_roc &lt;- roc(sub_test_df$phen ~ predict(mod, sub_test_df)) all_sex_auc[j,(sex*3+1):(sex*3+3)] &lt;- as.numeric(ci.auc(test_roc)) roc_holder[[sex+1]] &lt;- test_roc } sex_auc_p[j] &lt;- roc.test(roc_holder[[1]], roc_holder[[2]], paired = FALSE)$p.value } } else { all_sex_auc &lt;- NULL sex_auc_p &lt;- NULL } return_sex_split &lt;- list(&quot;all_sex_auc&quot; = all_sex_auc) 11.1.5 Comparison of Ethnic Groups The third major analysis compares the score distributions of various ethnic groups. These ethnic groups were created by analyzing the PCA that was completed by the UK Biobank (described just below). The vast majority of the individuals are British, and used throughout the main tuning/testing, but now we look at other ethnic groups such as African, Asian and other European ancestry. Many other reports have shown that scores created on European summary statistics will be greatly skewed based on which ethnic group it is applied. There is an ongoing discussion on exactly why this is that I unfortunately don’t have time to go into here. My intentions are simply to see how bad this skew is in the scores I am making. The process to determine ethnic groups was primarly carried out by reading in the 40 PCs calculated by the UK Biobank, then implementing K-means clustering (with a k of 3). Each cluster was then identified as belonging to a given ethnic group by merging with racial groups each individual self-identified with. Each k-means cluster was clearly one ethnic group, with only a handful of outliers. As a further precaution, individuals that were within the first percentile of being furthest from the center of their cluster center were removed. The remaining individuals were from that point onwards ascribed with the ethnicity of the cluster. The exact code that carried out this process is: library(vroom) # Column titles for the qc files #19 = outliers in hetrozygosity #20 = putative sex chromosome aneuploidy #21 = in kinship table #22 = excluded from kinship calcs #23 = excess relatives #24 = British ancestry #25 = Used in PCA #26 = PCs #read in qc and the fam file, which contains the eids of the qc file qc &lt;- as.data.frame(vroom(&quot;../qc/ukb_sample_qc.txt&quot;, delim = &quot; &quot;, col_names = F)) fam &lt;- read.table(&quot;../calls/ukbb.22.fam&quot;, stringsAsFactors = F) #do brit thing brit_fam &lt;- fam[qc[,19] == 0 &amp; qc[,20] == 0 &amp; qc[,23] == 0 &amp; qc[,24] == 1,] brit_fam$eth &lt;- 0 brit_fam$eth_name &lt;- &quot;brit&quot; #read in the phen phen &lt;- read.csv(&quot;../phenotypes/ukb26867.csv.gz&quot;, stringsAsFactors = F) #subset according to the specified conditions within &quot;Genetics of 38 blood and urine biomarkers in the UK Biobank&quot; good_fam &lt;- fam[qc[,19] == 0 &amp; qc[,20] == 0 &amp; qc[,23] == 0,] #subset the phen, qc, and fam files based on the good_fam above phen$eid[is.na(phen$eid)] &lt;- -999 phen &lt;- phen[phen[,1] %in% good_fam[,1],] qc &lt;- qc[fam[,1] %in% phen[,1],] fam &lt;- fam[fam[,1] %in% phen[,1],] phen &lt;- phen[order(phen[,1])[rank(fam[,1])],] #create vector for the survey answers of self-declared race ethnic &lt;- as.numeric(phen[,1288,drop=T]) ethnic_code &lt;- rep(0, length(ethnic)) ethnic_code[ethnic %in% c(1, 1001, 1002, 1003)] &lt;- 1 #european ethnic_code[ethnic %in% c(4002, 4003, 4)] &lt;- 2 #black ethnic_code[ethnic %in% c(3, 5, 3001, 3002, 3003, 3004)] &lt;- 3 #asian #do the kmeans and then calculate distance of each eid to its respective center euc_dist &lt;- function(x1, x2) sqrt(sum((x1 - x2) ^ 2)) pcs &lt;- qc[,26:65] k_clu &lt;- kmeans(pcs, 3) #dist_to_center &lt;- rep(0, length(ethnic_code)) #for(i in 1:3){ # for(j in which(k_clu$cluster == i)){ # dist_to_center[j] &lt;- euc_dist(k_clu$centers[i,], pcs[j,]) # } #} dist_to_center &lt;- readRDS(&quot;dist_to_center.RDS&quot;) #get the indices of the pca outliers ancestry_remove &lt;- list() for(i in 1:3){ cut_off &lt;- quantile(dist_to_center[k_clu$cluster == i], 0.99) ancestry_remove[[i]] &lt;- which(dist_to_center &gt; cut_off &amp; k_clu$cluster == i) } #Determine all_sums &lt;- c(sum(k_clu$cluster == 1), sum(k_clu$cluster == 2), sum(k_clu$cluster == 3)) #assign ethnic groups then kick out outliers fam$eth_name &lt;- &quot;&quot; fam$eth_name[k_clu$cluster == which.max(all_sums)] &lt;- &quot;euro&quot; fam$eth_name[k_clu$cluster == which.min(all_sums)] &lt;- &quot;african&quot; fam$eth_name[k_clu$cluster == which(all_sums == sort(all_sums)[2])] &lt;- &quot;asian&quot; fam$eth &lt;- 0 fam$eth[k_clu$cluster == which.max(all_sums)] &lt;- 1 fam$eth[k_clu$cluster == which.min(all_sums)] &lt;- 2 fam$eth[k_clu$cluster == which(all_sums == sort(all_sums)[2])] &lt;- 3 fam &lt;- fam[-unlist(ancestry_remove),] phen &lt;- phen[-unlist(ancestry_remove),] #break out ancestry fams euro_fam &lt;- fam[fam$eth_name == &quot;euro&quot;,] african_fam &lt;- fam[fam$eth_name == &quot;african&quot;,] asian_fam &lt;- fam[fam$eth_name == &quot;asian&quot;,] #create special for not dead eids and not lost to follow up bad_bool &lt;- apply(phen[,which(colnames(phen) %in% c(&quot;X40000.0.0&quot;, &quot;X191.0.0&quot;))], 1, function(x) any(! (x == &quot;&quot;))) bad_eid &lt;- phen$eid[bad_bool] alive_fam &lt;- fam[!(fam[,1] %in% bad_eid),] alive_euro_fam &lt;- euro_fam[!(euro_fam[,1] %in% bad_eid),] alive_african_fam &lt;- african_fam[!(african_fam[,1] %in% bad_eid),] alive_asian_fam &lt;- asian_fam[!(asian_fam[,1] %in% bad_eid),] #specific country eids england_eid &lt;- phen$eid[!is.na(phen[,which(colnames(phen) == &quot;X26410.0.0&quot;)])] scotland_eid &lt;- phen$eid[!is.na(phen[,which(colnames(phen) == &quot;X26427.0.0&quot;)])] wales_eid &lt;- phen$eid[!is.na(phen[,which(colnames(phen) == &quot;X26426.0.0&quot;)])] alive_england_fam &lt;- fam[!(fam[,1] %in% bad_eid) &amp; (fam[,1] %in% england_eid),] alive_scotland_fam &lt;- fam[!(fam[,1] %in% bad_eid) &amp; (fam[,1] %in% scotland_eid),] alive_wales_fam &lt;- fam[!(fam[,1] %in% bad_eid) &amp; (fam[,1] %in% wales_eid),] #write all of the tables write.table(fam, &quot;fam_files/qc_fam&quot;, row.names = F, col.names = F, quote = F, sep = &#39;\\t&#39;) write.table(euro_fam, &quot;fam_files/euro_fam&quot;, row.names = F, col.names = F, quote = F, sep = &#39;\\t&#39;) write.table(african_fam, &quot;fam_files/african_fam&quot;, row.names = F, col.names = F, quote = F, sep = &#39;\\t&#39;) write.table(asian_fam, &quot;fam_files/asian_fam&quot;, row.names = F, col.names = F, quote = F, sep = &#39;\\t&#39;) write.table(alive_fam, &quot;fam_files/qc_alive_fam&quot;, row.names = F, col.names = F, quote = F, sep = &#39;\\t&#39;) write.table(alive_euro_fam, &quot;fam_files/qc_alive_euro_fam&quot;, row.names = F, col.names = F, quote = F, sep = &#39;\\t&#39;) write.table(alive_african_fam, &quot;fam_files/qc_alive_african_fam&quot;, row.names = F, col.names = F, quote = F, sep = &#39;\\t&#39;) write.table(alive_asian_fam, &quot;fam_files/qc_alive_asian_fam&quot;, row.names = F, col.names = F, quote = F, sep = &#39;\\t&#39;) write.table(alive_england_fam, &quot;fam_files/qc_alive_england_fam&quot;, row.names = F, col.names = F, quote = F, sep = &#39;\\t&#39;) write.table(alive_scotland_fam, &quot;fam_files/qc_alive_scotland_fam&quot;, row.names = F, col.names = F, quote = F, sep = &#39;\\t&#39;) write.table(alive_wales_fam, &quot;fam_files/qc_alive_wales_fam&quot;, row.names = F, col.names = F, quote = F, sep = &#39;\\t&#39;) write.table(brit_fam, &quot;fam_files/brit_fam&quot;, row.names = F, col.names = F, quote = F, sep = &#39;\\t&#39;) To characterize the score distribution within each ethnic group I simply calculate the mean, standard deviation, and quantiles for the respective distribution. I also compute basic T-tests between each of the ancestral samples. With the relatively massive sample sizes the p-values are very low, so to get a better idea of the magnitude of the diffrences I keep the t-statistic as well. This might get fancier later on but this is what I have right now. The code showing these calculations is below: asian_fam &lt;- read.table(&quot;~/athena/ukbiobank/custom_qc/fam_files/asian_fam&quot;, stringsAsFactors=F) african_fam &lt;- read.table(&quot;~/athena/ukbiobank/custom_qc/fam_files/african_fam&quot;, stringsAsFactors=F) euro_fam &lt;- read.table(&quot;~/athena/ukbiobank/custom_qc/fam_files/euro_fam&quot;, stringsAsFactors=F) ethnic_scores &lt;- as.data.frame(ethnic_scores) ethnic_scores$ethnic &lt;- &quot;none&quot; ethnic_scores$ethnic[ethnic_eid %in% asian_fam[,1]] &lt;- &quot;asian&quot; ethnic_scores$ethnic[ethnic_eid %in% african_fam[,1]] &lt;- &quot;african&quot; ethnic_scores$ethnic[ethnic_eid %in% euro_fam[,1]] &lt;- &quot;euro&quot; brit_stats &lt;- matrix(0, nrow = ncol(ethnic_scores)-1, ncol = 13) euro_stats &lt;- matrix(0, nrow = ncol(ethnic_scores)-1, ncol = 13) african_stats &lt;- matrix(0, nrow = ncol(ethnic_scores)-1, ncol = 13) asian_stats &lt;- matrix(0, nrow = ncol(ethnic_scores)-1, ncol = 13) for(i in 1:(ncol(ethnic_scores)-1)){ brit_ind &lt;- which(colnames(brit_scores) == colnames(ethnic_scores)[1]) brit_stats[i,] &lt;- c(mean(brit_scores[,brit_ind]), sd(brit_scores[,brit_ind]), quantile(brit_scores[,brit_ind], 0:10/10)) sub_score &lt;- ethnic_scores[ethnic_scores$ethnic == &quot;euro&quot;,i] euro_stats[i,] &lt;- c(mean(sub_score), sd(sub_score), quantile(sub_score, 0:10/10)) sub_score &lt;- ethnic_scores[ethnic_scores$ethnic == &quot;african&quot;,i] african_stats[i,] &lt;- c(mean(sub_score), sd(sub_score), quantile(sub_score, 0:10/10)) sub_score &lt;- ethnic_scores[ethnic_scores$ethnic == &quot;asian&quot;,i] asian_stats[i,] &lt;- c(mean(sub_score), sd(sub_score), quantile(sub_score, 0:10/10)) } tvals &lt;- data.frame(matrix(NA, nrow = 6, ncol = ncol(ethnic_scores)-1)) for(i in 1:(ncol(ethnic_scores)-1)){ brit_ind &lt;- which(colnames(brit_scores) == colnames(ethnic_scores)[i]) euro &lt;- ethnic_scores[ethnic_scores$ethnic == &quot;euro&quot;,i] african &lt;- ethnic_scores[ethnic_scores$ethnic == &quot;african&quot;,i] asian &lt;- ethnic_scores[ethnic_scores$ethnic == &quot;asian&quot;,i] brit &lt;- brit_scores[,brit_ind] tvals[1,i] &lt;- t.test(brit, euro)$stat tvals[2,i] &lt;- t.test(brit, african)$stat tvals[3,i] &lt;- t.test(brit, asian)$stat tvals[4,i] &lt;- t.test(euro, asian)$stat tvals[5,i] &lt;- t.test(euro, african)$stat tvals[6,i] &lt;- t.test(african, asian)$stat } pvals &lt;- data.frame(matrix(NA, nrow = 6, ncol = ncol(ethnic_scores)-1)) for(i in 1:(ncol(ethnic_scores)-1)){ brit_ind &lt;- which(colnames(brit_scores) == colnames(ethnic_scores)[i]) euro &lt;- ethnic_scores[ethnic_scores$ethnic == &quot;euro&quot;,i] african &lt;- ethnic_scores[ethnic_scores$ethnic == &quot;african&quot;,i] asian &lt;- ethnic_scores[ethnic_scores$ethnic == &quot;asian&quot;,i] brit &lt;- brit_scores[,brit_ind] pvals[1,i] &lt;- t.test(brit, euro)$p.value pvals[2,i] &lt;- t.test(brit, african)$p.value pvals[3,i] &lt;- t.test(brit, asian)$p.value pvals[4,i] &lt;- t.test(euro, asian)$p.value pvals[5,i] &lt;- t.test(euro, african)$p.value pvals[6,i] &lt;- t.test(african, asian)$p.value } return_ethnic_groups &lt;- list(&quot;names_to_keep&quot; = colnames(ethnic_scores), &quot;brit_stats&quot; = brit_stats, &quot;euro_stats&quot; = euro_stats, &quot;african_stats&quot; = african_stats, &quot;asian_stats&quot; = asian_stats) 11.1.6 Comparison of Siblings This type of non-predictive evaluation was inspired by a paper entitled “Sibling validation of polygenic risk scores and complex trait prediction” by Lillen, Raben and Hsu. The main motivation with this idea is that polygenic risk scores may be easily confounded by family upbringing or other environmental effects. However, for siblings these effects are in the same direction and magnitude for both (or more) individuals, and therefore if one sibling gets a disease and the other does not we can conclude the environmental effects are likely not involved. Luckily for us the UK Biobank comes pre-packaged with person-to-person genetic relatedness files (just the same as the QC files). From this file we can extract siblings (I use the same definition as the paper I mentioned at the top). The statistic used to examine polygenic risk scores and siblings is called the concordance. It’s easily calculated by taking all pairs of siblings in which one has the phenotype and the other does not. If the PGS of phenotype positive individual is greater than the other that pair is given the value of 1, otherwise they are assigned 0. The mean value of the vector of siblings’0’s and 1’s is the concordance. The higher the value the better our polygenic risk score is. We can repeat this exercise for non-siblings and compare the two concordances to see if the environmental effects are significant. Computationally we complete this task with simple for loops and assigning the 1’s and 0’s to a vector. The exact code is shown below: ############################################## ########### SIBLING GROUPS ################### ############################################## #have to look at sibling pairs compared to non-sibling pairs sibs &lt;- read.table(&quot;../get_covars/covar_data/sibs&quot;, stringsAsFactors=F, header=T) use_pheno &lt;- unname(apply(brit_pheno[,1:4], 1, function(x) 1 %in% x)*1) df &lt;- data.frame(pheno = use_pheno, brit_covars) conc_ci &lt;- function(conc, ss, cases){ #see: The meaning and use of the area under a receiver operating characteristic (ROC) curve q1 &lt;- conc/(2-conc) q2 &lt;- (2*conc^2)/(1+conc) var &lt;- ((conc*(1-conc) + (cases-1)*(q1-conc^2))+(ss-cases-1)*(q2-conc^2))/(cases*(ss-cases)) c_logit &lt;- log(conc/(1-conc)) c_var_logit &lt;- var/((conc*(1-conc))^2) ci_hi &lt;- exp(c_logit+1.96*c_var_logit)/(1+exp(c_logit+1.96*c_var_logit)) ci_lo &lt;- exp(c_logit-1.96*c_var_logit)/(1+exp(c_logit-1.96*c_var_logit)) return(matrix(c(ci_hi, ci_lo))) } all_sib_conc &lt;- matrix(0, nrow = ncol(brit_scores), ncol = 6) for(i in 1:ncol(brit_scores)){ print(i) df$score &lt;- brit_scores[,i] pheno_sibs &lt;- sibs[sibs[,1] %in% df$eid[df$pheno == 1] | sibs[,2] %in% df$eid[df$pheno == 1],] pos_guess &lt;- rep(NA, nrow(pheno_sibs)) for(j in 1:nrow(pheno_sibs)){ sub_df &lt;- df[df$eid %in% pheno_sibs[j,],] if(nrow(sub_df) == 2){ if(sum(sub_df$pheno) == 1){ pos_guess[j] &lt;- (sub_df$score[sub_df$pheno == 1] &gt; sub_df$score[sub_df$pheno == 0])*1 } } } pos_guess &lt;- pos_guess[!is.na(pos_guess)] sib_conc &lt;- sum(pos_guess)/length(pos_guess) if(sib_conc == 1){ sib_conc_ci &lt;- c(1,1) } else { sib_conc_ci &lt;- as.numeric(conc_ci(sib_conc, length(pos_guess)*2, length(pos_guess))) } pos_guess &lt;- rep(NA, nrow(pheno_sibs)*10) for(j in 1:length(pos_guess)){ pos_guess[j] &lt;- (df$score[sample(which(df$pheno == 1), 1)] &gt; df$score[sample(which(df$pheno == 0), 1)])*1 } nonsib_conc &lt;- sum(pos_guess)/length(pos_guess) nonsib_conc_ci &lt;- as.numeric(conc_ci(nonsib_conc, length(pos_guess)*2, length(pos_guess))) all_sib_conc[i,] &lt;- c(sib_conc_ci[1], sib_conc, sib_conc_ci[2], nonsib_conc_ci[1], nonsib_conc, nonsib_conc_ci[2]) } rownames(all_sib_conc) &lt;- colnames(brit_scores) colnames(all_sib_conc) &lt;- c(&quot;sib_conc_ci_lo&quot;, &quot;sib_conc&quot;, &quot;sib_conc_ci_hi&quot;, &quot;nonsib_conc_ci_lo&quot;, &quot;nonsib_conc&quot;, &quot;nonsib_conc_ci_hi&quot;) return_sibling_groups &lt;- list(&quot;all_sib_conc&quot; = all_sib_conc) 11.1.7 Comparison of Age The analyses described below were completed a fair amount of time after the original. Therefore, the code is not completely connected, as it comes from a different script. However, all of the variables/objects that are set-up will fulfill the requirements of these code snippets. The first additional comparison of personal attributes involves age. In an attempt to make equal sized groups, similar to what was done in the sex comparison, an age was determined for each disease such that it split the cases (those with the disease) evenly. Also known as the median age of the cases. The following process followed very similarly to the sex difference analysis: splitting the sample into two and then fitting and assessing a model on each. The AUCs and the p-value representing the difference between the two underlying ROC curves are kept for analysis. The exact code is: ############################################## ########### AGE DIFFERENCE #################### ############################################## split_age &lt;- function(indf){ quota &lt;- sum(df$phen)/2 age_cut &lt;- min(indf$age) good_val &lt;- sum(indf$phen[indf$age &lt;= age_cut]) while(good_val &lt; quota){ age_cut &lt;- age_cut + 0.1 good_val &lt;- sum(indf$phen[indf$age &lt;= age_cut]) } indf$young_old &lt;- 0 indf$young_old[indf$age &gt; age_cut] &lt;- 1 return(indf) } diag_phen &lt;- apply(brit_pheno[,1:5], 1, function(x) any(x==1))*1 all_age_auc &lt;- matrix(0, nrow = ncol(brit_scores), ncol = 6) df &lt;- data.frame(phen = diag_phen, brit_covars) df &lt;- split_age(df) age_auc_p &lt;- rep(NA, ncol(brit_scores)) for(j in 1:ncol(brit_scores)){ df$score &lt;- brit_scores[,j] train_df &lt;- df[df$eid %in% brit_train[,1],] test_df &lt;- df[df$eid %in% brit_test[,1],] roc_holder &lt;- list() for(young in c(0,1)){ sub_train_df &lt;- train_df[train_df$young_old == young,] sub_test_df &lt;- test_df[test_df$young_old == young,] sub_train_df &lt;- sub_train_df[,-which(colnames(sub_train_df) == &quot;young_old&quot;)] sub_test_df &lt;- sub_test_df[,-which(colnames(sub_test_df) == &quot;young_old&quot;)] if(&quot;sex&quot; %in% colnames(sub_train_df)){ mod &lt;- glm(phen ~ age + sex + PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10 + score, data = sub_train_df, family = &quot;binomial&quot;) } else { mod &lt;- glm(phen ~ age + PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10 + score, data = sub_train_df, family = &quot;binomial&quot;) } test_roc &lt;- roc(sub_test_df$phen ~ predict(mod, sub_test_df)) all_age_auc[j,(young*3+1):(young*3+3)] &lt;- as.numeric(ci.auc(test_roc)) roc_holder[[young+1]] &lt;- test_roc } age_auc_p[j] &lt;- roc.test(roc_holder[[1]], roc_holder[[2]], paired = FALSE)$p.value } 11.1.8 Comparison of Many Other Following-up on the age difference tests, I later on realized that it would be easy to test and valuable to learn how the performance splits for many other personal attributes. The process of splitting the entire testing sample and then fitting and assessing the seperate groups was completed in a simple loop. The real work therefore was not the modeling but selecting the variables and choosing proper splits. I chose four variables that were measured to the individual and hopefully well represent the social and environmental status of the individual. I similarly chose four variables that are measured through the census, reflecting the wider living arrangement of the individual. Similar to the age analysis, each of these eight variables were split with the goal of creating two equally sized groups. Once these splits were made just as before the models were fit and assessed. The exact code is shown below: census_attrib &lt;- read.table(&quot;census_attrib.txt&quot;, stringsAsFactors=F, header=T) colnames(census_attrib) &lt;- c(&quot;eid&quot;, &quot;median_age&quot;, &quot;unemployed&quot;, &quot;very_good_health&quot;, &quot;pop_dens&quot;) survey_attrib &lt;- read.table(&quot;survey_attrib.txt&quot;, stringsAsFactors=F, header=T, sep=&quot;,&quot;) colnames(survey_attrib) &lt;- c(&quot;eid&quot;, &quot;time_address&quot;, &quot;number_in_house&quot;, &quot;income&quot;, &quot;age_edu&quot;) common_eid &lt;- intersect(df$eid[df$eid %in% survey_attrib$eid], df$eid[df$eid %in% census_attrib$eid]) brit_scores &lt;- brit_scores[df$eid %in% common_eid,] df &lt;- df[df$eid %in% common_eid,] survey_attrib &lt;- survey_attrib[survey_attrib$eid %in% common_eid,] census_attrib &lt;- census_attrib[census_attrib$eid %in% common_eid,] survey_attrib &lt;- survey_attrib[order(survey_attrib$eid)[rank(df$eid)],] census_attrib &lt;- census_attrib[order(census_attrib$eid)[rank(df$eid)],] df &lt;- cbind(df, survey_attrib[,-1], census_attrib[,-1]) #QC ################################# df$time_address[df$time_address &lt; 0 &amp; !is.na(df$time_address)] &lt;- NA df$bin_address &lt;- NA df$bin_address[df$time_address %in% 1:19 &amp; !is.na(df$time_address)] &lt;- 0 df$bin_address[df$time_address %in% 20:100 &amp; !is.na(df$time_address)] &lt;- 1 df$income[(df$income == -1 | df$income == -3) &amp; !is.na(df$income)] &lt;- NA df$bin_income &lt;- NA df$bin_income[df$income %in% c(1,2) &amp; !is.na(df$income)] &lt;- 0 df$bin_income[df$income %in% c(3,4,5) &amp; !is.na(df$income)] &lt;- 1 df$number_in_house[(df$number_in_house == -1 | df$number_in_house == -3) &amp; !is.na(df$number_in_house)] &lt;- NA df$number_in_house[df$number_in_house &gt; 25 &amp; !is.na(df$number_in_house)] &lt;- NA df$bin_in_house &lt;- NA df$bin_in_house[df$number_in_house %in% c(1,2) &amp; !is.na(df$number_in_house)] &lt;- 0 df$bin_in_house[df$number_in_house %in% 3:25 &amp; !is.na(df$number_in_house)] &lt;- 1 df$age_edu[df$age_edu &lt; 0 &amp; !is.na(df$age_edu)] &lt;- NA df$bin_edu &lt;- NA df$bin_edu[df$age_edu %in% 1:19 &amp; !is.na(df$age_edu)] &lt;- 0 df$bin_edu[df$age_edu %in% 20:40 &amp; !is.na(df$age_edu)] &lt;- 1 df$bin_census_age &lt;- NA df$bin_census_age[df$median_age &gt; median(df$median_age, na.rm = T) &amp; !is.na(df$median_age)] &lt;- 0 df$bin_census_age[df$median_age &lt;= median(df$median_age, na.rm = T) &amp; !is.na(df$median_age)] &lt;- 1 df$bin_census_employ &lt;- NA df$bin_census_employ[df$unemployed &gt; median(df$unemployed, na.rm = T) &amp; !is.na(df$unemployed)] &lt;- 0 df$bin_census_employ[df$unemployed &lt;= median(df$unemployed, na.rm = T) &amp; !is.na(df$unemployed)] &lt;- 1 df$bin_census_health &lt;- NA df$bin_census_health[df$very_good_health &gt; median(df$very_good_health, na.rm = T) &amp; !is.na(df$very_good_health)] &lt;- 0 df$bin_census_health[df$very_good_health &lt;= median(df$very_good_health, na.rm = T) &amp; !is.na(df$very_good_health)] &lt;- 1 df$bin_pop_den &lt;- NA df$bin_pop_den[df$pop_dens &gt; median(df$pop_dens, na.rm = T) &amp; !is.na(df$pop_dens)] &lt;- 0 df$bin_pop_den[df$pop_dens &lt;= median(df$pop_dens, na.rm = T) &amp; !is.na(df$pop_dens)] &lt;- 1 ##################################### vars_examine &lt;- grep(&quot;bin&quot;, colnames(df), value=T) for(j in 1:ncol(brit_scores)){ df$score &lt;- brit_scores[,j] train_df &lt;- df[df$eid %in% brit_train[,1],] test_df &lt;- df[df$eid %in% brit_test[,1],] for(var in vars_examine){ for(bin_val in 0:1){ sub_train_df &lt;- train_df[train_df[var] == bin_val,] sub_test_df &lt;- test_df[test_df[var]== bin_val,] if(&quot;sex&quot; %in% colnames(sub_train_df)){ mod &lt;- glm(phen ~ age + sex + PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10 + score, data = sub_train_df, family = &quot;binomial&quot;) } else { mod &lt;- glm(phen ~ age + PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10 + score, data = sub_train_df, family = &quot;binomial&quot;) } test_roc &lt;- roc(sub_test_df$phen ~ predict(mod, sub_test_df)) if(bin_val == 0){ save_roc &lt;- test_roc } else { all_pval[[which(vars_examine == var)]][j,1] &lt;- roc.test(save_roc, test_roc)$p.value } all_auc[[which(vars_examine == var)]][j,(bin_val*3+1):(bin_val*3+3)] &lt;- as.numeric(ci.auc(test_roc)) } } } 11.1.9 Plotting The plotting process, which takes place locally compared to on the academic computing system, can be easily broken down into once section for each analysis conducted. However, before any of these sections can be carried out I first have to read in the data. I also read in the extra data that describes all of the score and method names. This small amount of code is: library(stringr) library(ggplot2) library(cowplot) library(reshape2) library(viridis) library(pROC) theme_set(theme_cowplot()) author &lt;- &quot;Bentham&quot; all_authors &lt;- unique(str_split(list.files(&quot;nonpred_results/per_score/&quot;), fixed(&quot;.&quot;), simplify = T)[,1]) all_authors &lt;- all_authors[-which(all_authors == &quot;xie&quot;)] for(author in all_authors){ print(author) nonpred_res &lt;- readRDS(paste0(&quot;nonpred_results/per_score/&quot;, tolower(author), &quot;.res.many.RDS&quot;)) score_names &lt;- nonpred_res[[&quot;extra&quot;]][[1]] method_names &lt;- str_split(score_names, fixed(&quot;.&quot;), simplify = T)[,3] best_in_method &lt;- read.table(paste0(&quot;tune_results/&quot;, tolower(author), &quot;.methods.ss&quot;)) convert_names &lt;- function(x, the_dict = method_dict){ y &lt;- rep(NA, length(x)) for(i in 1:length(x)){ if(x[i] %in% the_dict[,1]){ y[i] &lt;- the_dict[the_dict[,1] == x[i], 2] } } return(y) } method_dict &lt;- read.table(&quot;local_info/method_names&quot;, stringsAsFactors = F) disease_dict &lt;- read.table(&quot;local_info/disease_names&quot;, stringsAsFactors = F, sep = &quot;\\t&quot;) neat_method_names &lt;- convert_names(method_names) neat_score_names &lt;- paste0(neat_method_names, &quot;-&quot;, str_split(score_names, fixed(&quot;.&quot;), simplify = T)[,2]) Onto the first section: plotting of score sizes. This is the most complex section as many sub-analyses are involved. First I extract the simple score length component and plot all scores in detail and compiled together by method. this detailed and compiled by method pattern continues for the effect of equal length and equal splits mean effect. These plots are crowded as colors and symbols are invovled, but there is no other way I can think of to include that much information nicely. Lastly, I use a color gradient to depict all 10 deciles of absolute effects. Seeing as this plot is not saying much new and is quite confusing with the gradient I have elected not to save it. ################################################################# ##################### SCORE SIZES ############################### ################################################################# #score sizes score_size_res &lt;- nonpred_res[[&quot;score_sizes&quot;]] all_len &lt;- score_size_res[[&quot;all_len&quot;]] plot_df &lt;- data.frame(neat_score_names, neat_method_names, all_len) plot_df$neat_score_names &lt;- factor(plot_df$neat_score_names, levels = plot_df$neat_score_names[order(plot_df$all_len)]) the_plot &lt;- ggplot(plot_df, aes(all_len, neat_score_names, color = neat_method_names)) + geom_point() + labs(x = &quot;Number SNPs in Score&quot;, y = &quot;Score Names&quot;, color = &quot;Method&quot;) + theme(axis.text.y = element_blank()) plot(the_plot) ggsave(paste0(&quot;meta_plots/&quot;, tolower(author), &quot;.nonpred.scoresize.1.png&quot;), the_plot, &quot;png&quot;, height=6, width=7) mean_vals &lt;- unlist(lapply(as.character(unique(plot_df$neat_method_names)), function(x) mean(plot_df$all_len[plot_df$neat_method_names == x]))) plot_df$neat_method_names &lt;- factor(plot_df$neat_method_names, levels = as.character(unique(plot_df$neat_method_names))[order(mean_vals)]) the_plot &lt;- ggplot(plot_df, aes(log10(all_len), neat_method_names)) + geom_boxplot() + geom_point() + labs(x = &quot;log10(Number SNPs in Score)&quot;, y = &quot;Method&quot;) + geom_hline(yintercept = 1:length(unique(plot_df$neat_method_names)) + 0.5, color = &quot;grey80&quot;) plot(the_plot) ggsave(paste0(&quot;meta_plots/&quot;, tolower(author), &quot;.nonpred.scoresize.2.png&quot;), the_plot, &quot;png&quot;, height=6, width=7) saveRDS(plot_df, paste0(&quot;nonpred_results/derived_from_per_score/&quot;, author, &quot;.score.len.RDS&quot;)) ### #Equal Splits Mean score_equal_splits_mean &lt;- data.frame(score_size_res[[&quot;all_equal_splits_mean&quot;]]) score_equal_splits_mean &lt;- score_equal_splits_mean/rowSums(score_equal_splits_mean) colnames(score_equal_splits_mean) &lt;- c(&quot;Q1&quot;, &quot;Q2&quot;, &quot;Q3&quot;, &quot;Q4&quot;) score_equal_splits_mean$method &lt;- neat_method_names score_equal_splits_mean$score &lt;- neat_score_names save_labels &lt;- score_equal_splits_mean$score[order(score_equal_splits_mean$Q1)] score_equal_splits_mean &lt;- melt(score_equal_splits_mean, id.vars = c(&quot;method&quot;, &quot;score&quot;)) score_equal_splits_mean$score &lt;- factor(score_equal_splits_mean$score, levels = save_labels) the_plot &lt;- ggplot(score_equal_splits_mean, aes(value, score, shape = variable, color = method)) + geom_point() + labs(x = &quot;Proportion of Mean Effect&quot;, y = &quot;Score&quot;, color = &quot;Quartile of\\nAbs. Effect&quot;) + theme(axis.text.y = element_blank()) plot(the_plot) ggsave(paste0(&quot;meta_plots/&quot;, tolower(author), &quot;.nonpred.scoremean.1.png&quot;), the_plot, &quot;png&quot;, height=6, width=7) saveRDS(score_equal_splits_mean, paste0(&quot;nonpred_results/derived_from_per_score/&quot;, author, &quot;.score.mean_quant.RDS&quot;)) the_plot &lt;- ggplot(score_equal_splits_mean, aes(value, method, color = variable)) + geom_boxplot() + labs(x = &quot;Proportion of Mean Effect&quot;, y = &quot;Method&quot;, color = &quot;Quartile&quot;) + geom_hline(yintercept = 1:length(unique(score_equal_splits_mean$method)) + 0.5, color = &quot;grey80&quot;) plot(the_plot) ggsave(paste0(&quot;meta_plots/&quot;, tolower(author), &quot;.nonpred.scoremean.2.png&quot;), the_plot, &quot;png&quot;, height=6, width=7) ### #Equal Splits Len score_equal_splits_len &lt;- data.frame(score_size_res[[&quot;all_equal_splits_len&quot;]]) score_equal_splits_len &lt;- score_equal_splits_len/rowSums(score_equal_splits_len) colnames(score_equal_splits_len) &lt;- c(&quot;Q1&quot;, &quot;Q2&quot;, &quot;Q3&quot;, &quot;Q4&quot;) score_equal_splits_len$method &lt;- neat_method_names score_equal_splits_len$score &lt;- neat_score_names save_labels &lt;- score_equal_splits_len$score[order(score_equal_splits_len$Q1)] score_equal_splits_len &lt;- melt(score_equal_splits_len, id.vars = c(&quot;method&quot;, &quot;score&quot;)) score_equal_splits_len$score &lt;- factor(score_equal_splits_len$score, levels = save_labels) the_plot &lt;- ggplot(score_equal_splits_len, aes(value, score, shape = variable, color = method)) + geom_point() + labs(x = &quot;Proportion of Length&quot;, y = &quot;Score&quot;, color = &quot;Quartile of\\nAbs. Effect&quot;) + theme(axis.text.y = element_blank()) plot(the_plot) ggsave(paste0(&quot;meta_plots/&quot;, tolower(author), &quot;.nonpred.scoresplit.1.png&quot;), the_plot, &quot;png&quot;, height=6, width=7) saveRDS(score_equal_splits_len, paste0(&quot;nonpred_results/derived_from_per_score/&quot;, author, &quot;.score.len_quant.RDS&quot;)) the_plot &lt;- ggplot(score_equal_splits_len, aes(value, method, color = variable)) + geom_boxplot() + labs(x = &quot;Proportion of Length&quot;, y = &quot;Method&quot;, color = &quot;Quartile&quot;) + geom_hline(yintercept = 1:length(unique(score_equal_splits_len$method)) + 0.5, color = &quot;grey80&quot;) plot(the_plot) ggsave(paste0(&quot;meta_plots/&quot;, tolower(author), &quot;.nonpred.scoresplit.2.png&quot;), the_plot, &quot;png&quot;, height=6, width=7) ### #Quantiles score_quantiles &lt;- data.frame(score_size_res[[&quot;all_quantiles&quot;]]) score_quantiles &lt;- score_quantiles/rowSums(score_quantiles) colnames(score_quantiles) &lt;- paste0(&quot;Q.&quot;, 1:10) score_quantiles$method &lt;- neat_method_names score_quantiles$score &lt;- neat_score_names score_quantiles$names &lt;- score_names save_labels &lt;- score_quantiles$names[order(score_quantiles$Q.1)] score_quantiles &lt;- melt(score_quantiles, id.vars = c(&quot;method&quot;, &quot;score&quot;, &quot;names&quot;)) score_quantiles$names &lt;- factor(score_quantiles$names, levels = save_labels) score_quantiles$Q &lt;- as.numeric(str_split(score_quantiles$variable, fixed(&quot;.&quot;), simplify = T)[,2]) the_plot &lt;- ggplot(score_quantiles, aes(value, names, color = Q)) + geom_point() + scale_y_discrete(labels = neat_method_names) + labs(x = &quot;Proportion of Abs. Effect&quot;, y = &quot;Method&quot;, color = &quot;Quantile&quot;) + theme(axis.text=element_text(size=8)) + scale_color_viridis() plot(the_plot) Then the output plots look like: Figure 11.1: Example plot of the score sizes Figure 11.2: Another example plot of the score sizes Figure 11.3: Example plot of the score means Figure 11.4: Another example plot of the score means Figure 11.5: Example plot of the equal score splits by effect Figure 11.6: Example plot of the equal score splits by length The next section: phenotype method. First I make a quick refrence plot of the number of cases for each method and phenotype. Next I show the AUC for each method, colored by the disease through both a series of boxplots and a heatmap. Showing the individual score detail seemed impossible/not useful so I did not attempt it, and rather grouped the scores together in the case of the boxplot and only kept the best AUC for each method in the case of the heatmap. ################################################################# ##################### PHENO DEFS ############################### ################################################################# pheno_def_res &lt;- nonpred_res[[&quot;pheno_defs&quot;]] #Cases pheno_def_size &lt;- as.data.frame(pheno_def_res[[&quot;total_phens&quot;]]) colnames(pheno_def_size) &lt;- &quot;size&quot; pheno_def_size$method &lt;- c(&quot;ICD&quot;, &quot;Self\\nReported&quot;, &quot;ICD or\\nSelf Rep.&quot;, &quot;Any&quot;, &quot;Double\\nReported&quot;) pheno_def_size$method &lt;- factor(pheno_def_size$method, levels = pheno_def_size$method[order(pheno_def_size$size)]) the_plot &lt;- ggplot(pheno_def_size, aes(size, method)) + geom_point() + labs(x = &quot;Cases&quot;, y = &quot;Phenotyping Method&quot;) saveRDS(pheno_def_size, paste0(&quot;nonpred_results/derived_from_per_score/&quot;, author, &quot;.pheno_def.len.RDS&quot;)) plot(the_plot) ggsave(paste0(&quot;meta_plots/&quot;, tolower(author), &quot;.nonpred.phenodefs.1.png&quot;), the_plot, &quot;png&quot;, height=6, width=7) #AUC pheno_def_auc &lt;- as.data.frame(pheno_def_res[[&quot;all_phen_auc&quot;]]) pheno_def_auc &lt;- pheno_def_auc[,seq(2,14,3)] colnames(pheno_def_auc) &lt;- c(&quot;ICD&quot;, &quot;Self\\nReported&quot;, &quot;ICD or\\nSelf Rep.&quot;, &quot;Any&quot;, &quot;Double\\nReported&quot;) pheno_def_auc$score &lt;- neat_score_names pheno_def_auc$method &lt;- neat_method_names # keep_score_names &lt;- rep(&quot;&quot;, length(unique(neat_method_names))) # for(m in unique(neat_method_names)){ # keep_score_names[which(unique(neat_method_names) == m)] &lt;- pheno_def_auc$score[pheno_def_auc$method == m][ # which.max(pheno_def_auc$`ICD or\\nSelf Rep.`[pheno_def_auc$method == m])] # } temp_save &lt;- data.frame(pheno_def_auc) pheno_def_auc &lt;- melt(pheno_def_auc, id.vars = c(&quot;score&quot;, &quot;method&quot;)) mean_vals &lt;- unlist(lapply(unique(pheno_def_auc$method), function(x) mean(pheno_def_auc$value[pheno_def_auc$method == x &amp; pheno_def_auc$variable == &quot;ICD or\\nSelf Rep.&quot;]))) pheno_def_auc$method &lt;- factor(pheno_def_auc$method, levels = unique(pheno_def_auc$method)[order(mean_vals)]) the_plot &lt;- ggplot(pheno_def_auc, aes(value, method, color = variable)) + geom_boxplot() + labs(x = &quot;AUC&quot;, y = &quot;Method&quot;, color = &quot;Phenotyping\\nMethod&quot;) + geom_hline(yintercept = 1:length(unique(pheno_def_auc$method)) + 0.5, color = &quot;grey80&quot;) plot(the_plot) ggsave(paste0(&quot;meta_plots/&quot;, tolower(author), &quot;.nonpred.phenodefs.2.png&quot;), the_plot, &quot;png&quot;, height=6, width=7) pheno_def_auc &lt;- temp_save[score_names %in% best_in_method[,1],] pheno_def_auc &lt;- melt(pheno_def_auc, id.vars = c(&quot;score&quot;, &quot;method&quot;)) the_plot &lt;- ggplot(pheno_def_auc, aes(variable, method, fill = value)) + geom_raster() + scale_fill_viridis() + labs(x = &quot;Phenotyping Method&quot;, y = &quot;Method&quot;, fill = &quot;AUC&quot;) + theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) plot(the_plot) ggsave(paste0(&quot;meta_plots/&quot;, tolower(author), &quot;.nonpred.phenodefs.3.png&quot;), the_plot, &quot;png&quot;, height=6, width=7) saveRDS(pheno_def_auc, paste0(&quot;nonpred_results/derived_from_per_score/&quot;, author, &quot;.pheno_def.auc.RDS&quot;)) Figure 11.7: Example plot showing the number of cases by each method Figure 11.8: Example plot of the performance of each method (for all scores) by phenotype method Figure 11.9: Example plot of the performance of each method (for the best score) by phenotype method The next section: sex diffreences. Almost identical to the previous section I do not attempt to show every score and instead group the scores for each method in a series of boxplots, or look at just the best score for each method, however this time plotting the AUC with CIs for male and female. ################################################################# ##################### SEX DIFF ############################### ################################################################# if(!is.null(nonpred_res[[&quot;sex_split&quot;]][[1]])){ sex_res &lt;- as.data.frame(nonpred_res[[&quot;sex_split&quot;]][[1]]) # keep_score_names &lt;- rep(&quot;&quot;, length(unique(neat_method_names))) # for(m in unique(neat_method_names)){ # keep_score_names[which(unique(neat_method_names) == m)] &lt;- # neat_score_names[neat_method_names == m][which.max(sex_res[neat_method_names == m,2])] # } colnames(sex_res) &lt;- c(&quot;female_lo&quot;, &quot;female_auc&quot;, &quot;female_hi&quot;, &quot;male_lo&quot;, &quot;male_auc&quot;, &quot;male_hi&quot;) sex_res$score_name &lt;- neat_score_names sex_res$methods_name &lt;- neat_method_names temp_save &lt;- data.frame(sex_res) plot_df &lt;- melt(sex_res, id.vars = c(&quot;score_name&quot;, &quot;methods_name&quot;)) plot_df &lt;- plot_df[plot_df$variable %in% c(&quot;female_auc&quot;, &quot;male_auc&quot;),] mean_vals &lt;- unlist(lapply(unique(plot_df$methods_name), function(x) mean(plot_df$value[plot_df$methods_name == x]))) plot_df$methods_name &lt;- factor(plot_df$methods_name, levels = unique(plot_df$methods_name)[order(mean_vals)]) the_plot &lt;- ggplot(plot_df, aes(value, methods_name, color = variable)) + geom_boxplot() + labs(x = &quot;AUC&quot;, y = &quot;Methods&quot;, color = &quot;Sex&quot;) + scale_color_discrete(labels = c(&quot;Female&quot;, &quot;Male&quot;)) + geom_hline(yintercept = 1:length(unique(plot_df$methods_name)) + 0.5, color = &quot;grey80&quot;) plot(the_plot) ggsave(paste0(&quot;meta_plots/&quot;, tolower(author), &quot;.nonpred.sexdiff.1.png&quot;), the_plot, &quot;png&quot;, height=6, width=7) plot_df &lt;- temp_save plot_df &lt;- sex_res[,c(1:3,7,8)] colnames(plot_df) &lt;- c(&quot;male_lo&quot;, &quot;male_auc&quot;, &quot;male_hi&quot;, &quot;score_name&quot;, &quot;methods_name&quot;) plot_df &lt;- rbind(plot_df, temp_save[,4:8]) plot_df$sex &lt;- c(rep(&quot;female&quot;, nrow(sex_res)), rep(&quot;male&quot;, nrow(sex_res))) plot_df &lt;- plot_df[score_names %in% best_in_method[,1],] plot_df$sex &lt;- str_to_title(plot_df$sex) plot_df$methods_name &lt;- factor(plot_df$methods_name, levels = plot_df$methods_name[plot_df$sex == &quot;Male&quot;][order(plot_df$male_auc[plot_df$sex == &quot;Male&quot;])]) the_plot &lt;- ggplot(plot_df, aes(male_auc, methods_name, color = sex)) + geom_point(position = position_jitterdodge(jitter.width = 0, dodge.width = 0.5)) + geom_errorbarh(position = position_jitterdodge(jitter.width = 0, dodge.width = 0.5), aes(xmin = male_lo, xmax = male_hi, height = 0)) + geom_hline(yintercept = 1:length(unique(plot_df$methods_name)) + 0.5, color = &quot;grey80&quot;) + labs(x = &quot;AUC&quot;, color = &quot;Sex&quot;, y = &quot;Methods&quot;) plot(the_plot) ggsave(paste0(&quot;meta_plots/&quot;, tolower(author), &quot;.nonpred.sexdiff.2.png&quot;), the_plot, &quot;png&quot;, height=6, width=7) saveRDS(plot_df, paste0(&quot;nonpred_results/derived_from_per_score/&quot;, author, &quot;.sex.auc.RDS&quot;)) } Figure 11.10: Example plot of the performance of each method (for all scores) by sex Figure 11.11: Example plot of the performance of each method (for the best score) by sex The next section: comparison of ethnic groups. By default this comparison is only looking at the best score for each method. I found trying to depict each of the quantiles to be unwieldy and instead look at just the mean and SD of each score in each racial group. The only plot I make is that exact information through a series of dots and error bars. ################################################################# ##################### ETHNICITY ############################### ################################################################# ethnic_res &lt;- nonpred_res[[&quot;new_ethnic&quot;]] all_dist &lt;- list() all_param &lt;- list() i &lt;- 1 k &lt;- 1 for(ethnic in c(&quot;brit_stats&quot;, &quot;euro_stats&quot;, &quot;african_stats&quot;, &quot;asian_stats&quot;)){ for(j in 1:nrow(ethnic_res[[ethnic]])){ all_dist[[i]] &lt;- data.frame(score = rnorm(1000, mean = ethnic_res[[ethnic]][j,1], sd = ethnic_res[[ethnic]][j,2])) all_dist[[i]]$ethnic &lt;- ethnic all_dist[[i]]$name &lt;- ethnic_res[[&quot;names_to_keep&quot;]][j] i &lt;- i + 1 } all_param[[k]] &lt;- data.frame(ethnic_res[[ethnic]][,1:2]) colnames(all_param[[k]]) &lt;- c(&quot;mean&quot;, &quot;sd&quot;) all_param[[k]]$ethnic &lt;- ethnic all_param[[k]]$name &lt;- ethnic_res[[&quot;names_to_keep&quot;]][1:nrow(all_param[[k]])] k &lt;- k + 1 } all_dist &lt;- do.call(&quot;rbind&quot;, all_dist) #can create normal distribution looking things from here all_param &lt;- do.call(&quot;rbind&quot;, all_param) all_param$method &lt;- convert_names(str_split(all_param$name, fixed(&quot;.&quot;), simplify = T)[,3]) for_convert &lt;- cbind(c(&quot;brit_stats&quot;, &quot;euro_stats&quot;, &quot;african_stats&quot;, &quot;asian_stats&quot;), c(&quot;British&quot;, &quot;European&quot;, &quot;African&quot;, &quot;Asian&quot;)) all_param$ethnic &lt;- convert_names(all_param$ethnic, for_convert) all_param$method &lt;- factor(all_param$method, levels = all_param$method[all_param$ethnic == &quot;African&quot;][order(all_param$mean[all_param$ethnic == &quot;African&quot;])]) the_plot &lt;- ggplot(all_param, aes(method, mean, color = ethnic)) + geom_point(position=position_dodge(width = 0.9)) + coord_flip() + geom_errorbar(position=position_dodge(width = 0.9), aes(ymin = mean-sd, ymax = mean+sd), width = 0.2) + labs(y = &quot;Score&quot;, x = &quot;Method&quot;, color = &quot;Ethnicity&quot;) + geom_vline(xintercept = 1:length(unique(all_param$method)) + 0.5, color = &quot;grey80&quot;) plot(the_plot) ggsave(paste0(&quot;meta_plots/&quot;, tolower(author), &quot;.nonpred.ethnic.1.png&quot;), the_plot, &quot;png&quot;, height=6, width=7) saveRDS(all_param, paste0(&quot;nonpred_results/derived_from_per_score/&quot;, author, &quot;.ethnic.plot.RDS&quot;)) ethnic_stat &lt;- ethnic_res[[&quot;stat_test&quot;]] keep1 &lt;- ethnic_stat$comp1 keep2 &lt;- ethnic_stat$comp2 colnames(ethnic_stat) &lt;- c(ethnic_res[[&quot;names_to_keep&quot;]][-length(ethnic_res[[&quot;names_to_keep&quot;]])], &quot;eth1&quot;, &quot;eth2&quot;) saveRDS(ethnic_stat, paste0(&quot;nonpred_results/derived_from_per_score/&quot;, author, &quot;.ethnic.tstat.RDS&quot;)) ethnic_stat &lt;- as.data.frame(ethnic_res[[&quot;pval_test&quot;]]) ethnic_stat$comp1 &lt;- keep1 ethnic_stat$comp2 &lt;- keep2 colnames(ethnic_stat) &lt;- c(ethnic_res[[&quot;names_to_keep&quot;]][-length(ethnic_res[[&quot;names_to_keep&quot;]])], &quot;eth1&quot;, &quot;eth2&quot;) saveRDS(ethnic_stat, paste0(&quot;nonpred_results/derived_from_per_score/&quot;, author, &quot;.ethnic.pval.RDS&quot;)) Figure 11.12: Example plot of the best scores’ mean and standard deviation for each method stratified by the ethnicities The next section: sibling comparison. While it would be easy to follow the pattern of previous plots and depict all statistics together in a boxplot for each method, and a single best statistic for each method (the statistic here is concordance), I do not know how to say for sure what is the best in this case. Would best be based on sibling, non-sibling, both? Seeing as the method should be able to not favor one sibling group over all parameters I hope to be safe in only picking showing the box plot in this situation. ################################################################# ##################### SIBLING ############################### ################################################################# sibs_res &lt;- as.data.frame(nonpred_res[[&quot;sibs&quot;]][[1]]) sibs_res$method &lt;- convert_names(str_split(rownames(sibs_res), fixed(&quot;.&quot;), simplify = T)[,3]) sibs_res_sib &lt;- sibs_res[,c(1:3,7)] colnames(sibs_res_sib) &lt;- c(&quot;lo&quot;, &quot;conc&quot;, &quot;hi&quot;, &quot;method&quot;) sibs_res_sib$type &lt;- &quot;Sibling&quot; sibs_res_non &lt;- sibs_res[,c(4:7)] colnames(sibs_res_non) &lt;- c(&quot;lo&quot;, &quot;conc&quot;, &quot;hi&quot;, &quot;method&quot;) sibs_res_non$type &lt;- &quot;Non-Sib&quot; sibs_res &lt;- rbind(sibs_res_sib, sibs_res_non) mean_vals &lt;- unlist(lapply(unique(sibs_res$method), function(x) mean(sibs_res$conc[sibs_res$method == x]))) sibs_res$method &lt;- factor(sibs_res$method, levels = unique(sibs_res$method)[order(mean_vals)]) the_plot &lt;- ggplot(sibs_res, aes(conc, method, color = type)) + geom_boxplot() + labs(x = &quot;Concordance&quot;, y = &quot;Method&quot;, color = &quot;Comparison&quot;) + geom_hline(yintercept = 1:length(unique(sibs_res$method)) + 0.5, color = &quot;grey80&quot;) plot(the_plot) ggsave(paste0(&quot;meta_plots/&quot;, tolower(author), &quot;.nonpred.sibs.1.png&quot;), the_plot, &quot;png&quot;, height=6, width=7) saveRDS(sibs_res, paste0(&quot;nonpred_results/derived_from_per_score/&quot;, author, &quot;.sibs_res.plot.RDS&quot;)) Figure 11.13: Example plot of the concordance for both sibling and non-sibling pairs for the best score for each method The next section: age difference. The data being depicted here is very similar to the sex difference analysis. Therefore, the code and the plots themselves are very similar, and do not require much expounding. ################################################################# ##################### AGE DIFF ############################### ################################################################# age_res &lt;- as.data.frame(nonpred_res[[&quot;age_diff&quot;]]) colnames(age_res) &lt;- c(&quot;young_lo&quot;, &quot;young_auc&quot;, &quot;young_hi&quot;, &quot;old_lo&quot;, &quot;old_auc&quot;, &quot;old_hi&quot;) age_res$score_name &lt;- neat_score_names age_res$methods_name &lt;- neat_method_names temp_save &lt;- data.frame(age_res) plot_df &lt;- melt(age_res, id.vars = c(&quot;score_name&quot;, &quot;methods_name&quot;)) plot_df &lt;- plot_df[plot_df$variable %in% c(&quot;young_auc&quot;, &quot;old_auc&quot;),] mean_vals &lt;- unlist(lapply(unique(plot_df$methods_name), function(x) mean(plot_df$value[plot_df$methods_name == x]))) plot_df$methods_name &lt;- factor(plot_df$methods_name, levels = unique(plot_df$methods_name)[order(mean_vals)]) the_plot &lt;- ggplot(plot_df, aes(value, methods_name, color = variable)) + geom_boxplot() + labs(x = &quot;AUC&quot;, y = &quot;Methods&quot;, color = &quot;Age\\nGroup&quot;) + scale_color_discrete(labels = c(&quot;Young&quot;, &quot;Old&quot;)) + geom_hline(yintercept = 1:length(unique(plot_df$methods_name)) + 0.5, color = &quot;grey80&quot;) plot(the_plot) ggsave(paste0(&quot;meta_plots/&quot;, tolower(author), &quot;.nonpred.agediff.1.png&quot;), the_plot, &quot;png&quot;, height=6, width=7) plot_df &lt;- temp_save plot_df &lt;- age_res[,c(1:3,7,8)] colnames(plot_df) &lt;- c(&quot;old_lo&quot;, &quot;old_auc&quot;, &quot;old_hi&quot;, &quot;score_name&quot;, &quot;methods_name&quot;) plot_df &lt;- rbind(plot_df, temp_save[,4:8]) plot_df$sex &lt;- c(rep(&quot;young&quot;, nrow(age_res)), rep(&quot;old&quot;, nrow(age_res))) plot_df &lt;- plot_df[score_names %in% best_in_method[,1],] plot_df$sex &lt;- str_to_title(plot_df$sex) plot_df$methods_name &lt;- factor(plot_df$methods_name, levels = plot_df$methods_name[plot_df$sex == &quot;Old&quot;][order(plot_df$old_auc[plot_df$sex == &quot;Old&quot;])]) the_plot &lt;- ggplot(plot_df, aes(old_auc, methods_name, color = sex)) + geom_point(position = position_jitterdodge(jitter.width = 0, dodge.width = 0.5)) + geom_errorbarh(position = position_jitterdodge(jitter.width = 0, dodge.width = 0.5), aes(xmin = old_lo, xmax = old_hi, height = 0)) + geom_hline(yintercept = 1:length(unique(plot_df$methods_name)) + 0.5, color = &quot;grey80&quot;) + labs(x = &quot;AUC&quot;, color = &quot;Age\\nGroup&quot;, y = &quot;Methods&quot;) plot(the_plot) ggsave(paste0(&quot;meta_plots/&quot;, tolower(author), &quot;.nonpred.agediff.2.png&quot;), the_plot, &quot;png&quot;, height=6, width=7) saveRDS(plot_df, paste0(&quot;nonpred_results/derived_from_per_score/&quot;, author, &quot;.agediff.auc.RDS&quot;)) Figure 11.14: Example plot of the AUCs split by Age The final section: many other personal attributed. Once again the plots and data are very similar, they are shown below for completness. ################################################################# ##################### MANY OTHER AUC ############################### ################################################################# vars_examined &lt;- c(&quot;Time at\\nCurrent\\nAddress&quot;, &quot;Income&quot;, &quot;Number in\\nHouse&quot;, &quot;Year of\\nEducation&quot;, &quot;Census:\\nMedian Age&quot;, &quot;Census:\\nUnemployment&quot;, &quot;Census:\\nHealth&quot;, &quot;Census:\\nPop. Den.&quot;) var_splits &lt;- list(c(&quot;1-20 years&quot;, &quot;20+ years&quot;), c(&quot;&lt; 40,000&quot;, &quot;&gt; 40,000&quot;), c(&quot;1-2 person&quot;, &quot;3+ persons&quot;), c(&quot;1-19 years&quot;, &quot;20+ years&quot;), c(&quot;&gt; 42 years&quot;, &quot;&lt; 42 years&quot;), c(&quot;&gt; 38&quot;, &quot;&lt; 38&quot;), c(&quot;&gt; 719&quot;, &quot;&lt; 719&quot;), c(&quot;&gt; 32 persons/hectare&quot;, &quot;&lt; 32 persons/hectare&quot;)) all_plot_df &lt;- list() all_pval_df &lt;- list() for(var_ind in 1:length(vars_examined)){ new_res &lt;- as.data.frame(nonpred_res[[&quot;many_auc&quot;]][[var_ind]]) new_pval &lt;- as.data.frame(nonpred_res[[&quot;many_pval&quot;]][[var_ind]]) colnames(new_res) &lt;- c(&quot;bottom_lo&quot;, &quot;bottom_auc&quot;, &quot;bottom_hi&quot;, &quot;upper_lo&quot;, &quot;upper_auc&quot;, &quot;upper_hi&quot;) new_res$score_name &lt;- neat_score_names new_res$methods_name &lt;- neat_method_names temp_save &lt;- data.frame(new_res) plot_df &lt;- melt(new_res, id.vars = c(&quot;score_name&quot;, &quot;methods_name&quot;)) plot_df &lt;- plot_df[plot_df$variable %in% c(&quot;bottom_auc&quot;, &quot;upper_auc&quot;),] mean_vals &lt;- unlist(lapply(unique(plot_df$methods_name), function(x) mean(plot_df$value[plot_df$methods_name == x]))) plot_df$methods_name &lt;- factor(plot_df$methods_name, levels = unique(plot_df$methods_name)[order(mean_vals)]) the_plot &lt;- ggplot(plot_df, aes(value, methods_name, color = variable)) + geom_boxplot() + labs(x = &quot;AUC&quot;, y = &quot;Methods&quot;, color = vars_examined[var_ind]) + scale_color_discrete(labels = var_splits[[var_ind]]) + geom_hline(yintercept = 1:length(unique(plot_df$methods_name)) + 0.5, color = &quot;grey80&quot;) plot(the_plot) ggsave(paste0(&quot;meta_plots/&quot;, tolower(author), &quot;.nonpred.many.&quot;, var_ind, &quot;.1.png&quot;), the_plot, &quot;png&quot;, height=6, width=7) plot_df &lt;- temp_save plot_df &lt;- new_res[,c(1:3,7,8)] colnames(plot_df) &lt;- c(&quot;upper_lo&quot;, &quot;upper_auc&quot;, &quot;upper_hi&quot;, &quot;score_name&quot;, &quot;methods_name&quot;) plot_df &lt;- rbind(plot_df, temp_save[,4:8]) plot_df$var &lt;- c(rep(&quot;young&quot;, nrow(new_res)), rep(&quot;old&quot;, nrow(new_res))) plot_df &lt;- plot_df[score_names %in% best_in_method[,1],] plot_df$methods_name &lt;- factor(plot_df$methods_name, levels = plot_df$methods_name[plot_df$var == &quot;old&quot;][order(plot_df$upper_auc[plot_df$var == &quot;old&quot;])]) the_plot &lt;- ggplot(plot_df, aes(upper_auc, methods_name, color = var)) + geom_point(position = position_jitterdodge(jitter.width = 0, dodge.width = 0.5)) + geom_errorbarh(position = position_jitterdodge(jitter.width = 0, dodge.width = 0.5), aes(xmin = upper_lo, xmax = upper_hi, height = 0)) + geom_hline(yintercept = 1:length(unique(plot_df$methods_name)) + 0.5, color = &quot;grey80&quot;) + labs(x = &quot;AUC&quot;, color = vars_examined[var_ind], y = &quot;Methods&quot;) + scale_color_discrete(labels = rev(var_splits[[var_ind]])) plot(the_plot) ggsave(paste0(&quot;meta_plots/&quot;, tolower(author), &quot;.nonpred.many.&quot;, var_ind, &quot;.2.png&quot;), the_plot, &quot;png&quot;, height=6, width=7) new_pval &lt;- new_pval[score_names %in% best_in_method[,1],] plot_df$pval &lt;- new_pval all_plot_df[[var_ind]] &lt;- plot_df #new_pval$score_name &lt;- neat_score_names #new_pval$methods_name &lt;- neat_method_names #new_pval &lt;- new_pval[score_names %in% best_in_method[,1],] #all_pval_df[[var_ind]] &lt;- new_pval } saveRDS(all_plot_df, paste0(&quot;nonpred_results/derived_from_per_score/&quot;, author, &quot;.many.auc.RDS&quot;)) Figure 11.15: Example plot of the many other personal attributes examined wherein the attribute was used to split the sample and models were fit and assessed on each half "],["to-do.html", "12 To Do 12.1 Across Score Evaluations", " 12 To Do 12.1 Across Score Evaluations Now I will describe evaluaitons that are only possible when comparing multiple scores to each other. 12.1.1 Set-Up The goal of the set-up is not to analyze the polygenic risk score itself (a value for every person), but rather a series of statistics/values that correspond to each score. Therefore, our final product from this set-up is a data frame with each row containing a score and each column containing a statistic/value. We can seperate these columns into different classes. The first class related to predictive performance, namely AUC and its CI. The second class involves the score but is nonpredictive, including number of SNPs, phenotype and parameter. The find class involves the phenotpe at large, including heritability, number of SNPs in the summary statistics, case/control information, and similar information. This large data frame is finally subset into smaller datasets that only contain the best score at-large or the best score for each type of method within a given phenotype. These data frames fuel the later analyses, We construct this all-important data frame by iterating rhough each author (or disease) under analysis. For each author we read in the AUC, the the case/control split of UKBB, and the number of SNPs each score. We assign each piece of data to an element of a list, and after the for loop combine everything together. Lastly, we read in meta-statistics generated back from when we refined the raw summary statistics. We then add the meta-statistics for each author to the corresponding row. The exact code is: #When all of the tuning is done want to go though and check that #If method performance is dependent on any factors (sample size, SNPs, etc.) #Do for one AUC for each author (the best) #Do this once for each method (the best method for each author) #Want to see if there is a correlation between method parameters and the meta stats #so collect all results (for all authors) then run a model #Also want to compare training to testing results #Will focus on AUC splitter &lt;- function(values, N){ inds = c(0, sapply(1:N, function(i) which.min(abs(cumsum(as.numeric(values)) - sum(as.numeric(values))/N*i)))) dif = diff(inds) if(any(dif == 0)){ dif[1] &lt;- dif[1] - sum(dif == 0) dif[dif == 0] &lt;- 1 } re = rep(1:length(dif), times = dif) return(split(values, re)) } options(warn = 2) list_all_auc &lt;- list() list_all_best_names &lt;- list() list_all_best_methods &lt;- list() list_ukb_cc &lt;- list() list_ukb_snps &lt;- list() list_ukb_beta_pdiff &lt;- list() list_ukb_len_pdiff &lt;- list() list_pval_6 &lt;- list() list_pval_8 &lt;- list() list_beta_len &lt;- list() list_beta_effect &lt;- list() i &lt;- 1 all_author &lt;- unlist(lapply(strsplit(list.files(&quot;../tune_score/tune_results/&quot;, &quot;res&quot;), &quot;_&quot;), function(x) x[1])) all_author &lt;- all_author[all_author != &quot;Xie&quot;] for(author in all_author){ all_res &lt;- readRDS(paste0(&quot;../tune_score/tune_results/&quot;, author, &quot;_res.RDS&quot;)) score_names &lt;- all_res[[&quot;score_names&quot;]] #GWAS Stats orig_gwas &lt;- read.table(paste0(&quot;~/athena/doc_score/raw_ss/&quot;, author, &quot;/clean_&quot;, tolower(author), &quot;.txt.gz&quot;), stringsAsFactors=F, header=T) four_len &lt;- unlist(lapply(splitter(sort(abs(orig_gwas$BETA[orig_gwas$P &lt; 0.05])), 4), function(x) length(x))) four_mean &lt;- unlist(lapply(splitter(sort(abs(orig_gwas$BETA[orig_gwas$P &lt; 0.05])), 4), function(x) mean(x))) list_beta_len[[i]] &lt;- (four_len[4] - four_len[1])/four_len[1] list_beta_effect[[i]] &lt;- (four_mean[4] - four_mean[1])/four_mean[1] list_pval_6[[i]] &lt;- sum(orig_gwas$P &lt; 1e-6) list_pval_8[[i]] &lt;- sum(orig_gwas$P &lt; 1e-8) #read in list_all_best_names[[i]] &lt;- read.table(paste0(&quot;../tune_score/tune_results/&quot;, tolower(author), &quot;.best.ss&quot;), stringsAsFactors=F) list_all_best_methods[[i]] &lt;- read.table(paste0(&quot;../tune_score/tune_results/&quot;, tolower(author), &quot;.methods.ss&quot;), stringsAsFactors=F) #get the mean_auc, and put in other info mean_auc &lt;- as.data.frame(Reduce(&quot;+&quot;, all_res[[&quot;auc&quot;]])/length(all_res[[&quot;auc&quot;]])) mean_auc$name &lt;- score_names mean_auc$method &lt;- unlist(lapply(strsplit(score_names, &quot;.&quot;, fixed=T), function(x) x[3])) mean_auc$author &lt;- author #get the case control in UKBB ukb_pheno &lt;- read.table(paste0(&quot;../construct_defs/pheno_defs/diag.&quot;, tolower(author) ,&quot;.txt.gz&quot;), stringsAsFactors=F) list_ukb_cc[[i]] &lt;- t(matrix(as.numeric(table(rowSums(ukb_pheno[,1:4]) &gt; 0))))[rep(1, nrow(mean_auc)),] #get the ukb snp lengths ukb_snps &lt;- rep(0, nrow(list_all_best_methods[[i]])) ukb_beta_pdiff &lt;- rep(0, nrow(list_all_best_methods[[i]])) ukb_len_pdiff &lt;- rep(0, nrow(list_all_best_methods[[i]])) for(sname in list_all_best_methods[[i]][,1]){ new_name &lt;- paste0(strsplit(sname, &quot;.&quot;, fixed = T)[[1]][3], &quot;.&quot;, strsplit(sname, &quot;.&quot;, fixed = T)[[1]][2], &quot;.ss.gz&quot;) get_files &lt;- list.files(paste0(&quot;../../mod_sets/&quot;, author, &quot;/&quot;), pattern = new_name) prs_sets &lt;- list() #temp_length &lt;- rep(0, length(get_files)) for(j in 1:length(get_files)){ #temp_length[j] &lt;- as.numeric(system(paste0(&quot;cat ../../mod_sets/&quot;, author, &quot;/&quot;, get_files[j], &quot; | wc -l&quot;), intern = TRUE)) prs_sets[[j]] &lt;- read.table(paste0(&quot;../../mod_sets/&quot;, author, &quot;/&quot;, get_files[j]), stringsAsFactors=F, header=T) colnames(prs_sets[[j]]) &lt;- paste0(rep(&quot;X&quot;, ncol(prs_sets[[j]])), 1:ncol(prs_sets[[j]])) } prs_sets &lt;- do.call(&quot;rbind&quot;, prs_sets) ukb_snps[which(list_all_best_methods[[i]][,1] == sname)] &lt;- nrow(prs_sets) if(length(unique(prs_sets[,7])) &gt; 10){ temp &lt;- unlist(lapply(splitter(sort(abs(sort(prs_sets[,7]))), 4), function(x) mean(x))) ukb_beta_pdiff[which(list_all_best_methods[[i]][,1] == sname)] &lt;- (temp[4] - temp[1])/temp[1] temp &lt;- unlist(lapply(splitter(sort(abs(sort(prs_sets[,7]))), 4), function(x) length(x))) ukb_len_pdiff[which(list_all_best_methods[[i]][,1] == sname)] &lt;- (temp[4] - temp[1])/temp[1] } else { ukb_beta_pdiff[which(list_all_best_methods[[i]][,1] == sname)] &lt;- NA ukb_len_pdiff[which(list_all_best_methods[[i]][,1] == sname)] &lt;- NA } } names(ukb_snps) &lt;- list_all_best_methods[[i]][,1] list_ukb_snps[[i]] &lt;- ukb_snps list_ukb_beta_pdiff[[i]] &lt;- ukb_beta_pdiff list_ukb_len_pdiff[[i]] &lt;- ukb_len_pdiff list_all_auc[[i]] &lt;- mean_auc i &lt;- i + 1 } for(i in 1:length(list_pval_6)){ list_pval_6[[i]] &lt;- rep(list_pval_6[[i]], length(list_ukb_snps[[i]])) list_pval_8[[i]] &lt;- rep(list_pval_8[[i]], length(list_ukb_snps[[i]])) list_beta_len[[i]] &lt;- rep(list_beta_len[[i]], length(list_ukb_snps[[i]])) list_beta_effect[[i]] &lt;- rep(list_beta_effect[[i]], length(list_ukb_snps[[i]])) } #add meta info to the all_auc all_auc &lt;- do.call(&quot;rbind&quot;, list_all_auc) all_auc &lt;- cbind(all_auc, do.call(&quot;rbind&quot;, list_ukb_cc)) method_best_names &lt;- unlist(list_all_best_methods) all_auc &lt;- all_auc[all_auc$name %in% method_best_names,] all_auc &lt;- cbind(all_auc, unlist(list_ukb_snps), unlist(list_ukb_beta_pdiff), unlist(list_ukb_len_pdiff), unlist(list_pval_6), unlist(list_pval_8), unlist(list_beta_len), unlist(list_beta_effect)) colnames(all_auc) &lt;- c(&quot;auc_lo&quot;, &quot;auc&quot;, &quot;auc_hi&quot;, &quot;name&quot;, &quot;method&quot;, &quot;author&quot;, &quot;uk_control&quot;, &quot;uk_case&quot;, &quot;uk_snps&quot;, &quot;uk_beta_pdiff&quot;, &quot;uk_len_pdiff&quot;, &quot;sig6_gwas_snps&quot;, &quot;sig8_gwas_snps&quot;, &quot;len_pdiff&quot;, &quot;effect_pdiff&quot;) meta_info &lt;- read.table(&quot;../../raw_ss/meta_stats&quot;, stringsAsFactors=F, sep=&quot;,&quot;, header=T) add_on &lt;- data.frame(matrix(0, nrow = nrow(all_auc), ncol = 10)) colnames(add_on) &lt;- colnames(meta_info)[-c(1,2)] for(author in unique(all_auc$author)){ add_on[all_auc$author == author,] &lt;- meta_info[meta_info$author == author,-c(1,2)] } all_auc &lt;- cbind(all_auc, add_on) all_auc$uk_cc_ratio &lt;- all_auc$uk_case/all_auc$uk_control all_auc$gwas_cc_ratio &lt;- all_auc$cases/all_auc$controls all_auc$uk_sampe_size &lt;- all_auc$uk_case + all_auc$uk_control #get the best names (absolute best, and best name for each method for each author) abs_best_names &lt;- unlist(lapply(list_all_best_names, function(x) x[3,2])) for(reg_name in c(&quot;uk_snps&quot;, &quot;uk_beta_pdiff&quot;, &quot;uk_len_pdiff&quot;, &quot;sig6_gwas_snps&quot;, &quot;sig8_gwas_snps&quot;, &quot;len_pdiff&quot;, &quot;effect_pdiff&quot;, &quot;sampe_size&quot;, &quot;snps&quot;, &quot;h2&quot;, &quot;uk_cc_ratio&quot;, &quot;gwas_cc_ratio&quot;)){ all_auc[reg_name] &lt;- (all_auc[reg_name] - min(all_auc[reg_name], na.rm=T))/(max(all_auc[reg_name],na.rm=T) - min(all_auc[reg_name],na.rm=T)) } #subset the all_auc all_auc$ancestry &lt;- as.numeric(as.factor(all_auc$ancestry)) all_auc &lt;- all_auc[,-which(colnames(all_auc) %in% c(&quot;ldsc_h2&quot;, &quot;ldsc_h2_se&quot;, &quot;hdl_h2&quot;, &quot;hdl_h2_se&quot;, &quot;hdl_h2se&quot;))] abs_best_auc &lt;- all_auc[all_auc$name %in% abs_best_names,] method_best_auc &lt;- all_auc 12.1.2 Meta Info Regressions With all of the data prepared we go go onto actually conducting the regressions. This section is actually relatively simple as all we have to do is call a lm command for each meta-statistic as the independent variable. To further break things down, the data I am pulling from in each regression is broken into the best method for each disease, or the best parameter-set for a given method for each disease. I am therefore able to estimate not only the overall impact of the number of initial SNPs (for example) on performance, but also whether this effect of number of SNPs only applies to the clumping method. After each regression I keep the regression coefficent, standard error, z-value and p-value. The exact code is: ############################################################ ################ META INFO REGRESSIONS ##################### ############################################################ meta_to_regress &lt;- c(&quot;uk_snps&quot;, &quot;uk_beta_pdiff&quot;, &quot;uk_len_pdiff&quot;, &quot;sig6_gwas_snps&quot;, &quot;sig8_gwas_snps&quot;, &quot;len_pdiff&quot;, &quot;effect_pdiff&quot;, &quot;sampe_size&quot;, &quot;ancestry&quot;, &quot;snps&quot;, &quot;h2&quot;, &quot;uk_cc_ratio&quot;, &quot;gwas_cc_ratio&quot;) abs_best_coefs &lt;- matrix(0, nrow = length(meta_to_regress), ncol = 4) all_poss_coefs &lt;- matrix(0, nrow = length(meta_to_regress), ncol = 4) method_best_coefs &lt;- rep(list(matrix(0, nrow = length(meta_to_regress), ncol = 4)), length(unique(method_best_auc$method))) for(i in 1:length(meta_to_regress)){ best_mod &lt;- lm(as.formula(paste0(&quot;auc ~ &quot;, meta_to_regress[i])), data = abs_best_auc) abs_best_coefs[i,] &lt;- summary(best_mod)$coefficients[2,] all_mod &lt;- lm(as.formula(paste0(&quot;auc ~ &quot;, meta_to_regress[i])), data = method_best_auc) all_poss_coefs[i,] &lt;- summary(all_mod)$coefficients[2,] for(m in unique(method_best_auc$method)){ method_mod &lt;- lm(as.formula(paste0(&quot;auc ~ &quot;, meta_to_regress[i])), data = method_best_auc[method_best_auc$method == m,]) method_best_coefs[[which(unique(method_best_auc$method) == m)]][i,] &lt;- summary(method_mod)$coefficients[2,] } } #should add regressions across all for best method, not just abs best auc meta_to_regress &lt;- meta_to_regress[-which(meta_to_regress == &quot;ancestry&quot;)] umethod &lt;- unique(method_best_auc$method) method_holder &lt;- data.frame(matrix(0, nrow = length(meta_to_regress)*2, ncol = length(umethod))) norm_auc &lt;- (method_best_auc$auc - min(method_best_auc$auc))/(max(method_best_auc$auc) - min(method_best_auc$auc)) k &lt;- 1 for(i in 1:length(meta_to_regress)){ j &lt;- which(colnames(method_best_auc) == meta_to_regress[i]) stat_val &lt;- (method_best_auc[,j] - min(method_best_auc[,j]))/(max(method_best_auc[,j]) - min(method_best_auc[,j])) temp &lt;- method_best_auc[order(norm_auc*stat_val,decreasing=T),] top_method &lt;- temp$method[!duplicated(temp$author)][1:10] for(m in unique(top_method)){ method_holder[k,which(umethod == m)] &lt;- sum(top_method == m) } stat_val &lt;- abs(stat_val - 1) temp &lt;- method_best_auc[order(norm_auc*stat_val,decreasing=T),] top_method &lt;- temp$method[!duplicated(temp$author)][1:10] for(m in unique(top_method)){ method_holder[k+1,which(umethod == m)] &lt;- sum(top_method == m) } k &lt;- k + 2 } colnames(method_holder) &lt;- umethod method_holder$stat &lt;- paste0(c(&quot;&quot;, &quot;rev_&quot;), rep(meta_to_regress, each=2)) 12.1.3 Testing and Training Comparison While not the main objective of determining whether meta-statistic effect the performance of polygenic risk scores, comparing training and testing accuracies is an important step to determine model overfitting. For example, if the AUC is very high in training compared to testing then we know the cross validation in the training step did not adequately lead to independent groups and perhaps the entire assessment of best scores could be corrputed. The process to check this problem is luckily quite simple. We simply read in the training and testing results, average over the folds in the training group, then take the difference between each. The exact code is shown below (including the final step of saving everything): ############################################################ ################ TRAIN AND TEST COMP ##################### ############################################################ ttcomp &lt;- matrix(0, nrow = length(all_author), ncol = 4) k &lt;- 1 for(author in all_author){ tune_res &lt;- readRDS(paste0(&quot;../tune_score/tune_results/&quot;, author, &quot;_res.RDS&quot;)) test_res &lt;- readRDS(paste0(&quot;../test_score/final_stats/&quot;, author, &quot;_res.RDS&quot;)) use_name &lt;- test_res[[&quot;score_names&quot;]] use_index &lt;- which(tune_res[[&quot;score_names&quot;]] == use_name) mean_conc &lt;- Reduce(&quot;+&quot;, tune_res[[&quot;conc&quot;]])/length(tune_res[[&quot;conc&quot;]]) mean_auc &lt;- Reduce(&quot;+&quot;, tune_res[[&quot;auc&quot;]])/length(tune_res[[&quot;auc&quot;]]) mean_or &lt;- Reduce(&quot;+&quot;, tune_res[[&quot;or&quot;]])/length(tune_res[[&quot;or&quot;]]) mean_survfit &lt;- matrix(0, nrow = length(tune_res[[&quot;survfit&quot;]][[1]]), ncol = 6) for(i in 1:length(tune_res[[&quot;survfit&quot;]])){ for(j in 1:length(tune_res[[&quot;score_names&quot;]])){ mean_survfit[j,] &lt;- mean_survfit[j,] + as.numeric(tune_res[[&quot;survfit&quot;]][[i]][[j]]) } } mean_survfit &lt;- mean_survfit/length(tune_res[[&quot;survfit&quot;]]) mean_conc &lt;- mean_conc[use_index,] mean_auc &lt;- mean_auc[use_index,] mean_or &lt;- mean_or[use_index,] mean_survfit &lt;- mean_survfit[use_index,] diff_conc &lt;- as.numeric(test_res[[&quot;conc&quot;]][1] - mean_conc[1]) diff_auc &lt;- test_res[[&quot;auc&quot;]][[2]][2] - mean_auc[2] diff_or &lt;- test_res[[&quot;or&quot;]][2,2] - mean_or[2] diff_survfit &lt;- test_res[[&quot;survfit&quot;]][nrow(test_res[[&quot;survfit&quot;]]),3] - mean_survfit[2] ttcomp[k,] &lt;- c(diff_conc, diff_survfit, diff_auc, diff_or) k &lt;- k + 1 } 12.1.4 Plotting The seperated plotting process is nicely, quite simple. We first create plots to show the effect and standard error of each regression (straightforward seemingly obvious thing to do). To spice thing up we also make two plots to show some of the more interesting correlations between the meta-statistics and significances therein. Lastly, we plot the training and testing differences through a simple dot plot. Seeing as everything is simple enough I will stop now and leave the code below: Figure 12.1: Heatmap of correlations between meta-statistics Figure 12.2: The significance of each meta-stat on the AUCs of each phenotype Figure 12.3: The effect of each meta-statistics on the AUCs of the best methods Figure 12.4: Comparison of training and testing AUCs And the code is: library(reshape2) library(ggplot2) library(cowplot) library(stringr) library(viridis) theme_set(theme_cowplot()) #just need to add method_holder method_dict &lt;- read.table(&quot;local_info/method_names&quot;, stringsAsFactors = F) author_dict &lt;- read.table(&quot;local_info/disease_names&quot;, stringsAsFactors = F, sep = &#39;\\t&#39;) convert_names &lt;- function(x, the_dict = author_dict){ y &lt;- rep(NA, length(x)) for(i in 1:length(x)){ if(x[i] %in% the_dict[,1]){ y[i] &lt;- the_dict[the_dict[,1] == x[i], 2] } } return(y) } #1 - authors #2 - the stats for best methods for each authors (setup data) #3 - the stats for the single best methods for each authors (setup data) meta_results &lt;- readRDS(&quot;nonpred_results/meta_results.RDS&quot;) #1 - authors #2 - methods_auc - all aucs for all diseases and best methods #3 - best_auc - all aucs for all disease and abs best #4 - method_coef - regression coefs stratified by best methods #5 - abs_coef - regression coefs between abs best #6 - all_coef - regression coefs between all coefs #7 - method_holder - count the number of times a method appears in the top #8 - ttcomp methods_setup &lt;- meta_results[[2]] #nothing to do unless want to plot the AUC vs the meta-stat for each method or author best_setup &lt;- meta_results[[3]] #can plot the AUC vs meta-stats temp &lt;- meta_results[[&quot;method_auc&quot;]] temp &lt;- temp[!duplicated(temp$author),] temp &lt;- temp[,c(6, 12:21, 23)] temp[,1] &lt;- convert_names(tolower(temp$author), author_dict) temp &lt;- temp[,-which(colnames(temp) == c(&quot;cases&quot;, &quot;controls&quot;))] for(i in 2:ncol(temp)){ temp[,i] &lt;- signif(temp[,i], 3) } write.table(temp, &quot;supp_tables/meta_reg_input.txt&quot;, col.names = T, row.names = F, sep = &quot;\\t&quot;, quote = F) df &lt;- read.table(&quot;supp_tables/med_endpoint_2.txt&quot;, stringsAsFactors = F, header = T, sep = &quot;\\t&quot;, fill = T) df[,1] &lt;- convert_names(tolower(df$author), author_dict) write.table(df, &quot;supp_tables/med_endpoint_3.txt&quot;, row.names = F, col.names = T, quote = F, sep = &quot;\\t&quot;) ###################################################################### # METHOD REGRESSIONS @ ###################################################################### reg_coefs &lt;- meta_results[[4]] #list elements is by methods, rows in the element is meta-stat #c(&quot;sampe_size&quot;, &quot;cases&quot;, &quot;cases/controls&quot;, &quot;snps&quot;, &quot;h2&quot;, &quot;uk_snps&quot;, &quot;uk_case/uk_control&quot;, &quot;uk_case&quot;) stat_names &lt;- c(&quot;uk_snps&quot;, &quot;uk_beta_pdiff&quot;, &quot;uk_len_pdiff&quot;, &quot;sig6_gwas_snps&quot;, &quot;sig8_gwas_snps&quot;, &quot;len_pdiff&quot;, &quot;effect_pdiff&quot;, &quot;sampe_size&quot;, &quot;ancestry&quot;, &quot;snps&quot;, &quot;h2&quot;, &quot;uk_cc_ratio&quot;, &quot;gwas_cc_ratio&quot;) plot_stat_names &lt;- c(&quot;PRS SNPs&quot;, &quot;PRS Dist. by Effect&quot;, &quot;PRS Dist. by Length&quot;, &quot;GWAS SNPs &lt; 1e-6&quot;, &quot;GWAS SNPs &lt; 1e-8&quot;, &quot;GWAS Dist. by Length&quot;, &quot;GWAS Dist. by Effect&quot;, &quot;GWAS Sample Size&quot;, &quot;GWAS Ancestry&quot;, &quot;GWAS SNPs&quot;, &quot;GWAS Heritability&quot;, &quot;UKBB CC Ratio&quot;, &quot;GWAS CC Ratio&quot;) plot_df &lt;- data.frame(matrix(0, nrow = length(reg_coefs), ncol = 4)) colnames(plot_df) &lt;- c(&quot;method&quot;, &quot;coef&quot;, &quot;se&quot;, &quot;p&quot;) poss_methods &lt;- convert_names(unique(methods_setup$method), method_dict) all_plot_df &lt;- list() for(stat_ind in 1:length(stat_names)){ for(i in 1:nrow(plot_df)){ plot_df[i,1] &lt;- poss_methods[i] plot_df[i,2:4] &lt;- reg_coefs[[i]][stat_ind,c(1:2, 4)] } plot_df$method &lt;- factor(plot_df$method, levels = plot_df$method[order(plot_df$coef)]) the_plot &lt;- ggplot(plot_df, aes(coef, method)) + geom_point() + geom_errorbar(aes(xmin = coef - se, xmax = coef + se, width = 0)) + geom_vline(xintercept = 0) + labs(x = &quot;Regression Coefficient&quot;, y = &quot;&quot;, caption = plot_stat_names[stat_ind]) plot(the_plot) ggsave(paste0(&quot;reg_plots/reg_coef.&quot;, tolower(gsub(&quot;/&quot;, &quot;&quot;, gsub(&quot; &quot;, &quot;_&quot;, stat_names)))[stat_ind], &quot;.png&quot;), the_plot + theme(plot.margin=unit(c(1,1,1,1), &quot;cm&quot;)), height = 6, width = 6) plot_df$stat_name &lt;- plot_stat_names[stat_ind] all_plot_df[[stat_ind]] &lt;- plot_df } plot_df &lt;- do.call(&quot;rbind&quot;, all_plot_df) the_plot &lt;- ggplot(plot_df, aes(coef, method)) + geom_point() + facet_grid(cols = vars(stat_name), scales = &quot;free&quot;) + geom_vline(xintercept = 0) + labs(x = &quot;Regression Coefficient&quot;, y = &quot;&quot;) + theme(strip.text.x = element_text(size = 8)) + scale_x_continuous(breaks = scales::pretty_breaks(n = 2)) plot(the_plot) ggsave(paste0(&quot;reg_plots/reg_coef.facet.png&quot;), the_plot, height = 6, width = 16) plot_df[plot_df$p &lt; 0.05,] mat_beta &lt;- matrix(0, nrow = length(reg_coefs), ncol = length(stat_names)) mat_pval &lt;- matrix(0, nrow = length(reg_coefs), ncol = length(stat_names)) for(i in 1:length(reg_coefs)){ for(j in 1:length(stat_names)){ mat_beta[i,j] &lt;- signif(reg_coefs[[i]][j,1], 3) mat_pval[i,j] &lt;- signif(reg_coefs[[i]][j,4], 3) } } mat_beta &lt;- cbind(poss_methods, data.frame(mat_beta)) mat_pval &lt;- cbind(poss_methods, data.frame(mat_pval)) colnames(mat_beta) &lt;- c(&quot;Method&quot;, plot_stat_names) colnames(mat_pval) &lt;- c(&quot;Method&quot;, plot_stat_names) write.table(mat_beta, &quot;supp_tables/meta_method.beta.txt&quot;, row.names = F, col.names = T, sep = &quot;\\t&quot;, quote = F) write.table(mat_pval, &quot;supp_tables/meta_method.pval.txt&quot;, row.names = F, col.names = T, sep = &quot;\\t&quot;, quote = F) write.table(t(mat_beta)[,c(1:8)], &quot;supp_tables/meta_method.beta.1.txt&quot;, row.names = T, col.names = F, sep = &quot;\\t&quot;, quote = F) write.table(t(mat_beta)[,c(1,9:15)], &quot;supp_tables/meta_method.beta.2.txt&quot;, row.names = T, col.names = F, sep = &quot;\\t&quot;, quote = F) write.table(t(mat_pval)[,c(1:8)], &quot;supp_tables/meta_method.pval.1.txt&quot;, row.names = T, col.names = F, sep = &quot;\\t&quot;, quote = F) write.table(t(mat_pval)[,c(1,9:15)], &quot;supp_tables/meta_method.pval.txt.2.txt&quot;, row.names = T, col.names = F, sep = &quot;\\t&quot;, quote = F) ###################################################################### # ABS BEST REGRESSIONS @ ###################################################################### reg_coefs &lt;- data.frame(meta_results[[5]]) colnames(reg_coefs) &lt;- c(&quot;coef&quot;, &quot;se&quot;, &quot;z&quot;, &quot;p&quot;) reg_coefs$stat_names &lt;- plot_stat_names reg_coefs$stat_names &lt;- factor(reg_coefs$stat_names, levels = reg_coefs$stat_names[order(reg_coefs$coef)]) reg_coefs &lt;- reg_coefs[abs(reg_coefs$coef) &lt; 5, ] the_plot &lt;- ggplot(reg_coefs, aes(coef, stat_names)) + geom_point() + geom_errorbar(aes(xmin = coef - se, xmax = coef + se, width = 0)) + geom_vline(xintercept = 0) + labs(x = &quot;Regression Coefficient&quot;, y = &quot;&quot;, caption = &quot;Among Best Scores&quot;) plot(the_plot) ggsave(paste0(&quot;reg_plots/reg_coef.best.png&quot;), the_plot, height = 6, width = 7) for_table &lt;- reg_coefs[,c(5,1,2,4)] for_table[,2] &lt;- signif(reg_coefs[,2], 3) for_table[,3] &lt;- signif(reg_coefs[,3], 3) for_table[,4] &lt;- signif(reg_coefs[,4], 3) write.table(for_table, &quot;supp_tables/meta_reg.disease.txt&quot;, row.names = F, col.names = T, sep = &quot;\\t&quot;, quote = F) #to double check df &lt;- meta_results[[&quot;method_auc&quot;]] best_names &lt;- readRDS(&quot;nonpred_results/best_names.RDS&quot;) df &lt;- df[df$name %in% best_names,] ###################################################################### # ALL AUC REGRESSIONS @ ###################################################################### reg_coefs &lt;- data.frame(meta_results[[6]]) colnames(reg_coefs) &lt;- c(&quot;coef&quot;, &quot;se&quot;, &quot;z&quot;, &quot;p&quot;) reg_coefs$stat_names &lt;- plot_stat_names reg_coefs$stat_names &lt;- factor(reg_coefs$stat_names, levels = reg_coefs$stat_names[order(reg_coefs$coef)]) reg_coefs &lt;- reg_coefs[abs(reg_coefs$coef) &lt; 5, ] the_plot &lt;- ggplot(reg_coefs, aes(coef, stat_names)) + geom_point() + geom_errorbar(aes(xmin = coef - se, xmax = coef + se, width = 0)) + geom_vline(xintercept = 0) + labs(x = &quot;Regression Coefficient&quot;, y = &quot;&quot;, caption = &quot;Among All Scores&quot;) plot(the_plot) ggsave(paste0(&quot;reg_plots/reg_coef.all.png&quot;), the_plot, height = 6, width = 7) for_table &lt;- reg_coefs[,c(5,1,2,4)] for_table[,2] &lt;- signif(reg_coefs[,2], 3) for_table[,3] &lt;- signif(reg_coefs[,3], 3) for_table[,4] &lt;- signif(reg_coefs[,4], 3) write.table(for_table, &quot;supp_tables/meta_reg.all.txt&quot;, row.names = F, col.names = T, sep = &quot;\\t&quot;, quote = F) ###################################################################### # METHODS BEST AT EXTREMES @ ###################################################################### exit() method_ex &lt;- data.frame(meta_results[[7]]) method_ex$stat &lt;- paste(rep(plot_stat_names[plot_stat_names != &quot;GWAS Ancestry&quot;], each = 2), c(&quot;&quot;, &quot;Rev.&quot;)) method_ex &lt;- melt(method_ex, id.vars = &quot;stat&quot;) method_ex$variable &lt;- convert_names(method_ex$variable, method_dict) the_plot &lt;- ggplot(method_ex, aes(variable, stat, fill = value)) + geom_raster() + scale_fill_viridis() + theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) + labs(x = &quot;&quot;, y = &quot;&quot;, fill = &quot;Times In\\nTop 10&quot;) plot(the_plot) ggsave(paste0(&quot;reg_plots/method_extreme.png&quot;), the_plot, height = 7, width = 7) method_ex &lt;- method_ex[grepl(&quot;GWAS&quot;, method_ex$stat),] method_ex$stat &lt;- unlist(lapply(strsplit(method_ex$stat, &quot;GWAS&quot;), function(x) x[2])) method_ex$stat &lt;- trimws(method_ex$stat) method_ex$stat[grepl(&quot;SNP&quot;, method_ex$stat)] &lt;- paste0(&quot;No. &quot;, method_ex$stat[grepl(&quot;SNP&quot;, method_ex$stat)]) the_plot &lt;- ggplot(method_ex, aes(variable, stat, fill = value)) + geom_raster() + scale_fill_viridis() + theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) + labs(x = &quot;&quot;, y = &quot;&quot;, fill = &quot;Times In\\nTop 10&quot;) plot(the_plot) ggsave(paste0(&quot;reg_plots/method_extreme_gwas.png&quot;), the_plot, height = 5, width = 7) to_save &lt;- data.frame(meta_results[[7]]) to_save$stat &lt;- paste(rep(plot_stat_names[plot_stat_names != &quot;GWAS Ancestry&quot;], each = 2), c(&quot;&quot;, &quot;Rev.&quot;)) colnames(to_save) &lt;- convert_names(colnames(to_save), method_dict) to_save &lt;- to_save[,c(ncol(to_save), 1:(ncol(to_save)-1))] write.table(to_save[,c(1,2:7)], &quot;supp_tables/method_extreme.1.txt&quot;, row.names = F, col.names = T, quote = F, sep = &quot;\\t&quot;) write.table(to_save[,c(1,8:16)], &quot;supp_tables/method_extreme.2.txt&quot;, row.names = F, col.names = T, quote = F, sep = &quot;\\t&quot;) write.table(to_save[,c(1,11:16)], &quot;supp_tables/method_extreme.3.txt&quot;, row.names = F, col.names = T, quote = F, sep = &quot;\\t&quot;) ###################################################################### # TRAIN/TEST @ ###################################################################### tt_df &lt;- data.frame(meta_results[[8]]) colnames(tt_df) &lt;- c(&quot;diff_conc&quot;, &quot;diff_survfit&quot;, &quot;diff_auc&quot;, &quot;diff_or&quot;) tt_df$disease &lt;- convert_names(meta_results[[1]]) mean(tt_df$diff_auc) sd(tt_df$diff_auc)/sqrt(nrow(tt_df)) melt_tt &lt;- melt(tt_df, id.vars = &quot;disease&quot;) melt_tt$variable &lt;- convert_names(melt_tt$variable, cbind(colnames(tt_df)[1:4], c(&quot;Conc.&quot;, &quot;Hazard&quot;, &quot;AUC&quot;, &quot;OR&quot;))) the_plot &lt;- ggplot(melt_tt, aes(x = value, y = disease, )) + geom_point() + facet_grid(cols = vars(variable), scales = &quot;free&quot;) + geom_vline(xintercept = 0) + scale_x_continuous(breaks = scales::pretty_breaks(n = 3)) + labs(x = &quot;Statistic Difference&quot;) plot(the_plot) ggsave(paste0(&quot;reg_plots/reg_coef.tt.png&quot;), the_plot, height = 6, width = 12) tt_df &lt;- data.frame(meta_results[[8]]) colnames(tt_df) &lt;- c(&quot;diff_conc&quot;, &quot;diff_survfit&quot;, &quot;diff_auc&quot;, &quot;diff_or&quot;) tt_df$disease &lt;- convert_names(meta_results[[1]]) tt_df &lt;- tt_df[,c(5,1,2,3,4)] tt_df[,2] &lt;- signif(tt_df[,2], 3) tt_df[,3] &lt;- signif(tt_df[,3], 3) tt_df[,4] &lt;- signif(tt_df[,4], 3) tt_df[,5] &lt;- signif(tt_df[,5], 3) write.table(tt_df, &quot;supp_tables/train-test.txt&quot;, row.names = F, col.names = T, sep = &quot;\\t&quot;, quote = F) "],["lifestyle-and-medications.html", "13 Lifestyle and Medications 13.1 Lifestyle Modifcations 13.2 Medications", " 13 Lifestyle and Medications 13.1 Lifestyle Modifcations 13.1.1 Getting the Statistics The larger project up this point has focused on either assessing the predictive accuracy of polygenic risk scores or chracterizing their component weights. In this section we add a third aim, translating polygenic risk scores to improved clinical outcomes (i.e. decrease number of disease events in a sample of individuals) via a direct clinical action. In other words the goal is to show the viability of a scenario in which you go to an appointment, doctor notcies you have a high PGS, and gives you X which thereby reduces your disease risk and effectively prevents some negative outcome. The first class of actions investigated that may provide this PGS-linked decrease in disease risk are lifestyle modifications. Numerous papers have previously shown that individuals with high PGS experience greater drops in disease risk from a lifestyle modification than individuals with a low PGS. To replicate these results, I first pulled a handful of lifestyle measurements that the UK Biobank has to offer. While there are many different ways to proceed next, specifically defining disease risk, I followed previous examples and the most interpretable approach and classified the PRS risk as a direct grouping of PRS, not the model predications, and defined risk as the simple rate of incidence, or the number of events that occured in this study’s time frame divided by the total number of individuals. The groups of the lifestyle measure was manually completed in attempt to make the same sub-sample sizes as the PGS (1st quintile, 2-4th quintiles, 5th quintile). An additional note to this process, that originally almost escaped me, the disease labels under analysis must be altered. Since we don’t want a disease diagnosis to occur that then changes the likelihood of lifestyle modifications, all individuals that were diagnosed before the time the lifestyles were measures, were omitted. All lifestyle and disease combinations were assessed in this 3x3 grouping process. Those that visually appeared to contain a distinct pattern of greater disease risk reduction in the high PGS compared to low PGS groups were classified as such. The code to compute the incidences, with the set-up identical to the primary testing script being removed for readability, is as follows: ########################################################### # INCIDENCE # ########################################################### #forget everything just do prs and raw incidence #3,7,9 #BASE ############################### get_se &lt;- function(x){ y &lt;- sum(x)/length(x) sqrt((y*(1-y))/length(x)) } get_arr_se &lt;- function(x,y){ a &lt;- sum(x) b &lt;- sum(y) n1 &lt;- length(x) n2 &lt;- length(y) se &lt;- sqrt( ((a/n1)*(1-a/n1))/n1 + ((b/n2)*(1-b/n2))/n2 ) return(se) } get_prev &lt;- function(x){sum(x)/length(x)} prs_groups &lt;- rep(1, nrow(df_test)) prs_groups[df_test$score &lt; quantile(df_test$score, 0.2)] &lt;- 0 prs_groups[df_test$score &gt; quantile(df_test$score, 0.8)] &lt;- 2 #do manual: cont_tables &lt;- rep(list(matrix(0, nrow = 3, ncol = 3)), ncol(mod_factors)) se_cont_tables &lt;- rep(list(matrix(0, nrow = 3, ncol = 3)), ncol(mod_factors)) quants_list &lt;- rep(list(NA), ncol(mod_factors)) se_arr &lt;- rep(list(c(NA, NA, NA)), ncol(mod_factors)) for(i in 1:ncol(mod_factors)){ use_mod &lt;- mod_factors[!is.na(mod_factors[,i]), i] quants &lt;- quantile(use_mod, c(0.2, 0.8)) if(i == 3 | i ==7){ quants &lt;- c(0,2) } else if (i==9){ quants &lt;- c(1,3) } quants_list[[i]] &lt;- quants use_pheno &lt;- df_test$pheno[!is.na(mod_factors[,i])] use_prs &lt;- prs_groups[!is.na(mod_factors[,i])] for(j in 0:2){ cont_tables[[i]][1,j+1] &lt;- get_prev(use_pheno[use_prs == j &amp; use_mod &lt;= quants[1]]) cont_tables[[i]][2,j+1] &lt;- get_prev(use_pheno[use_prs == j &amp; use_mod &gt; quants[1] &amp; use_mod &lt; quants[2]]) cont_tables[[i]][3,j+1] &lt;- get_prev(use_pheno[use_prs == j &amp; use_mod &gt;= quants[2]]) se_cont_tables[[i]][1,j+1] &lt;- get_se(use_pheno[use_prs == j &amp; use_mod &lt;= quants[1]]) se_cont_tables[[i]][2,j+1] &lt;- get_se(use_pheno[use_prs == j &amp; use_mod &gt; quants[1] &amp; use_mod &lt; quants[2]]) se_cont_tables[[i]][3,j+1] &lt;- get_se(use_pheno[use_prs == j &amp; use_mod &gt;= quants[2]]) se_arr[[i]][j+1] &lt;- get_arr_se(use_pheno[use_prs == j &amp; use_mod &lt;= quants[1]], use_pheno[use_prs == j &amp; use_mod &gt;= quants[2]]) } } names(cont_tables) &lt;- colnames(mod_factors) names(se_cont_tables) &lt;- colnames(mod_factors) names(quants_list) &lt;- colnames(mod_factors) final_obj &lt;- list(&quot;cont_tables&quot; = cont_tables, &quot;se_cont_tables&quot; = se_cont_tables, &quot;se_arr&quot; = se_arr) saveRDS(final_obj, paste0(&quot;final_stats/&quot;, author, &quot;_arr_data.RDS&quot;)) saveRDS(quants_list, &quot;mod_quants.RDS&quot;) I should now note two changes that are included in this code, but were not originally thought of. First, to reduce confounding, the polygenic risk score was adjusted for age, sex, and the top ten genetic principal components (all of the base covariates). The adjustment was specifically made by taking the residuals in a basic linear regression. Second, fisher’s exact test was carried out on each iteration and within each polygenic risk score group. In each test the predicted positive are those in the high risk lifestyle group and the not predicted positive are those in the low risk lifestyle group. The p-values and odds ratios from these tests were stored for later plotting. 13.1.2 Plotting Plots of the lifestyle modifications are fortunately very simple. The only plot form involves a grouped bar plot 3 bars in each. While I collect the data across all diseases (and even attempt to form a plot), nothing looks very good on this large (23 disease) scale, and so I do not make any overall plots. An example of the output plot is shown below. Figure 13.1: An example of the lifestyle modifications plot And the code for making this style of plot is below. I specifically am only plotting the lifestyle and disease combinations that are deemed significant. I have not found any statistically pure way to find significancy among three p-values and have therefore taken a tri-comparison. library(stringr) library(ggplot2) library(cowplot) library(pROC) library(reshape2) library(rmda) theme_set(theme_cowplot()) convert_names &lt;- function(x, the_dict = method_dict){ y &lt;- rep(NA, length(x)) for(i in 1:length(x)){ if(x[i] %in% the_dict[,1]){ y[i] &lt;- the_dict[the_dict[,1] == x[i], 2] } } return(y) } method_names &lt;- read.table(&quot;local_info/method_names&quot;, stringsAsFactors = F) disease_names &lt;- read.table(&quot;local_info/disease_names&quot;, stringsAsFactors = F, sep = &quot;\\t&quot;) method_dict &lt;- read.table(&quot;local_info/method_names&quot;, stringsAsFactors = F) author_dict &lt;- read.table(&quot;local_info/disease_names&quot;, stringsAsFactors = F, sep = &#39;\\t&#39;) mod_names &lt;- read.table(&quot;local_info/mod_splits.txt&quot;, stringsAsFactors = F, sep = &quot;\\t&quot;) all_authors &lt;- unique(str_split(list.files(&quot;test_results/&quot;, &quot;class_data&quot;), &quot;_&quot;, simplify = T)[,1]) if(any(all_authors == &quot;Xie&quot;)){ all_authors &lt;- all_authors[-which(all_authors == &quot;Xie&quot;)] } #plot_authors #plot_vars keep_factors &lt;- c(&quot;days_mod_activity&quot;, &quot;smoking_status&quot;, &quot;time_tv&quot;, &quot;vitamin_d&quot;, &quot;cook_veg&quot;, &quot;alcohol_intake&quot;, &quot;time_summer&quot;) all_mod_df &lt;- list() all_supp_df &lt;- list() best_supp_quals &lt;- list() big_count &lt;- 1 best_count &lt;- 1 for(author in all_authors){ res &lt;- readRDS(paste0(&quot;test_results/&quot;, author, &quot;.arr_data.RDS&quot;)) all_mod_factors &lt;- list() single_supp_df &lt;- list() #rows are mod risk factor #cols are prs risk group #for(i in which(names(res[[1]]) %in% keep_factors)){ for(i in 1:length(res[[1]])){ df &lt;- data.frame(res[[&quot;cont_tables&quot;]][[i]]) sedf &lt;- data.frame(res[[&quot;se_cont_tables&quot;]][[i]]) fishp &lt;- res[[&quot;fish_stat&quot;]][res[[&quot;fish_stat&quot;]]$mod_factor == names(res[[1]])[i],1] fishor &lt;- res[[&quot;fish_stat&quot;]][res[[&quot;fish_stat&quot;]]$mod_factor == names(res[[1]])[i],2] single_supp_df[[i]] &lt;- as.data.frame(t(as.data.frame(signif( c(as.numeric(res[[1]][[i]]), fishp, fishor), 3)))) colnames(single_supp_df[[i]]) &lt;- c(&quot;prs lo - mod lo&quot;, &quot;prs lo - mod inter&quot;, &quot;prs lo - mod hi&quot;, &quot;prs inter - mod lo&quot;, &quot;prs inter - mod inter&quot;, &quot;prs inter - mod hi&quot;, &quot;prs hi - mod lo&quot;, &quot;prs hi - mod inter&quot;, &quot;prs hi - mod hi&quot;, &quot;pval - lo&quot;, &quot;pval - inter&quot;, &quot;pval - hi&quot;, &quot;or - lo&quot;, &quot;or - inter&quot;, &quot;or - hi&quot;) single_supp_df[[i]]$mod_factor &lt;- names(res[[1]])[i] single_supp_df[[i]]$author &lt;- author colnames(df) &lt;- c(&quot;prs_lo&quot;, &quot;prs_inter&quot;, &quot;prs_hi&quot;) df &lt;- melt(df) df$mod_group &lt;- rep(as.character(mod_names[which(names(res[[1]])[i] == mod_names[,1]), 3:5]), 3) colnames(sedf) &lt;- c(&quot;prs_lo&quot;, &quot;prs_inter&quot;, &quot;prs_hi&quot;) sedf &lt;- melt(sedf) df$se &lt;- sedf$value df$mod_group &lt;- factor(df$mod_group, levels = mod_names[which(names(res[[1]])[i] == mod_names[,1]), 3:5]) mod_drop &lt;- df$value[seq(1,9,3)] - df$value[seq(3,9,3)] the_plot &lt;- ggplot(df, aes(variable, value, fill = mod_group)) + geom_bar(position = position_dodge(), stat=&quot;identity&quot;) + geom_errorbar(aes(ymin = value - se, ymax = value + se), position = position_dodge(0.9), width = 0) + labs (x = &quot;Polygenic Risk Score Group&quot;, y = &quot;Incidence Rate&quot;, caption = paste(&quot;P-Vals:&quot;, paste(as.character(signif(fishp, 3)), collapse = &quot;, &quot;))) + scale_x_discrete(labels = c(&quot;Low&quot;, &quot;Inter.&quot;, &quot;High&quot;)) + scale_fill_viridis_d(name = gsub(&quot;_&quot;, &quot;\\n&quot;, mod_names[which(names(res[[1]])[i] == mod_names[,1]),2])) #plot(the_plot) #ggsave(paste0(&quot;mod_factor_plots/&quot;, tolower(author), &quot;.&quot;, poss_eps[kk], &quot;.&quot;, mod_names[i,1], &quot;.png&quot;), # the_plot, &quot;png&quot;, height=5, width=6) if(all(fishp &lt; 0.05) | sum(fishp &lt; 0.005) == 2 | any(fishp[c(1,3)] &lt; 0.0005)){ if(abs(mod_drop[3]) &gt; abs(mod_drop[1])){ if(all(df$value &gt; 0)){ ggsave(paste0(&quot;great_mod_factor_plots/&quot;, tolower(author), &quot;.&quot;, names(res[[1]])[i], &quot;.png&quot;), the_plot, &quot;png&quot;, height=4.5, width=5) best_supp_quals[[best_count]] &lt;- c(author, names(res[[1]])[i]) best_count &lt;- best_count + 1 } } } all_mod_factors[[i]] &lt;- df all_mod_factors[[i]]$mod_factor &lt;- names(res[[&quot;cont_tables&quot;]])[i] all_mod_factors[[i]]$author &lt;- author } all_mod_df[[big_count]] &lt;- all_mod_factors all_supp_df[[big_count]] &lt;- single_supp_df big_count &lt;- big_count + 1 } redo_list &lt;- list() k &lt;- 1 for(i in 1:length(all_supp_df)){ for(j in 1:length(all_supp_df[[i]])){ if(!is.null(all_supp_df[[i]][[j]])){ redo_list[[k]] &lt;- all_supp_df[[i]][[j]] k &lt;- k + 1 } } } big_df &lt;- do.call(&quot;rbind&quot;, redo_list) keep_rows &lt;- do.call(&quot;rbind&quot;, best_supp_quals) best_df &lt;- big_df[paste0(big_df$author, &quot;_&quot;, big_df$mod_factor) %in% paste0(keep_rows[,1], &quot;_&quot;, keep_rows[,2]),] best_df$disease &lt;- convert_names(best_df$author, author_dict) best_df$mod_name &lt;- convert_names(best_df$mod_factor, mod_names) for(i in 1:9){ best_df[,i] &lt;- signif(best_df[,i], 2) } best_df &lt;- best_df[best_df$mod_factor != &quot;cook_veg&quot;,] best_df$mod_name &lt;- gsub(&quot;_&quot;, &quot; &quot;, best_df$mod_name) supp1 &lt;- best_df[,c(18, 19, 1:9)] supp2 &lt;- best_df[,c(18, 19, 10:15)] supp1$mod_name[supp1$mod_name == &quot;Pieces Fruit Eaten Per Day&quot;] &lt;- &quot;Fruit&quot; supp1$mod_name[supp1$mod_name == &quot;Hours per Day Watch TV&quot;] &lt;- &quot;TV&quot; supp1$mod_name[supp1$mod_name == &quot;Processed Meat Intake&quot;] &lt;- &quot;Meat&quot; supp1$mod_name[supp1$mod_name == &quot;Glasses of Water Per Day&quot;] &lt;- &quot;Water Intake&quot; supp1$mod_name[supp1$mod_name == &quot;Days Mod. Activity Per Week&quot;] &lt;- &quot;Mod. Activity&quot; supp1$mod_name[supp1$mod_name == &quot;Hours per Day Driving&quot;] &lt;- &quot;Driving&quot; supp1$mod_name[supp1$mod_name == &quot;Tbsp Raw Veg. Per Day&quot;] &lt;- &quot;Vegetable&quot; supp1$mod_name[supp1$mod_name == &quot;Alcohol Consumed&quot;] &lt;- &quot;Alcohol&quot; supp1$mod_name[supp1$mod_name == &quot;Min. Walked Per Day&quot;] &lt;- &quot;Min. Walked&quot; supp2$mod_name[supp2$mod_name == &quot;Pieces Fruit Eaten Per Day&quot;] &lt;- &quot;Fruit&quot; supp2$mod_name[supp2$mod_name == &quot;Hours per Day Watch TV&quot;] &lt;- &quot;TV&quot; supp2$mod_name[supp2$mod_name == &quot;Processed Meat Intake&quot;] &lt;- &quot;Meat&quot; supp2$mod_name[supp2$mod_name == &quot;Glasses of Water Per Day&quot;] &lt;- &quot;Water Intake&quot; supp2$mod_name[supp2$mod_name == &quot;Days Mod. Activity Per Week&quot;] &lt;- &quot;Mod. Activity&quot; supp2$mod_name[supp2$mod_name == &quot;Hours per Day Driving&quot;] &lt;- &quot;Driving&quot; supp2$mod_name[supp2$mod_name == &quot;Tbsp Raw Veg. Per Day&quot;] &lt;- &quot;Vegetable&quot; supp2$mod_name[supp2$mod_name == &quot;Alcohol Consumed&quot;] &lt;- &quot;Alcohol&quot; supp2$mod_name[supp2$mod_name == &quot;Min. Walked Per Day&quot;] &lt;- &quot;Min. Walked&quot; write.table(supp1, paste0(&quot;supp_tables/mod_factor.vals.txt&quot;), col.names = T, row.names = F, quote = F, sep = &quot;\\t&quot;) write.table(supp2, paste0(&quot;supp_tables/mod_factor.sigs.txt&quot;), col.names = T, row.names = F, quote = F, sep = &quot;\\t&quot;) # for(uval in unique(big_df$mod_factor)){ # small_df &lt;- big_df[big_df$mod_factor == uval,] # small_df &lt;- small_df[,-which(colnames(small_df) == &quot;mod_factor&quot;)] # small_df$author &lt;- convert_names(small_df$author, author_dict) # small_df &lt;- small_df[,c(10,1:9)] # new_df &lt;- as.data.frame(rbind(str_split(colnames(small_df), &quot;-&quot;, simplify = T)[,1], # str_split(colnames(small_df), &quot;-&quot;, simplify = T)[,2]), stringsAsFactors = F) # colnames(new_df) &lt;- colnames(small_df) # small_df &lt;- rbind(new_df, small_df) # write.table(small_df, paste0(&quot;supp_tables/mod_factor.&quot;, uval, &quot;.txt&quot;), col.names = F, row.names = F, quote = F, sep = &quot;\\t&quot;) # } 13.2 Medications 13.2.1 Set Up In truth, this entire section started out with the hopes of it being a much larger independent project. This fact can hopefully explain why the data is organized in a much more sophistacted manner than necessary. The underlying motivation has remained the same throughout however, determine whether the efficacy of a medication is affected by the polygenic risk score a person has. This is essentially the same premise of the lifestyle analysis, although with prescription data at various timepoints and various dosages the analysis gets a bit more complex. To start this analysis we need to define the sub-cohorts of people we want to analyze. While we could simply analyze whether a medication changes how likely you are to get a disease, more often than not that is not how a medication is designed. Rather, a medication is designed to reduce the negative outcomes of a disease once it is known and diagnosed. Therefore, several endpoints that do not just include disease onset were included. Under these analyses the sub-cohort contained only people that were diagnosed with a relavent illness, thereby setting up an artifical study that someone could create if they were going to go through the steps of getting an IRB, enrolling the relavent participants, following their outcomes and doing the analysis. The script used to get these endpoints is exactly the same as the one used to define the primary disease phenotypes, so I will not repeat it here. The endpoints under consideration and their definitions are as follows: x &lt;- read.table(&quot;/home/quenton/Academics/doc_score/med_scripts/all_endpoints&quot;, stringsAsFactors=F, sep=&quot;\\t&quot;, fill =T) print(x) ## V1 V2 V3 V4 ## 1 author endpt1 endpt2 endpt3 ## 2 Bentham dependence fatigue ## 3 Christophersen disese_onset stroke death_cardio ## 4 Demenais disese_onset ## 5 Dubois disese_onset ## 6 Gormley disese_onset ## 7 IMSGC disese_onset dependence fatigue ## 8 Kottgen disese_onset ## 9 Liu-1 disese_onset disease_of_intestine ## 10 Liu-2 disese_onset disease_of_intestine ## 11 Mahajan disese_onset diabetes_complication_2 death_diabetes ## 12 Malik disese_onset death_early ## 13 Michailidou disese_onset death_bc death_early ## 14 Namjou liver_failure death_liver death_early ## 15 Nikpay disese_onset myocardial_infarction heart_failure ## 16 Okada disese_onset ## 17 Onengut disese_onset diabetes_complication_1 death_diabetes ## 18 Phelan disese_onset death_oc death_early ## 19 Schumacher disese_onset death_pc death_early ## 20 Shah disese_onset death_cardio death_early ## 21 Wray disese_onset ## V5 V6 V7 ## 1 endpt4 endpt5 endpt6 ## 2 ## 3 death_early ## 4 ## 5 ## 6 ## 7 death_ms death_early ## 8 ## 9 ## 10 ## 11 death_early ## 12 ## 13 ## 14 ## 15 arrhythmia death_cardio death_early ## 16 ## 17 death_early ## 18 ## 19 ## 20 ## 21 x &lt;- read.table(&quot;/home/quenton/Academics/doc_score/med_scripts/endpoint_def&quot;, stringsAsFactors=F, sep=&quot;\\t&quot;, fill =T) print(x) ## V1 V2 V3 V4 V5 V6 ## 1 author name sex cancer noncancer icd9 ## 2 dependence dependence A &lt;NA&gt; &lt;NA&gt; V46 ## 3 fatigue fatigue A &lt;NA&gt; &lt;NA&gt; 7807 ## 4 disease_of_intestine disease_of_intestine A &lt;NA&gt; &lt;NA&gt; 560 ## 5 diabetes_complication_1 diabetes_complication_1 A &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 6 diabetes_complication_2 diabetes_complication_2 A &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 7 liver_failure liver_failure A &lt;NA&gt; &lt;NA&gt; 5739 ## 8 myocardial_infarction myocardial_infarction A &lt;NA&gt; &lt;NA&gt; 410 ## 9 arrhythmia arrhythmia A &lt;NA&gt; &lt;NA&gt; 426|427 ## V7 V8 V9 ## 1 icd10 opcs meds ## 2 R263|Z99 &lt;NA&gt; &lt;NA&gt; ## 3 R53 &lt;NA&gt; &lt;NA&gt; ## 4 K63 &lt;NA&gt; &lt;NA&gt; ## 5 E100|E101|E102|E103|E104|E105|E106|E107|E108 &lt;NA&gt; &lt;NA&gt; ## 6 E110|E111|E112|E113|E114|E115|E116|E117|E118|E119 &lt;NA&gt; &lt;NA&gt; ## 7 K72 &lt;NA&gt; &lt;NA&gt; ## 8 I21 &lt;NA&gt; &lt;NA&gt; ## 9 I44|I45|I47|I48|I49 &lt;NA&gt; &lt;NA&gt; Once the identities of the individuals in each sub-cohort are realized, we must find all of the medications that could effect the respective outcome. This step requires understanding how UK Biobank organized the medication data. A full description of the data is here: https://biobank.ndph.ox.ac.uk/showcase/showcase/docs/primary_care_data.pdf. In short, the prescriptions in general practices that are electronically linked to the UK Biobanked are compiled together. If a UK Biobank participant changed general practices and went to a non-linked practice then there would be an artifical gap in the data. The specific form of the prescription collected include the date, BNF code and the raw text of the prescription. In order to increase the number of medications that apply to a group and limit the problems of identifying the text of a medication name, the medications are grouped by BNF code. Moving ahead in the medication analysis, for each sub-cohort all possible medications (BNF codes) are gathered and simply counted. If there are more than 50 people who take a medication and reach the sub-cohort endpoint then the name of the medication is kept for later analysis. The exact code that carries out this sample sizing is below. The crux of it is that a sub-cohort is briefly assembled, those EIDs are used to subset all script data via fgrep on the command line, then the subset script is read beack into R and counted. There is a slightly different script for disease_onset and non-disease_onset. library(data.table) #This script is for generating the med info for the general onset of disease endpoint #author &lt;- &quot;christophersen&quot; author &lt;- tolower(commandArgs(trailingOnly=TRUE)) dates &lt;- read.table(paste0(&quot;~/athena/doc_score/analyze_score/construct_defs/pheno_defs/time.&quot;, author, &quot;.txt.gz&quot;), stringsAsFactors=F) for(i in 1:ncol(dates)){ if(i %in% c(1,2,6)){ dates[dates[,i] == &quot;__________&quot;, i] &lt;- &quot;2020-12-31&quot; dates[,i] &lt;- as.Date(dates[,i], &quot;%Y-%m-%d&quot;) } else { dates[dates[,i] == &quot;__________&quot;, i] &lt;- &quot;31/12/2020&quot; dates[,i] &lt;- as.Date(dates[,i], &quot;%d/%m/%Y&quot;) } } pheno_time &lt;- dates[,-ncol(dates)] eid &lt;- read.table(&quot;~/athena/doc_score/analyze_score/construct_defs/eid.csv&quot;, stringsAsFactors=F, header=T, nrows = nrow(pheno_time)) ##################################################### #PHENO GROUPS ####################################### check_inds &lt;- which(apply(pheno_time, 1, function(x) any(x != &quot;2020-12-31&quot;))) sub_pheno &lt;- apply(pheno_time[check_inds,], 1, min) sub_eid &lt;- eid[check_inds,] #get the eids and dates of people with disease write.table(sub_eid, &quot;meds_in_interval/good_eids&quot;, row.names = F, col.names = F, quote = F) system(&quot;zcat ~/athena/ukbiobank/gp/gp_scripts.txt.gz | fgrep -w -f meds_in_interval/good_eids &gt; meds_in_interval/sub_gp&quot;) if(file.info(&quot;meds_in_interval/sub_gp&quot;)$size &gt; 0){ #sub_gp &lt;- read.table(&quot;sub_gp&quot;, stringsAsFactors=F, sep = &#39;\\t&#39;, fill = T) sub_gp &lt;- as.data.frame(fread(&quot;meds_in_interval/sub_gp&quot;)) sub_gp[,3] &lt;- as.Date(sub_gp[,3], &quot;%d/%m/%Y&quot;) sub_gp &lt;- sub_gp[sub_gp[,3] &gt; as.Date(&quot;1999-01-01&quot;),] #add in the medications that occur before a given date #sub_eid are individuals who go on to get the disease all_good_meds &lt;- list() for(k in 1:length(sub_eid)){ if(sub_eid[k] %in% sub_gp[,1]){ #condition that meds are taken by eid and those meds were prescribed before date of diagnosis all_good_meds[[k]] &lt;- unique(substr(sub_gp[sub_gp[,1] == sub_eid[k] &amp; sub_gp[,3] &lt; sub_pheno[k],5], 1, 8)) } else { all_good_meds[[k]] &lt;- &quot;none&quot; } } #do the table to get amount of people on a medication final_meds &lt;- sort(table(unlist(all_good_meds)), decreasing=T) final_meds &lt;- final_meds[final_meds &gt; 50 &amp; names(final_meds) != &quot;none&quot; &amp; final_meds != &quot;&quot;] saveRDS(final_meds, paste0(&quot;meds_in_interval/&quot;, author, &quot;.disease_onset.RDS&quot;)) } system(&quot;rm meds_in_interval/sub_gp&quot;) #NOTE: All of the numbers are the number of people with med and either cases or cases then death Once the sub-cohort, endpoint and possible medications under analysis are all set it is time to actually do the analysis. The first step is set-up, which compiled the very simple survival data frame. There is a row for each individual with a start and end date, with a phenotype marker of endpoint or censor. The code is very similar to what has been used in previous testing sections but I will still include the code here: library(survival) library(pROC) library(epitools) args &lt;- commandArgs(trailingOnly=TRUE) author &lt;- args[1] endpoint &lt;- args[2] #author &lt;- &quot;Christophersen&quot; #endpoint &lt;- &quot;disease_onset&quot; #get scores all_scores &lt;- readRDS(paste0(&quot;~/athena/doc_score/do_score/final_scores/all_score.&quot;, tolower(author), &quot;.RDS&quot;)) all_eid &lt;- read.table(&quot;~/athena/doc_score/do_score/all_specs/for_eid.fam&quot;, stringsAsFactors=F) train_eid &lt;- read.table(paste0(&quot;~/athena/doc_score/qc/cv_files/train_eid.0.8.txt&quot;), stringsAsFactors=F) test_eid &lt;- read.table(paste0(&quot;~/athena/doc_score/qc/cv_files/test_eid.0.2.txt&quot;), stringsAsFactors=F) new_eid &lt;- rbind(train_eid, test_eid) all_scores &lt;- all_scores[all_eid[,1] %in% new_eid[,1],] eid &lt;- all_eid[all_eid[,1] %in% new_eid[,1],1] #Normalize the scores scores &lt;- all_scores[,grepl(tolower(author), colnames(all_scores))] scores &lt;- scores[,apply(scores, 2, function(x) length(unique(x)) &gt; 3)] scores &lt;- apply(scores, 2, function(x) (x-mean(x)) / (max(abs((x-mean(x)))) * 0.01) ) get_pheno &lt;- function(author, keep_score){ #Read in the phenotypes, order is: cancer sr, noncancer sr, icd9, icd10, oper, meds #selfasses date: 2018-11-22; hesin date: 21/01/2000 if( any(grepl(tolower(author), list.files(&quot;../endpoints/disease_endpoints/&quot;))) ){ dates &lt;- read.table(paste0(&quot;/home/kulmsc/athena/med_surv_study/endpoints/disease_endpoints/time.&quot;, tolower(author), &quot;.txt.gz&quot;), stringsAsFactors=F) } else if(grepl(&quot;death&quot;, author)){ dates &lt;- read.table(paste0(&quot;/home/kulmsc/athena/med_surv_study/endpoints/death_endpoints/time.&quot;, tolower(author), &quot;.txt.gz&quot;), stringsAsFactors=F) } else { if(author == &quot;heart_failure&quot;){ dates &lt;- read.table(paste0(&quot;/home/kulmsc/athena/med_surv_study/endpoints/disease_endpoints/time.shah.txt.gz&quot;), stringsAsFactors=F) } else if(author == &quot;stroke&quot;){ dates &lt;- read.table(paste0(&quot;/home/kulmsc/athena/med_surv_study/endpoints/disease_endpoints/time.malik.txt.gz&quot;), stringsAsFactors=F) } else { dates &lt;- read.table(paste0(&quot;/home/kulmsc/athena/med_surv_study/endpoints/other_endpoints/time.&quot;, tolower(author), &quot;.txt.gz&quot;), stringsAsFactors=F) } } for(i in 1:ncol(dates)){ if(any(grepl(&quot;-&quot;, dates[,i]))){ dates[dates[,i] == &quot;__________&quot;, i] &lt;- &quot;2020-12-31&quot; dates[,i] &lt;- as.Date(dates[,i], &quot;%Y-%m-%d&quot;) } else { dates[dates[,i] == &quot;__________&quot;, i] &lt;- &quot;31/12/2020&quot; dates[,i] &lt;- as.Date(dates[,i], &quot;%d/%m/%Y&quot;) } } dates &lt;- dates[,1:4] dates &lt;- apply(dates, 1, min) dates[dates == as.Date(&quot;2020-12-31&quot;)] &lt;- NA pheno &lt;- rep(0, length(dates)) pheno[!is.na(dates)] &lt;- 1 #Read in the eids used that are the same order as the pheno and dates, then subset the pheno and dates accordingly pheno_eids &lt;- read.table(&quot;~/athena/doc_score/analyze_score/construct_defs/eid.csv&quot;, header = T) pheno_eids &lt;- pheno_eids[order(pheno_eids[,1]),] pheno_eids &lt;- pheno_eids[-length(pheno_eids)] if(keep_score){ scores &lt;- scores[eid %in% pheno_eids,] } else { scores &lt;- NULL } eid &lt;- eid[eid %in% pheno_eids] dates &lt;- dates[pheno_eids %in% eid] pheno &lt;- pheno[pheno_eids %in% eid] pheno_eids &lt;- pheno_eids[pheno_eids %in% eid] dates &lt;- dates[order(pheno_eids)[rank(eid)]] pheno &lt;- pheno[order(pheno_eids)[rank(eid)]] return(list(dates, pheno, pheno_eids, scores)) } base_info &lt;- get_pheno(author, TRUE) if(endpoint != &quot;disease_onset&quot;){ end_info &lt;- get_pheno(endpoint, FALSE) } dates &lt;- base_info[[1]] pheno &lt;- base_info[[2]] eid &lt;- base_info[[3]] scores &lt;- base_info[[4]] #Read in the base covars covars &lt;- readRDS(&quot;~/athena/doc_score/analyze_score/get_covars/base_covars.RDS&quot;) covars &lt;- covars[covars[,1] %in% eid,] covars &lt;- covars[order(covars[,1])[rank(eid)],] #Set up survival analysis data frame #Artifically decide start date is 1999, that way all are even, if date is prior then remove it #The current maximum date possible is 31 May 2020 death &lt;- read.table(&quot;~/athena/ukbiobank/hesin/death.txt&quot;, stringsAsFactors=F, header = T) death[,5] &lt;- unlist(lapply(death[,5], function(x) paste0(strsplit(x, &quot;/&quot;)[[1]][3], &quot;-&quot;, strsplit(x, &quot;/&quot;)[[1]][2], &quot;-&quot;, strsplit(x, &quot;/&quot;)[[1]][1]))) death &lt;- death[!duplicated(death[,1]),] death &lt;- death[death[,1] %in% eid,] add_on &lt;- death[1,] add_on[5] &lt;- &quot;&quot; add_eid &lt;- eid[!(eid %in% death[,1])] add_on &lt;- add_on[rep(1, length(add_eid)),] add_on$eid &lt;- add_eid death &lt;- rbind(death, add_on) death &lt;- death[order(death[,1])[rank(eid)],] censor &lt;- read.table(&quot;~/athena/doc_score/analyze_score/get_covars/covar_data/censor_covars&quot;, stringsAsFactors=F, header = T, sep = &quot;,&quot;) censor &lt;- censor[censor[,1] %in% eid,] censor &lt;- censor[order(censor[,1])[rank(eid)],] #set up start and end dates start_date &lt;- rep(&quot;1999-01-01&quot;, length(eid)) end_date &lt;- rep(&quot;2020-05-31&quot;, length(eid)) end_date[censor[,2] != &quot;&quot;] &lt;- censor[censor[,2] != &quot;&quot;, 2] end_date[death[,5] != &quot;&quot;] &lt;- death[death[,5] != &quot;&quot;, 5] end_date[!is.na(dates)] &lt;- dates[!is.na(dates)] is_death_date &lt;- rep(0, nrow(scores)) is_death_date[death[,5] != &quot;&quot; &amp; pheno == 0] &lt;- 1 surv_df &lt;- data.frame(time = as.numeric(as.Date(end_date) - as.Date(start_date)), start_date, end_date, pheno, is_death_date, covars) if(endpoint != &quot;disease_onset&quot;){ surv_df &lt;- surv_df[surv_df$pheno == 1,] surv_df$start_date &lt;- surv_df$end_date surv_df$end_date &lt;- rep(&quot;2020-05-31&quot;, nrow(surv_df)) real_end_date &lt;- end_info[[1]][end_info[[3]] %in% surv_df$eid] real_eid &lt;- end_info[[3]][end_info[[3]] %in% surv_df$eid] surv_df$end_date[!is.na(real_end_date)] &lt;- real_end_date[!is.na(real_end_date)] surv_df$pheno &lt;- 0 surv_df$pheno[!is.na(real_end_date)] &lt;- 1 surv_df$time &lt;- as.numeric(as.Date(surv_df$end_date) - as.Date(surv_df$start_date)) } real_eid &lt;- eid[surv_df$time &gt; 0] scores &lt;- scores[surv_df$time &gt; 0,] surv_df &lt;- surv_df[surv_df$time &gt; 0,] author_defs &lt;- read.table(&quot;~/athena/doc_score/analyze_score/descript_defs/author_defs&quot;, stringsAsFactors=F, header=T) subset_sex &lt;- author_defs$sex[author_defs$author == author] if(subset_sex == &quot;F&quot;){ real_eid &lt;- real_eid[surv_df$sex == 0] scores &lt;- scores[surv_df$sex == 0,] surv_df &lt;- surv_df[surv_df$sex == 0,] } else if(subset_sex == &quot;M&quot;){ real_eid &lt;- real_eid[surv_df$sex == 1] scores &lt;- scores[surv_df$sex == 1,] surv_df &lt;- surv_df[surv_df$sex == 1,] } saveRDS(list(surv_df, scores, real_eid), paste0(&quot;surv_dfs/&quot;, author, &quot;.&quot;, endpoint, &quot;.RDS&quot;)) 13.2.2 Meications Next, we need to add the medications into the survival dataframe. Going back to project origins, I include far more detailed information than necessary, specifically, the level of dosage for each segment of time. For example, each prescription is translated to a dosage and pill value. So “Dosulepin 25mg capsules 168 caps” would be coverted to 25mg level of dosage and 168 pills. A somewhat involved “natural language processing” set of rules will try to match a number next to the mg/ml/g unit to dosage and pills/caps/etc. to the pills. A very rough estimate of 1 pill per day is used, and the dosage is held constant for each day (although in some cases the dosage is divided across all days if the text states). This data is then organized to a row in the survival dataframe, with the starting date of the prescription used as reference. After going across all prescriptions for an individual, a final check is made to make sure prescriptions do not overlap and extend beyond the end of the larger dataframe. The entire code that pulls out the dosage and pills, then correctly determines how to organize the survival dataframe with this prescription data follows: library(stringr) library(data.table) options(warn=2) #MUST EDIT THIS!!!!!!!!!!! #author &lt;- &quot;Christophersen&quot; #endpoint &lt;- &quot;death_early&quot; args &lt;- commandArgs(trailingOnly=TRUE) author &lt;- args[1] endpoint &lt;- args[2] get_first &lt;- function(drug_string){ #val &lt;- strsplit(drug_string, &quot; &quot;)[[1]][1] if(grepl(&quot;[0-9]&quot;, substr(drug_string, 1, 1))){ val &lt;- unlist(regmatches(drug_string, gregexpr(&#39;\\\\(?[0-9,.]+&#39;, drug_string)))[1] val &lt;- gsub(&quot;(&quot;, &quot;&quot;, val, fixed=T) } else { val &lt;- NA } return(val) } get_val &lt;- function(drug_string, split_by){ if(grepl(split_by, drug_string)){ drug_string &lt;- trimws(str_split(drug_string[1], split_by)[[1]][1]) if(grepl(&quot;[0-9]&quot;, substr(drug_string, nchar(drug_string), nchar(drug_string)))){ drug_num &lt;- tail(unlist(regmatches(drug_string, gregexpr(&#39;\\\\(?[0-9,.]+&#39;, drug_string))), 1) #works for everything but commas if(grepl(&quot;,&quot;, drug_num)){ drug_num &lt;- tail(strsplit(drug_num, &quot;,&quot;)[[1]], 1) } drug_num &lt;- gsub(&quot;(&quot;, &quot;&quot;, drug_num, fixed=T) } else { drug_num &lt;- NA } } else { drug_num &lt;- NA } return(drug_num) } surv_objs &lt;- readRDS(paste0(&quot;surv_dfs/&quot;, author, &quot;.&quot;, endpoint, &quot;.RDS&quot;)) script_eids &lt;- read.table(&quot;script_eids&quot;, stringsAsFactors=F) surv_scores &lt;- surv_objs[[2]][surv_objs[[1]]$eid %in% script_eids[,1],] #I do not include scores in this process, in part to keep things smaller surv_df &lt;- surv_objs[[1]][surv_objs[[1]]$eid %in% script_eids[,1],] surv_df$start_time &lt;- 0 surv_df$med_amt &lt;- 0 surv_df$start_date &lt;- as.Date(surv_df$start_date) surv_df$end_date &lt;- as.Date(surv_df$end_date) surv_df$dosage &lt;- 0 surv_df &lt;- surv_df[surv_df$start_date &lt; surv_df$end_date,] if(file.exists(paste0(&quot;../endpoints/meds_in_interval/&quot;, tolower(author), &quot;.&quot;, tolower(endpoint), &quot;.RDS&quot;))){ med_vec &lt;- readRDS(paste0(&quot;../endpoints/meds_in_interval/&quot;, tolower(author), &quot;.&quot;, tolower(endpoint), &quot;.RDS&quot;)) } else { med_vec &lt;- readRDS(paste0(&quot;../endpoints/meds_in_interval/&quot;, tolower(author), &quot;.&quot;, tolower(endpoint), &quot;.spec.RDS&quot;)) } if(length(med_vec) &gt; 0){ #Iterating over each medication #for(i in 1:min(10, length(med_vec))){ for(i in 1:length(med_vec)){ #final_name &lt;- paste0(&quot;med_files/&quot;, author, &quot;/&quot;, author, &quot;.&quot;, names(med_vec[i]), &quot;.&quot;, endpoint, &quot;.df.RDS&quot;) final_name &lt;- paste0(&quot;med_dfs/&quot;, author, &quot;.&quot;, endpoint, &quot;.&quot;, names(med_vec[i]), &quot;.RDS&quot;) if(file.exists(final_name)){ print(i) } else { print(paste(&quot;med_vec&quot;, i)) write.table(names(med_vec)[i], &quot;temp_med_name&quot;, row.names = F, col.names = F, quote = F) system(&quot;zcat ~/athena/ukbiobank/gp/gp_scripts.txt.gz | fgrep -w -f temp_med_name | grep -ax &#39;.*&#39;&gt; sub_gp_script2&quot;) #sub_gp &lt;- read.table(&quot;sub_gp_script&quot;, stringsAsFactors=F, sep = &#39;\\t&#39;) sub_gp &lt;- as.data.frame(fread(&quot;sub_gp_script2&quot;, quote = &quot;^&quot;)) #66630 sub_gp &lt;- sub_gp[grep(paste0(&quot;^&quot;, names(med_vec)[i]), sub_gp[,5]), ] sub_gp[,3] &lt;- as.Date(sub_gp[,3], &quot;%d/%m/%Y&quot;) #sub_gp &lt;- sub_gp[sub_gp[,3] &gt; as.Date(&quot;1999-01-01&quot;),] sub_gp &lt;- sub_gp[sub_gp[,1] %in% surv_df$eid,] ################################################################################ #need to extract mg information ###### ################################################################################ print(&quot;extracting info&quot;) unq_med_names &lt;- unique(sub_gp[,7]) unq_dose_names &lt;- unique(sub_gp[,8]) dose_info_1 &lt;- as.numeric(unlist(lapply(tolower(unq_med_names), get_val, &quot;mg&quot;))) dose_info_2 &lt;- as.numeric(unlist(lapply(tolower(unq_med_names), get_val, &quot;g&quot;))) * 1000 dose_info_3 &lt;- as.numeric(unlist(lapply(tolower(unq_med_names), get_val, &quot;milli&quot;))) dose_info_4 &lt;- as.numeric(unlist(lapply(tolower(unq_med_names), get_val, &quot;ml&quot;))) dose_info_5 &lt;- as.numeric(unlist(lapply(tolower(unq_dose_names), get_val, &quot;mg&quot;))) dose_info_6 &lt;- as.numeric(unlist(lapply(tolower(unq_dose_names), get_val, &quot;g&quot;))) * 1000 dose_info_7 &lt;- as.numeric(unlist(lapply(tolower(unq_dose_names), get_val, &quot;milli&quot;))) dose_info_8 &lt;- as.numeric(unlist(lapply(tolower(unq_dose_names), get_val, &quot;ml&quot;))) freq_info_1 &lt;- as.numeric(unlist(lapply(tolower(unq_dose_names), get_val, &quot;tab&quot;))) freq_info_2 &lt;- as.numeric(unlist(lapply(tolower(unq_dose_names), get_val, &quot;cap&quot;))) freq_info_3 &lt;- as.numeric(unlist(lapply(tolower(unq_dose_names), get_val, &quot;day&quot;))) freq_info_4 &lt;- as.numeric(unlist(lapply(tolower(unq_dose_names), get_val, &quot;pack&quot;))) freq_info_5 &lt;- as.numeric(unlist(lapply(tolower(unq_dose_names), get_first))) freq_info_5[freq_info_5 == dose_info_5] &lt;- NA freq_info_5[freq_info_5 == dose_info_6] &lt;- NA freq_info_5[freq_info_5 == dose_info_7] &lt;- NA freq_info_5[freq_info_5 == dose_info_8] &lt;- NA dose_amt &lt;- rep(NA, nrow(sub_gp)) pill_amt &lt;- rep(NA, nrow(sub_gp)) freq_amt &lt;- rep(NA, nrow(sub_gp)) for(j in 1:length(unq_med_names)){ dose_amt[sub_gp[,7] == unq_med_names[j]] &lt;- dose_info_1[j] dose_amt[sub_gp[,7] == unq_med_names[j] &amp; is.na(dose_amt)] &lt;- dose_info_2[j] dose_amt[sub_gp[,7] == unq_med_names[j] &amp; is.na(dose_amt)] &lt;- dose_info_3[j] dose_amt[sub_gp[,7] == unq_med_names[j] &amp; is.na(dose_amt)] &lt;- dose_info_4[j] } for(j in 1:length(unq_dose_names)){ dose_amt[sub_gp[,8] == unq_dose_names[j] &amp; is.na(dose_amt)] &lt;- dose_info_5[j] dose_amt[sub_gp[,8] == unq_dose_names[j] &amp; is.na(dose_amt)] &lt;- dose_info_6[j] dose_amt[sub_gp[,8] == unq_dose_names[j] &amp; is.na(dose_amt)] &lt;- dose_info_7[j] dose_amt[sub_gp[,8] == unq_dose_names[j] &amp; is.na(dose_amt)] &lt;- dose_info_8[j] pill_amt[sub_gp[,8] == unq_dose_names[j]] &lt;- freq_info_1[j] pill_amt[sub_gp[,8] == unq_dose_names[j] &amp; is.na(pill_amt)] &lt;- freq_info_2[j] pill_amt[sub_gp[,8] == unq_dose_names[j] &amp; is.na(pill_amt)] &lt;- freq_info_3[j] freq_amt[sub_gp[,8] == unq_dose_names[j]] &lt;- freq_info_4[j] pill_amt[sub_gp[,8] == unq_dose_names[j] &amp; is.na(pill_amt) &amp; is.na(freq_amt)] &lt;- freq_info_5[j] #freq_amt[(sub_gp[,8] == unq_dose_names[j]) &amp; is.na(freq_amt) &amp; !is.na(pill_amt) &amp; (freq_info_5[j] != pill_amt[sub_gp[,8] == unq_dose_names[j])] &lt;- freq_info_5[j] } freq_amt[is.na(freq_amt)] &lt;- 1 pill_amt &lt;- pill_amt * freq_amt pill_amt[!is.na(pill_amt)][pill_amt[!is.na(pill_amt)] &gt; quantile(pill_amt[!is.na(pill_amt)], 0.99)] &lt;- median(pill_amt[!is.na(pill_amt)]) pill_amt[is.na(pill_amt)] &lt;- median(pill_amt) dose_amt[is.na(dose_amt)] &lt;- mean(dose_amt, na.rm = T) pill_amt[is.na(pill_amt)] &lt;- mean(pill_amt, na.rm = T) sub_gp$dose &lt;- dose_amt sub_gp$pill &lt;- pill_amt sub_gp$pill[sub_gp$pill == 0] &lt;- 1 ########################################################################### # need to create new survival df ########################################################################### print(&quot;creating new df&quot;) new_gp_dfs &lt;- list() k &lt;- 1 good_to_use_eid &lt;- unique(sub_gp[,1])[unique(sub_gp[,1]) %in% surv_df$eid] for(eid in good_to_use_eid){ eid_gp &lt;- sub_gp[sub_gp[,1] == eid,] eid_surv &lt;- surv_df[surv_df$eid == eid,] eid_gp &lt;- eid_gp[eid_gp[,3] &lt; eid_surv$end_date &amp; eid_gp[,3] &gt; eid_surv$start_date &amp; !is.na(eid_gp[,3]),] eid_surv_pheno &lt;- eid_surv$pheno if(nrow(eid_gp) &gt; 0){ #when two prescriptions are made on one day if(any(duplicated(eid_gp[,3]))){ bad_date &lt;- eid_gp[duplicated(eid_gp[,3]),3] add_dose &lt;- eid_gp$dose[duplicated(eid_gp[,3])] eid_gp &lt;- eid_gp[!duplicated(eid_gp[,3]),] for(m in 1:length(bad_date)){ eid_gp$dose[eid_gp[,3] == bad_date[m]] &lt;- eid_gp$dose[eid_gp[,3] == bad_date[m]] + add_dose[m] } } #if presscription is made past the time of death (or phenotype?) past_death &lt;- (eid_gp[,3] + eid_gp$pill) &gt;= eid_surv$end_date if(any(past_death)){ eid_gp$pill[past_death] &lt;- as.numeric(eid_surv$end_date - eid_gp[past_death,3] - 1) past_death &lt;- (eid_gp[,3] + eid_gp$pill) &gt;= eid_surv$end_date if(any(past_death)){ eid_gp &lt;- eid_gp[!past_death,] } eid_gp &lt;- eid_gp[eid_gp$pill &gt; 0,] } if(nrow(eid_gp) &gt; 0){ eid_surv &lt;- eid_surv[rep(1, 2+nrow(eid_gp)),] eid_surv$pheno &lt;- 0 eid_surv$start_date &lt;- c(eid_surv$start_date[1], eid_gp[,3], eid_gp[nrow(eid_gp),3]+eid_gp$pill[nrow(eid_gp)]) eid_surv$end_date &lt;- c(eid_gp[1,3], eid_gp[,3]+eid_gp$pill, eid_surv$end_date[1]) eid_surv$dosage &lt;- c(0, eid_gp$dose, 0) eid_surv$time &lt;- as.numeric(eid_surv$end_date - eid_surv$start_date) eid_surv$end_time &lt;- cumsum(eid_surv$time) eid_surv$start_time &lt;- c(0, cumsum(eid_surv$time)[-nrow(eid_surv)]) eid_surv$pheno[nrow(eid_surv)] &lt;- eid_surv_pheno if(any(eid_surv$end_date &lt;= eid_surv$start_date)){ exit() } } else { eid_surv$end_time &lt;- eid_surv$time eid_surv$start_time &lt;- 0 } } else { eid_surv$end_time &lt;- eid_surv$time eid_surv$start_time &lt;- 0 } new_gp_dfs[[k]] &lt;- eid_surv k &lt;- k + 1 } print(&quot;finishing&quot;) new_gp_dfs &lt;- do.call(&quot;rbind&quot;, new_gp_dfs) rest_surv_df &lt;- surv_df[!(surv_df$eid %in% good_to_use_eid),] rest_surv_df$end_time &lt;- rest_surv_df$time final_df &lt;- rbind(new_gp_dfs, rest_surv_df) if(!all(final_df$eid %in% surv_objs[[1]]$eid)){ print(&quot;BAD: EID SHOULD NOT BE THERE&quot;) } saveRDS(final_df, paste0(&quot;med_dfs/&quot;, author, &quot;.&quot;, endpoint, &quot;.&quot;, names(med_vec[i]), &quot;.RDS&quot;)) } } } 13.2.3 Analysis The last part is the actual logistic regression for each sub-cohort, endpoint and medication. You may think that with the whole, complicated survival data frame situation I would be going with a time-dependent cox proportional hazards model. I thought that too, but then I tried it and the models either do not converge at all or converge in a way that gives you crazy answers. Therefore, I just went with the tried and true logistic regression, which required me to collapse all of the time information together. Although, since this change would make the dosage feature a simple sum of all the dosages I decided to do something a little bit more advanced. I wrote a few functions that look across the time-aware dosage data and return a different dosage measurement. For example: get_frac_time &lt;- function(x){ sum(x$time[x$dosage != 0])/x$end_time[nrow(x)] } get_mean_dose &lt;- function(x){ mean((x$dosage * (x$end_time - x$start_time))/x$end_time[nrow(x)]) } get_last_3year &lt;- function(x){ sum(x$dosage[x$start_time &gt; x$start_time[nrow(x)] - 365*3]) } With the simplified data frame and the dosage measurements of note completed the only thing left to do was regress. Three regressions in total were done over three polygenic risk score groups, the first quintile, third to fourth quintile, and fifth quintile. The resulting effects from each of these 3 regressions are extracted, and saved for later. The full script that runs this dosage splitting and regression process is: library(survival) library(plyr) #New idea, when doing the repeat event survival analysis make the analysis equal cases and controls options(warn=2) #author &lt;- &quot;Christophersen&quot; #endpoint &lt;- &quot;death_early&quot; args &lt;- commandArgs(trailingOnly=TRUE) author &lt;- args[1] endpoint &lt;- args[2] surv_objs &lt;- readRDS(paste0(&quot;surv_dfs/&quot;, author, &quot;.&quot;, endpoint, &quot;.RDS&quot;)) pgs_fitting &lt;- function(df, dose_name){ pgs_group &lt;- rep(NA, nrow(df)) quant_vals &lt;- quantile(df$score[!duplicated(df$eid)], 1:10/10) pgs_group[df$score &lt;= quant_vals[2]] &lt;- 1 pgs_group[df$score &gt; quant_vals[2] &amp; df$score &lt; quant_vals[8]] &lt;- 2 pgs_group[df$score &gt;= quant_vals[8]] &lt;- 3 df$pgs_group &lt;- as.factor(pgs_group) #need a better way to split the dosage into groups #could do nonzero, then below and above median dose_group &lt;- rep(NA, nrow(df)) curr_dose &lt;- df[,which(colnames(df) == dose_name)] if(any(is.na(curr_dose))){ saveRDS(df, &quot;temp.RDS&quot;) } print(&quot;curr dose&quot;) print(dose_name) print(sum(is.na(curr_dose))) if(all(curr_dose %in% c(0, 1))){ dose_group[curr_dose == 0] &lt;- 1 dose_group[curr_dose == 1] &lt;- 3 } else if(sum(curr_dose == 0) &gt; 10){ dose_group[curr_dose == 0] &lt;- 1 dose_group[curr_dose &lt; median(curr_dose[curr_dose != 0]) &amp; curr_dose != 0] &lt;- 2 dose_group[curr_dose &gt;= median(curr_dose[curr_dose != 0]) &amp; curr_dose != 0] &lt;- 3 } else { quant_vals &lt;- quantile(curr_dose, 1:10/10) dose_group[curr_dose &lt;= quant_vals[2]] &lt;- 1 dose_group[curr_dose &gt; quant_vals[2] &amp; curr_dose &lt; quant_vals[8]] &lt;- 2 dose_group[curr_dose &gt;= quant_vals[8]] &lt;- 3 } if(!&quot;start_time&quot; %in% colnames(df)){ df$start_time &lt;- 0 df$end_time &lt;- df$time } models_detail_dose &lt;- list() if(&quot;sex&quot; %in% colnames(df)){ models_detail_dose[[1]] &lt;- try(glm(as.formula(paste0(&quot;pheno ~ age + sex + &quot;, dose_name)), data = df[df$pgs_group == 1,], family = &quot;binomial&quot;)) models_detail_dose[[2]] &lt;- try(glm(as.formula(paste0(&quot;pheno ~ age + sex + &quot;, dose_name)), , data = df[df$pgs_group == 2,], family = &quot;binomial&quot;)) models_detail_dose[[3]] &lt;- try(glm(as.formula(paste0(&quot;pheno ~ age + sex + &quot;, dose_name)), data = df[df$pgs_group == 3,], family = &quot;binomial&quot;)) } else { models_detail_dose[[1]] &lt;- try(glm(as.formula(paste0(&quot;pheno ~ age + &quot;, dose_name)), data = df[df$pgs_group == 1,], family = &quot;binomial&quot;)) models_detail_dose[[2]] &lt;- try(glm(as.formula(paste0(&quot;pheno ~ age + &quot;, dose_name)), data = df[df$pgs_group == 2,], family = &quot;binomial&quot;)) models_detail_dose[[3]] &lt;- try(glm(as.formula(paste0(&quot;pheno ~ age + &quot;, dose_name)), data = df[df$pgs_group == 3,], family = &quot;binomial&quot;)) } ss_size &lt;- matrix(NA, nrow = 3, ncol = 3) pheno_size &lt;- matrix(NA, nrow = 3, ncol = 3) for(i in 1:3){ for(j in 1:3){ ss_size[i,j] &lt;- sum(df$pgs_group == i &amp; dose_group == j) pheno_size[i,j] &lt;- sum(df$pgs_group == i &amp; dose_group == j &amp; df$pheno == 1) } } return(list(models_detail_dose, list(ss_size, pheno_size))) } #Adjust covariates to a max value of 100 adjust_100 &lt;- function(x){ return((x-min(x))/(max(x-min(x)))) } #creates sort of a quantile of doses adjust_dose &lt;- function(x){ ans &lt;- rep(0, length(x)) y &lt;- seq(0, max(x), length.out = 10) for(i in y){ ans[x &gt; i] &lt;- which(y == i) } return(ans) } #following Andrew&#39;s idea should also try to do a binary, or categorized comparison rather than just continous poss_files &lt;- list.files(&quot;med_dfs/&quot;) poss_files &lt;- poss_files[grepl(paste0(author, &quot;.&quot;, endpoint), poss_files)] for(j in 1:length(poss_files)){ print(poss_files[j]) save_name &lt;- paste(strsplit(poss_files[j], &quot;.&quot;, fixed=T)[[1]][2:5], collapse = &quot;.&quot;) new_name &lt;- paste0(&quot;logistic_results/&quot;, author, &quot;.&quot;, save_name, &quot;.RDS&quot;) #new_name &lt;- &quot;temp123.RDS&quot; if(!file.exists(new_name)){ ##################################################################################### # Read in the Data #33 ##################################################################################### #Caution - this takes a long time surv_df &lt;- readRDS(paste0(&quot;med_dfs/&quot;, poss_files[j])) surv_df &lt;- surv_df[surv_df$eid %in% surv_objs[[3]],] #For weird dosages if(max(surv_df$dosage) &gt; 10){ cut_off &lt;- quantile(surv_df$dosage[surv_df$dosage != 0], 0.975) bad_eid &lt;- unique(surv_df$eid[surv_df$dosage &gt; cut_off]) surv_df &lt;- surv_df[!(surv_df$eid %in% bad_eid),] } #Get the polygenic risk scores ueid &lt;- unique(surv_df$eid) score_list &lt;- list() for(i in 1:length(ueid)){ score_list[[i]] &lt;- surv_objs[[2]][surv_objs[[1]]$eid == ueid[i],,drop=F][rep(1, sum(surv_df$eid == ueid[i])),] } surv_score &lt;- do.call(&quot;rbind&quot;, score_list) best_tune &lt;- read.table(paste0(&quot;~/athena/doc_score/analyze_score/tune_score/tune_results/&quot;, tolower(author), &quot;.best.ss&quot;), stringsAsFactors=F) surv_df$score &lt;- surv_score[,colnames(surv_score) == best_tune[3,2]] best_score_ind &lt;- which(colnames(surv_score) == best_tune[3,2]) #reduce to a medication only surv_df med_eid &lt;- unique(surv_df$eid[surv_df$dosage != 1]) case_eid &lt;- unique(surv_df$eid[surv_df$pheno == 0]) control_eid &lt;- unique(surv_df$eid[!(surv_df$eid %in% case_eid)]) med_control_eid &lt;- unique(surv_df$eid[!(surv_df$eid %in% case_eid) &amp; surv_df$dosage != 0]) med_case_eid &lt;- unique(surv_df$eid[surv_df$eid %in% case_eid &amp; surv_df$dosage != 0]) #could also reduce to case/control matched but not sure if this really helps #med_surv_df &lt;- surv_df[surv_df$eid %in% c(med_control_eid, med_case_eid),] ##################################################################################### # Set up the Simple # ##################################################################################### #set up the simple surv df simple_surv_df &lt;- surv_objs[[1]][surv_objs[[1]]$eid %in% ueid,] simple_surv_df$score &lt;- surv_objs[[2]][surv_objs[[3]] %in% ueid, best_score_ind] simple_surv_df &lt;- simple_surv_df[order(simple_surv_df$eid)[rank(ueid)],] get_frac_time &lt;- function(x){ sum(x$time[x$dosage != 0])/x$end_time[nrow(x)] } get_mean_dose &lt;- function(x){ mean((x$dosage * (x$end_time - x$start_time))/x$end_time[nrow(x)]) } get_last_3year &lt;- function(x){ sum(x$dosage[x$start_time &gt; x$start_time[nrow(x)] - 365*3]) } get_last_given &lt;- function(x){ if(any(x$dosage != 0)){ x$dosage[x$dosage != 0][sum(x$dosage != 0)] } else { 0 } } quartile_dosage &lt;- function(x, q1, q2){ sum(x$dosage[x$end_time &gt; (x$end_time[nrow(x)] * q1) &amp; x$end_time &lt;= (x$end_time[nrow(x)] * q2)]) } get_on_mean &lt;- function(x){ if(any(x$dosage != 0)){ mean(x$dosage[x$dosage != 0] * (x$end_time[x$dosage != 0] - x$start_time[x$dosage != 0])) } else { 0 } } #get the simple_surv_df dosage variables simple_surv_df$total_dosage &lt;- plyr::daply(surv_df, .(eid), function(x) sum(x$dosage)) simple_surv_df$frac_time &lt;- plyr::daply(surv_df, .(eid), get_frac_time) simple_surv_df$mean_dosage &lt;- plyr::daply(surv_df, .(eid), get_mean_dose) simple_surv_df$on_mean_dosage &lt;- plyr::daply(surv_df, .(eid), get_on_mean) simple_surv_df$max_dosage &lt;- plyr::daply(surv_df, .(eid), function(x) max(x$dosage)) simple_surv_df$last_3year_dosage &lt;- plyr::daply(surv_df, .(eid), get_last_3year) simple_surv_df$last_given_dosage &lt;- plyr::daply(surv_df, .(eid), get_last_given) simple_surv_df$q1_dosage &lt;- plyr::daply(surv_df, .(eid), function(x) quartile_dosage(x, 0, 0.33)) simple_surv_df$q2_dosage &lt;- plyr::daply(surv_df, .(eid), function(x) quartile_dosage(x, 0.33, 0.66)) simple_surv_df$q3_dosage &lt;- plyr::daply(surv_df, .(eid), function(x) quartile_dosage(x, 0.66, 1)) single_test_names &lt;- c(&quot;total_dosage&quot;, &quot;frac_time&quot;, &quot;mean_dosage&quot;, &quot;on_mean_dosage&quot;, &quot;max_dosage&quot;, &quot;last_3year_dosage&quot;, &quot;last_given_dosage&quot;, &quot;q1_dosage&quot;, &quot;q2_dosage&quot;, &quot;q3_dosage&quot;) all_adjust_names &lt;- c(single_test_names, c(&quot;age&quot;, &quot;sex&quot;, &quot;score&quot;), paste0(&quot;PC&quot;, 1:10)) for(k in all_adjust_names){ simple_surv_df[k] &lt;- adjust_100(simple_surv_df[k]) } if(any(is.na(simple_surv_df[1,]))){ simple_surv_df &lt;- simple_surv_df[,-which(is.na(simple_surv_df[1,]))] all_adjust_names &lt;- all_adjust_names[all_adjust_names %in% colnames(simple_surv_df)] } simple_surv_df$any_med &lt;- 0 simple_surv_df$any_med[simple_surv_df$total_dosage &gt; 0] &lt;- 1 #do the same thing but for the medication only data frame med_surv_df &lt;- simple_surv_df[simple_surv_df$total_dosage &gt; 0,] for(k in all_adjust_names){ med_surv_df[k] &lt;- adjust_100(med_surv_df[k]) } if(&quot;sex&quot; %in% colnames(simple_surv_df)){ base_covars &lt;- &quot;age + sex&quot; } else { base_covars &lt;- &quot;age&quot; } #Switch to Logistic ##################################################################################### # Running the Models # ##################################################################################### all_surv_models &lt;- list() all_med_models &lt;- list() i &lt;- 1 for(test_name in c(single_test_names, &quot;any_med&quot;)){ if(all(!is.na(simple_surv_df[,which(colnames(simple_surv_df) == test_name)]))){ all_surv_models[[i]] &lt;- try(pgs_fitting(simple_surv_df, test_name)) } else { all_surv_models[[i]] &lt;- NULL } if(test_name != &quot;any_med&quot;){ if(all(!is.na(med_surv_df[,which(colnames(med_surv_df) == test_name)]))){ all_med_models[[i]] &lt;- try(pgs_fitting(med_surv_df, test_name)) } else { all_med_models[[i]] &lt;- NULL } } i &lt;- i + 1 } names(all_surv_models) &lt;- c(single_test_names, &quot;any_med&quot;) names(all_med_models) &lt;- single_test_names ####################################################################################### ##################################################################################### for(kk in 1:length(all_surv_models)){ for(ll in 1:3){ if(length(class(all_surv_models[[kk]][[1]][[ll]])) == 2 ){ all_surv_models[[kk]][[1]][[ll]] &lt;- summary(all_surv_models[[kk]][[1]][[ll]])$coef } } } for(kk in 1:length(all_med_models)){ for(ll in 1:3){ if(length(class(all_med_models[[kk]][[1]][[ll]])) == 2){ all_med_models[[kk]][[1]][[ll]] &lt;- summary(all_med_models[[kk]][[1]][[ll]])$coef } } } #exit() #all_datasets &lt;- list(surv_df = surv_df, simple_surv_df = simple_surv_df) all_fits &lt;- list(&quot;surv_models&quot; = all_surv_models, &quot;med_models&quot; = all_med_models) saveRDS(all_fits, new_name) } } 13.2.4 Change in Plans Despite all of this work, the results were not significant, and legitimate options have been able to change this result. As the underlying sample size is likely of issue I completely changed tact. Disregarding the detailed prescription data, I instead opted for the self-reported medication data which is available for everybody. The analysis followed exactly the same way as with the lifestyle modifications, except for now the three lifestyle groups are replaced by two groups (either an individual takes or does not take the medication). To make this process a little simpler, only medications that had greater than 1000 people taking it were analyzed (about 150). ########################################################### # INCIDENCE # ########################################################### #BASE ############################### get_se &lt;- function(x){ y &lt;- sum(x)/length(x) sqrt((y*(1-y))/length(x)) } get_arr_se &lt;- function(x,y){ a &lt;- sum(x) b &lt;- sum(y) n1 &lt;- length(x) n2 &lt;- length(y) se &lt;- sqrt( ((a/n1)*(1-a/n1))/n1 + ((b/n2)*(1-b/n2))/n2 ) return(se) } get_prev &lt;- function(x){sum(x)/length(x)} if(&quot;sex&quot; %in% colnames(df_test)){ prs_mod &lt;- lm(score ~ age + sex + PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10, data = df_test) } else { prs_mod &lt;- lm(score ~ age + PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10, data = df_test) } adj_prs &lt;- resid(prs_mod) prs_groups &lt;- rep(1, nrow(df_test)) prs_groups[adj_prs &lt; quantile(adj_prs, 0.2)] &lt;- 0 prs_groups[adj_prs &gt; quantile(adj_prs, 0.8)] &lt;- 2 #do manual: cont_tables &lt;- rep(list(matrix(0, nrow = 2, ncol = 3)), ncol(mod_factors)) fish_tables &lt;- rep(list(matrix(0, nrow = 2, ncol = 2)), ncol(mod_factors)*3) se_cont_tables &lt;- rep(list(matrix(0, nrow = 2, ncol = 3)), ncol(mod_factors)) se_arr &lt;- rep(list(c(NA, NA, NA)), ncol(mod_factors)) kval &lt;- 1 for(i in 1:ncol(mod_factors)){ print(i) use_mod &lt;- mod_factors[!is.na(mod_factors[,i]), i] use_pheno &lt;- df_test$pheno[!is.na(mod_factors[,i])] use_prs &lt;- prs_groups[!is.na(mod_factors[,i])] for(j in 0:2){ cont_tables[[i]][1,j+1] &lt;- get_prev(use_pheno[use_prs == j &amp; use_mod == 0]) cont_tables[[i]][2,j+1] &lt;- get_prev(use_pheno[use_prs == j &amp; use_mod == 1]) se_cont_tables[[i]][1,j+1] &lt;- get_se(use_pheno[use_prs == j &amp; use_mod == 0]) se_cont_tables[[i]][2,j+1] &lt;- get_se(use_pheno[use_prs == j &amp; use_mod == 1]) fish_tables[[kval]][1,1] &lt;- sum(use_pheno[use_prs == j &amp; use_mod == 0]) fish_tables[[kval]][1,2] &lt;- sum(use_pheno[use_prs == j &amp; use_mod == 0] == 0) fish_tables[[kval]][2,1] &lt;- sum(use_pheno[use_prs == j &amp; use_mod == 1]) fish_tables[[kval]][2,2] &lt;- sum(use_pheno[use_prs == j &amp; use_mod == 1] == 0) kval &lt;- kval + 1 se_arr[[i]][j+1] &lt;- get_arr_se(use_pheno[use_prs == j &amp; use_mod == 0], use_pheno[use_prs == j &amp; use_mod == 1]) } } fish_p &lt;- lapply(fish_tables, function(x) fisher.test(x)$p.value) fish_or &lt;- lapply(fish_tables, function(x) fisher.test(x)$estimate) fish_stat &lt;- data.frame(&quot;pval&quot; = unlist(fish_p), &quot;or&quot; = unlist(fish_or), &quot;mod_factor&quot; = rep(colnames(mod_factors), each = 3), &quot;prs&quot; = rep(1:3, ncol(mod_factors))) names(cont_tables) &lt;- colnames(mod_factors) names(se_cont_tables) &lt;- colnames(mod_factors) final_obj &lt;- list(&quot;cont_tables&quot; = cont_tables, &quot;se_cont_tables&quot; = se_cont_tables, &quot;se_arr&quot; = se_arr, &quot;fish_stat&quot; = fish_stat) saveRDS(final_obj, paste0(&quot;final_stats/&quot;, author, &quot;.dose_data.RDS&quot;)) The resulting net incidences are then plotted in an identical manner to the lifestyle analyses. I do understand that the significance thresholds set in both the dose and lifestyle analses are rather liberal, as they are not true Bonferonni thresholds. However, as already stated I could not find a great way to aggregate three p-values and at the end of the day did want a liberal threshold so that any prospects could be reported for future, targeted investigation. "]]
