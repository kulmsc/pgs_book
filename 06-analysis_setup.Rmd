# Score Analysis Set-Up

Now that we have the scores we are nearly ready for analysis.  However, there are actually several more things that need to be done, namely setting up all of the phenotypes and covariates.  Similar to creating the scores, this is an often underrated process that needs to be done carefully or everything else fails.

## Defining the Phenotypes

By phenotype I mean status of whether an individual has the disease corresponding to the polygenic risk score.  This is a tricky problem, since first of all each underlying GWAS of the polygenic risk scores may construct phenotypes differently.  Adjusting our phenotypes to each GWAS does not seem easy however, or even possible given the limited information within the UK Biobank.  However the UK Biobank does have a great deal of information.  The sources that we will use to construct phenotypes are as follows:

  1. Self-Reported - Each individual was interviewed by a trained nurse and asked about any illnesses they may have.  The nurse then placed any description by the individual into a pre-specified tree of diseases.  This data can be suspect as the individual may report self-diagnoses not confirmed by a doctor and not really existing, but overall they are likely to line up with actual conditions for most of the individuals.
  Further description on the self-reported data-type can be found here, http://biobank.ndph.ox.ac.uk/showcase/field.cgi?id=20002, and all possible self-reported codings can be found here, http://biobank.ndph.ox.ac.uk/showcase/coding.cgi?id=3, and here http://biobank.ndph.ox.ac.uk/showcase/coding.cgi?id=6 (for cancer and non-cancer).

  2. ICD - The UK Biobank has pulled in the electronic health record of every individual.  Specifically, when a doctor makes a diagnosis they will record the ICD code in the computer.  These should be highly accurate, however there is always the change of a typo or a doctor recording a similar diagnosis that does not quite match what we want, making ICD codes rather fickle.  These records have been parsed into hesin files (hospital episode statistics).  In short there this one file, hesin_diag, with ICD codes on every line, and another file, hesin, with dates of hospital episodes.  One can look up the dates for a given ICD code by using the EID and instance index.  We will go over this more later.
  More information on the hesin data can be found here, https://biobank.ndph.ox.ac.uk/showcase/showcase/docs/HospitalEpisodeStatistics.pdf.  The coding for ICD9 codes can be found here, http://biobank.ndph.ox.ac.uk/showcase/coding.cgi?id=87.  The coding for ICD10 codes can be found here, http://biobank.ndph.ox.ac.uk/showcase/coding.cgi?id=19.  Note that ICD9 codes are older than ICD10.

  3. OPCS - Similar to ICD, OPCS codes are generally part of the electronic health record and are accessed from the hesin set of files. However, instead of recording diagnoses they record operations.  While generally not helpful for our purposes, some publications have used specific OPCS codes to assume that an underlying phenotype was the cause.  Following precendent I will do the same.
  More information on OPCS coding can be found here, http://biobank.ndph.ox.ac.uk/showcase/coding.cgi?id=240.  There are also OPCS3 codes, but they are very, very sparse.

  4. Medications - This is the least orthodox way of determining phenotype.  But I figure if someone is taking a medication that is only used for one illness, then there is a very good chance the person has that illness.  Unfortunately the UK Biobank does not have to the day records of medications, but only inventories when individuals come in for assessments.  By looking over CDC, respective professional society, and  Mayo Clinic websites I determine the associated medications and convert them into the UK Biobank codes.
  More information on Medication coding can be found here, http://biobank.ndph.ox.ac.uk/showcase/coding.cgi?id=4.  More information on how medication data was recorded can be found here, http://biobank.ndph.ox.ac.uk/showcase/field.cgi?id=20003.

The table that actually holds the conversion from the many possible codes of each category into a 1/0 phenotype is as follows.

```{R}
  pheno_defs <- read.table("~/athena/doc_score/analyze_score/descript_defs/author_defs", stringsAsFactors=F, header=T)
  print(pheno_defs)
```

The pipe symbol is used to indicate that if any of the codes can be found in the respective data type the phenotype will be called positive.


## Making the Phenotype

Now that we know what codes go to which phenotype, we simply need to go through the respective data files and check off when we find one for each EID.  Easier said than done, so I've broken down things into parts.  The first part is preparing the data, specifically breaking down the large phenotype file downloaded from the UK Biobank into parts that are easy to inspect and read in.  Along with these files, the hesin files are also nescessary, although they do not need any breaking down.  I would display these files but I do not think I am allowed to.  Anyway, the breaking down scripts looks like the following (note that if following along your indices are likely different).

```{bash, code = readLines("../analyze_score/construct_defs/prep_big_pheno.sh"), eval = F}
```

Now that everything is prepared data-wise we can get on with inspecting and calling phenotypes. I have tried this in many different ways, and the fastest option seems to be breaking down the total 500,000 people into groups and calling phenotypes for each group in parallel.  This parallel component is controlled by the following script, which is straightforward.

```{bash, code = readLines("../analyze_score/construct_defs/control_make_pheno.sh"), eval = F}
```

As you may be able to see the key script here is called better_pheno.py.  This script has a few different parts.  First it reads in all of the prepared data.  Next it subsets down to the group of individuals specified by the control_make_pheno, and sorts each file so the EIDs line up.  This sorting is important as it allows for quick indexing of EIDs (just iterate to the next unique EID rather than searching for the index). Lastly I check each type of phenotype (self-report, ICD, etc.) for the coding that was specified.  For the ICD and OPCS this process required me to check not just the exact code, but also a more general code due to the hierarchical natur of their coding.  For example if I am looking for G35 and an individual has G351 then I will still count that as a match.  Further details on how this script works can be found in the well recorded comments of the script itself, which starts below.

```{python, code = readLines("../analyze_score/construct_defs/better_pheno.py"), eval = F}
```



